<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【Python 协程系列】greenlet 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F3.%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3%2F3.1.Greenlet%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[参考资料 greenlet:Lightweight concurrent programming github:0.4.14 CSDN:fjs_cloud 前言C在过程调用时，使用栈帧来传递参数、存储返回信息、保存寄存器，以及局部存储。Python 在执行的时，以 PyFrameObject 作为环境，不断加载 PyCodeObject 进行执行。greenlet 就是利用 C 栈和 PyFrameObject，这两个特性，实现了协程。 123456789101112131415from greenlet import greenletdef test1(): print(12) gr2.switch() print(56)def test2(): print(34) gr1.switch() print("Never")gr1 = greenlet(test1)gr2 = greenlet(test2)gr1.switch() greenlet 实现了在一个系统线程中伪并发的运行多个任务流程。之所以是伪并发，是因为同时运行的始终只有一个，不同的任务可以不断的切换。换句换说，greenlet 实现的是一种 micro-threads/coroutines，并且 greenlet 本身并不提供调度功能。 通过 gr.switch() 主动切换到不同协程，需要注意的是仅支持同线程内切换。协程要切换，必然也要组织成链式结构。greenlet 给每个协程都赋予了 parent 参数，执行完成后，自动返回到 parent 继续执行。 Python 用法Instantiation: greenlet(run=None, parent=None) run is callable greenlet.getcurrent() greenlet.GreenletExit 不传递给 parent，可以用来 kill greenlet 可以通过继承 greenlet ，调用 run 方法。 Switching： x = gr.switch(y) will send the object y to g, 并且将从 任意的协程 接收参数给 x 注意，切换进入的是在，曾经切出的位置 如果没有启动，将从头开始执行 Attributes： g.parent This is writeable, 但不能 循环 g.gr_frame The current top frame, or None. g.dead True if g is dead (i.e. it finished its execution). bool(g) True if g is active, False if it is dead or not yet started. g.throw([typ, [val, [tb]]]) Switches execution to the greenlet g，defaults greenlet.GreenletExit PyGreenlet1234567891011121314151617 | ^^^ | | older data | 高地址处 | | stack_stop . |_______________| . | | . | greenlet data | . | in stack | . * |_______________| . . _____________ stack_copy + stack_saved . | | | | . | data | |greenlet data| . | unrelated | | saved | . | to | | in heap |stack_start . | this | . . |_____________| stack_copy 低地址处 | greenlet | | | | newer data | | vvv | 1234567891011121314151617typedef struct _greenlet &#123; PyObject_HEAD char* stack_start; // 栈顶 char* stack_stop; // 栈底 char* stack_copy; // heap 数据地址 intptr_t stack_saved; // heap 数据大小 struct _greenlet* stack_prev; // gr 链， The main (initial) gr 是最后一个 struct _greenlet* parent; // parent 指针 PyObject* run_info; // 运行信息，PyThreadState_GET()-&gt;dict struct _frame* top_frame; int recursion_depth; // 栈深度 PyObject* weakreflist; PyObject* exc_type; PyObject* exc_value; PyObject* exc_traceback; PyObject* dict;&#125; PyGreenlet; Data： 部分在堆、部分在栈、都可能为空 stack_stop == NULL &amp;&amp; stack_start == NULL: did not start yet stack_stop != NULL &amp;&amp; stack_start == NULL: already finished stack_stop != NULL &amp;&amp; stack_start != NULL: active 初始对象： 栈底，高地址：gmain-&gt;stack_stop = (char *) -1 栈顶，低地址：gmain-&gt;stack_start = (char *) 1 注意要点： greenlet 将每个 gr 都保存在堆上，调用链上的 gr 各自都有栈帧。 switch 涉及到 C栈 的备份恢复，以及 Python 环境的备份恢复。 执行 swtch 时，将 %rbp %rbx %rsp 等寄存器以及当前 gr 的栈帧数据，保存到堆上。 将 ts_target 的堆数据恢复到栈帧，并且恢复寄存器的值，让程序切出处执行。 Python 环境通过实现备份恢复 PyThreadState_GET() 实现。 其他： gr 的 return 以及报错，都是上抛给 parent gr 的 parent 默认是 ts_current，可以更改 gr 的 switch 是通过全局变量 ts_current, ts_target 等实现 gr 的 switch 无法发生在不同线程之间 PyMODINIT_FUNC123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172static struct PyModuleDef greenlet_module_def = &#123; PyModuleDef_HEAD_INIT, "greenlet", NULL, -1, GreenMethods, // 定义了 getcurrent、settrace、gettrace&#125;;PyMODINIT_FUNCPyInit_greenlet(void)&#123; PyObject* m = NULL; char** p = NULL; PyObject *c_api_object; static void *_PyGreenlet_API[PyGreenlet_API_pointers]; // [8] GREENLET_NOINLINE_INIT(); // 宏：阻止编译器对部分函数 inline 优化 // 创建 module m = PyModule_Create(&amp;greenlet_module_def); PyType_Ready(&amp;PyGreenlet_Type) // 创建共享字符串，并赋值全局变量全局变量 static PyObject* ts_curkey = PyUnicode_InternFromString("__greenlet_ts_curkey"); ts_delkey = PyUnicode_InternFromString("__greenlet_ts_delkey"); ts_tracekey = PyUnicode_InternFromString("__greenlet_ts_tracekey"); ts_event_switch = PyUnicode_InternFromString("switch"); ts_event_throw = PyUnicode_InternFromString("throw"); PyType_Ready(&amp;PyGreenlet_Type) PyExc_GreenletError = PyErr_NewException("greenlet.error", NULL, NULL); PyExc_GreenletExit = PyErr_NewException("greenlet.GreenletExit", PyExc_BaseException, NULL); // 创建 (),&#123;&#125; 并赋值全局变量 ts_empty_tuple = PyTuple_New(0); ts_empty_dict = PyDict_New(); // 只要导入模块，就创建了 main 协程 // static PyGreenlet* volatile ts_current = NULL ts_current = green_create_main(); // 添加 module 属性 PyModule_AddObject(m, "greenlet", (PyObject*) &amp;PyGreenlet_Type); PyModule_AddObject(m, "error", PyExc_GreenletError); PyModule_AddObject(m, "GreenletExit", PyExc_GreenletExit); PyModule_AddObject(m, "GREENLET_USE_GC", PyBool_FromLong(GREENLET_USE_GC)); PyModule_AddObject(m, "GREENLET_USE_TRACING", PyBool_FromLong(GREENLET_USE_TRACING)); /* 同时添加到 PyGreenlet_Type.__dict__ */ for (p=copy_on_greentype; *p; p++) &#123; PyObject* o = PyObject_GetAttrString(m, *p); if (!o) continue; PyDict_SetItemString(PyGreenlet_Type.tp_dict, *p, o); Py_DECREF(o); &#125; /* Expose C API */ _PyGreenlet_API[PyGreenlet_Type_NUM] = (void *) &amp;PyGreenlet_Type; _PyGreenlet_API[PyExc_GreenletError_NUM] = (void *) PyExc_GreenletError; _PyGreenlet_API[PyExc_GreenletExit_NUM] = (void *) PyExc_GreenletExit; _PyGreenlet_API[PyGreenlet_New_NUM] = (void *) PyGreenlet_New; _PyGreenlet_API[PyGreenlet_GetCurrent_NUM] = (void *) PyGreenlet_GetCurrent; _PyGreenlet_API[PyGreenlet_Throw_NUM] = (void *) PyGreenlet_Throw; _PyGreenlet_API[PyGreenlet_Switch_NUM] = (void *) PyGreenlet_Switch; _PyGreenlet_API[PyGreenlet_SetParent_NUM] = (void *) PyGreenlet_SetParent; c_api_object = PyCapsule_New((void *) _PyGreenlet_API, "greenlet._C_API", NULL); PyModule_AddObject(m, "_C_API", c_api_object); return m;&#125; 如上，module init，主要是创建属性、暴露API。从中能看出，greenlet 大量利用 static 全局变量，保存当前状态。其中很重要的一点是对 ts_current的赋值 green_create_main()。 green_create_main12345678910111213static PyGreenlet* green_create_main(void)&#123; PyGreenlet* gmain; PyObject* dict = PyThreadState_GetDict(); /* create the main greenlet for this thread */ gmain = (PyGreenlet*) PyType_GenericAlloc(&amp;PyGreenlet_Type, 0); gmain-&gt;stack_start = (char*) 1; // 栈顶为 1 gmain-&gt;stack_stop = (char*) -1; // 栈底为 -1，即最大地址处 gmain-&gt;run_info = dict; // 当前线程状态信息 Py_INCREF(dict); return gmain;&#125; 如上，初始创建 gr 对象 gmain，并且对栈地址、run_info 进行初始化。 实例化green_new12345678910111213PyTypeObject PyGreenlet_Type = &#123; PyVarObject_HEAD_INIT(NULL, 0) "greenlet.greenlet", /* tp_name */ (destructor)green_dealloc, /* tp_dealloc */ &amp;green_as_number, /* tp_as _number*/ green_methods, /* tp_methods */ (initproc)green_init, /* tp_init */ GREENLET_tp_alloc, /* tp_alloc */ green_new, /* tp_new */ GREENLET_tp_free, /* tp_free */ (inquiry)GREENLET_tp_is_gc, /* tp_is_gc */ ...&#125; 初始化完成后greenlet.greenlet对应 PyGreenlet_Type。当执行greenlet(test1)，就是在调用green_new方法。 12345678910111213141516#define STATE_OK (ts_current-&gt;run_info == PyThreadState_GET()-&gt;dict \ || !green_updatecurrent())static PyObject* green_new(PyTypeObject *type, PyObject *args, PyObject *kwds)&#123; PyObject* o = PyBaseObject_Type.tp_new(type, ts_empty_tuple, ts_empty_dict); if (o != NULL) &#123; if (!STATE_OK) &#123; // 确保同一线程 Py_DECREF(o); return NULL; &#125; Py_INCREF(ts_current); ((PyGreenlet*) o)-&gt;parent = ts_current; &#125; return o;&#125; 创建对象，将 gr-&gt;parent 指向当前 ts_current。可见，parent 默认是与 gr 的创建位置有关，与启动位置无关。接着自然是执行 tp_init。 green_init12345678910111213141516171819202122static int green_init(PyGreenlet *self, PyObject *args, PyObject *kwargs)&#123; PyObject *run = NULL; PyObject* nparent = NULL; static char *kwlist[] = &#123;"run", "parent", 0&#125;; if (!PyArg_ParseTupleAndKeywords(args, kwargs, "|OO:green", kwlist, &amp;run, &amp;nparent)) return -1; if (run != NULL) &#123; // self-&gt;run_info = nrun; if (green_setrun(self, run, NULL)) return -1; &#125; if (nparent != NULL &amp;&amp; nparent != Py_None) // assert nparent != NULL &amp;&amp; PyGreenlet_Check(nparent) // 不能产生循环链(self != nparent-&gt;parent-&gt;... ) // assert self-&gt;run_info == run_info // 最终 self-&gt;parent = nparent return green_setparent(self, nparent, NULL); return 0;&#125; main greenlet 的 run_info 初始化为 线程状态信息。而实例化后的 gr，run_info 被赋值为 callable 对象。至此，生成的 gr，依然保持未启动状态，stack_stop==stack_start==NULL。 切换123456789101112def test1(): print(12) gr2.switch() print(56)def test2(): print(34) gr1.switch() print(&quot;Never&quot;)gr1 = greenlet(test1)gr2 = greenlet(test2) 上面的 Python 代码，切换链可以简化为：1main -&gt; gr1 -&gt; gr2 -&gt; gr1 ---return----&gt; to main 根据源码可以看出，在 Python 中调用gr.switch()，将执行g_switch。1234567891011121314// green_methods, /* tp_methods */static PyMethodDef green_methods[] = &#123; &#123;"switch", (PyCFunction)green_switch, ...&#125;static PyObject*green_switch(PyGreenlet* self, PyObject* args, PyObject* kwargs)&#123; Py_INCREF(args); Py_XINCREF(kwargs); // result = item if result ==(item,) else result return single_result(g_switch(self, args, kwargs));&#125; g_switch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static PyObject *g_switch(PyGreenlet* target, PyObject* args, PyObject* kwargs)&#123; int err = 0; PyObject* run_info; // 1.1 确保 ts_current-&gt;run_info 为线程状态信息 if (!STATE_OK) &#123; Py_XDECREF(args); Py_XDECREF(kwargs); return NULL; &#125; // 1.2.1 遍历 g-&gt;parent chain，直到找到 STARTED(g) 的 run_info run_info = green_statedict(target); // 1.2.2 确保 paretn-&gt;run_info 跟当前线程一样 if (run_info == NULL || run_info != ts_current-&gt;run_info) &#123; Py_XDECREF(args); Py_XDECREF(kwargs); PyErr_SetString(PyExc_GreenletError, run_info ? "cannot switch to a different thread" : "cannot switch to a garbage collected greenlet"); return NULL; &#125; // 2. 改变全局变量，传递参数 ts_passaround_args = args; ts_passaround_kwargs = kwargs; // 3. 执行切换 while (target) &#123; // gr 已经 启动 // gr2 -&gt; gr1 会进入到这部分 if (PyGreenlet_ACTIVE(target)) &#123; ts_target = target; err = g_switchstack(); break; &#125; // 启动 gr // main-&gt; gr1 -&gt; gr2 都将进入到这部分 if (!PyGreenlet_STARTED(target)) &#123; void* dummymarker; ts_target = target; err = g_initialstub(&amp;dummymarker); if (err == 1) &#123; continue; /* retry the switch */ &#125; break; &#125; target = target-&gt;parent; &#125; // 4. 将切换回来的 全局变量 保存起来 args = ts_passaround_args; ts_passaround_args = NULL; kwargs = ts_passaround_kwargs; ts_passaround_kwargs = NULL; PyGreenlet *origin; origin = ts_origin; ts_origin = NULL; Py_DECREF(origin); // 5. 处理返回值 /* if kwargs is None or kwargs is &#123;&#125;: return args elif args is (): return kwargs else: return (args, kwargs) */&#125; 如上： 首先，确保 ts_current/ts_target 线程状态 run_info 跟当前线程状态一致 其次，改变全局变量，传递参数 然后，g_switchstack 到已经启动的 gr，或者 g_initialstub 初始化 gr 最后，从全局变量，获取 switch() 得到的返回值，并处理后返回到调用位置 从main-&gt;g1-&gt;g2切换对象都是未启动的，必然是走第二条分支g_initialstub。若返回值为为0，会进入return流程。 从g2-&gt;g1，切换对象 g1 已经启动过，那么就直接进入g_switchstack分支。不管返回值如何，都将进入到return流程。 g_initialstub123456789if (!PyGreenlet_STARTED(target)) &#123; void* dummymarker; // 注意这个东西，一个临时变量指针 ts_target = target; // 同时注意这个 全局变量 err = g_initialstub(&amp;dummymarker); if (err == 1) &#123; continue; /* retry the switch */ &#125; break;&#125; 运行中申请变量，dummymarker其实就是当前的 C栈 指针位置！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071static int GREENLET_NOINLINE(g_initialstub)(void* mark)&#123; int err; PyGreenlet* self = ts_target; // 注意，self 其实是要初始化的 gr PyObject* args = ts_passaround_args; // 全局变量，switch() 时，传递的参数 PyObject* kwargs = ts_passaround_kwargs; /* save exception in case getattr clears it */ /* self.run is the object to call in the new greenlet */ /* restore saved exception */ /* recheck the state in case getattr caused thread switches */ /* recheck run_info in case greenlet reparented anywhere above */ /* start the greenlet */ self-&gt;stack_start = NULL; // 栈顶为 NULL，暂时 finished self-&gt;stack_stop = (char*) mark; // 栈底为 &amp;dummymarker，表明 actice // 构建 gr 链 if (ts_current-&gt;stack_start == NULL) &#123; /* ts_current is dying */ self-&gt;stack_prev = ts_current-&gt;stack_prev; &#125; else &#123; self-&gt;stack_prev = ts_current; &#125; self-&gt;top_frame = NULL; green_clear_exc(self); self-&gt;recursion_depth = PyThreadState_GET()-&gt;recursion_depth; /* restore arguments in case they are clobbered */ ts_target = self; ts_passaround_args = args; ts_passaround_kwargs = kwargs; /* perform the initial switch 还记得 g_switch()中，遇到已经启动的 gr，会直接调用 g_switchstack 那么，此处同样调用，就意味着，gr 已经初始化完毕 注意，当前的全局变量参数 */ err = g_switchstack(); // 切换栈，等待返回 /* returns twice! The 1st time with err=1: we are in the new greenlet The 2nd time with err=0: back in the caller's greenlet */ if (err == 1) &#123; /* in the new greenlet */ self-&gt;stack_start = (char*) 1; /* running */ /* now use run_info to store the statedict */ self-&gt;run_info = green_statedict(self-&gt;parent); /* call g.run(*args, **kwargs) */ run = PyObject_GetAttrString((PyObject*) self, "run"); result = PyEval_CallObjectWithKeywords( run, args, kwargs); result = g_handle_exit(result); /* jump back to parent */ self-&gt;stack_start = NULL; /* dead */ for (parent = self-&gt;parent; parent != NULL; parent = parent-&gt;parent) &#123; // 注意，这里 switch 目标是 parent // 并且把返回值作为了参数 args result = g_switch(parent, result, NULL); assert(result == NULL); &#125; &#125; if (err &lt; 0) &#123; ... &#125; // 切换出错 return err;&#125; 代码很长，绝大部分都在进行容错处理 run 不能为 NULL 确保同一线程 若已经被启动，则返回 真正执行部分，对 self 进行赋值，然后再次恢复全局变量，调用g_switchstack()，切换栈。注释中也提到，g_switchstack()执行完成后，会返回两次。一次是在 new gr 中，一次是从任意 gr 返回到 caller 中。 err=1，进入到 new gr 的代码执行阶段，调用PyEval_CallObjectWithKeywords开始执行用户指定的 python callable。注意，执行完成后，跳转到的是 parent，而并非自身的 caller。 g_switchstack1234567891011121314151617/* Perform a stack switch according to some global variables that must be set before: - ts_current: current greenlet (holds a reference) - ts_target: greenlet to switch to (weak reference) - ts_passaround_args: NULL if PyErr_Occurred(), else a tuple of args sent to ts_target (holds a reference) - ts_passaround_kwargs: switch kwargs (holds a reference) On return results are passed via global variables as well: - ts_origin: originating greenlet (holds a reference) - ts_current: current greenlet (holds a reference) - ts_passaround_args: NULL if PyErr_Occurred(), else a tuple of args sent to ts_current (holds a reference) - ts_passaround_kwargs: switch kwargs (holds a reference) It is very important that stack switch is 'atomic', i.e. no calls into other Python code allowed (except very few that are safe), because global variables are very fragile.*/ 先来看段注释，显然，栈切换是通过全局变量 ts_* 实现。那么，执行代码前的全局变量是什么样子的?执行main -&gt; gr1，会从 g_switch -&gt; g_initialstub -&gt; g_switchstack。 在 Module init 中： ts_current = main 在 g_initialstub 中： ts_target = self = ts_target = gr.switch() 的 gr ts_passaround_args = args = g_switch 参数 ts_passaround_kwargs = kwargs = g_switch 参数 同时还有一个神奇变量 dummymarker 在g_switch中创建，void* dummymarker 作为参数 mark 传入，g_initialstub(&amp;dummymarker) 在g_initialstub中，赋值给栈底，self-&gt;stack_stop = (char*) mark 123456789101112131415161718192021222324252627282930313233343536373839static int g_switchstack(void)&#123; int err; &#123; /* 保存 当前信息 */ PyGreenlet* current = ts_current; PyThreadState* tstate = PyThreadState_GET(); current-&gt;recursion_depth = tstate-&gt;recursion_depth; current-&gt;top_frame = tstate-&gt;frame; current-&gt;exc_type = tstate-&gt;exc_type; current-&gt;exc_value = tstate-&gt;exc_value; current-&gt;exc_traceback = tstate-&gt;exc_traceback; &#125; err = slp_switch(); // 执行切换 // ts_target 没有 active: err=1 // ts_target 已经 active：从 heap 恢复数据，恢复寄存器，err=0 if (err &lt; 0) &#123; ... // 错误处理 &#125; else &#123; PyGreenlet* target = ts_target; PyGreenlet* origin = ts_current; PyThreadState* tstate = PyThreadState_GET(); tstate-&gt;recursion_depth = target-&gt;recursion_depth; tstate-&gt;frame = target-&gt;top_frame; target-&gt;top_frame = NULL; tstate-&gt;exc_type = target-&gt;exc_type; tstate-&gt;exc_value = target-&gt;exc_value; tstate-&gt;exc_traceback = target-&gt;exc_traceback; green_clear_exc(target); assert(ts_origin == NULL); Py_INCREF(target); ts_current = target; ts_origin = origin; ts_target = NULL; &#125; return err;&#125; 在g_switchstack中，首先将当前线程的的状态信息，frame/exc 保存到 main 里。然后调用slp_switch()，这个函数，是一个区分平台的函数，利用内嵌汇编完成真正的切换。 如果调用链是some_gr.switch() -&gt; g_switch -&gt; g_initialstub -&gt; g_switchstack -&gt; slp_switch： 新 gr 返回值err=1 在g_initialstub中匹配到if(err==1): EvalCode... 直接就开始执行target.run() 执行完成后，切换到target.parent，而并非回到some_gr slp_switch123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 我们只看`gcc on X86`。// 使用内联汇编代码，static int slp_switch(void) &#123; int err; void *ebp, *ebx; unsigned short cw; register int *stackref, stsizediff; __asm__ volatile ("" : : : "esi", "edi"); __asm__ volatile ("fstcw %0" : "=m" (cw)); // 被调用者保存寄存器 ebx/ebp // 将寄存器 %ebp 的值保存到内存位置 ebp 处 __asm__ volatile ("movl %%ebp, %0" : "=m" (ebp)); __asm__ volatile ("movl %%ebx, %0" : "=m" (ebx)); // 将 栈指针 保存到寄存器 stackref 处 __asm__ ("movl %%esp, %0" : "=g" (stackref)); &#123; // 调整栈之间的偏移 stackref += STACK_MAGIC; // 将 target gr 之前的所有栈都保存到 heap 中 // 常返回0，错误返回 -1 if (slp_save_state((char*)stackref)) return -1; // 注意这句！！如果 ts_target 没有 active，return 1 if (!PyGreenlet_ACTIVE(ts_target)) return 1; // 第一次切换，就直接 返回 1/* -------- 如果 ts_target 已经启动过，才执行下面的语句 ----------- */ // 获取 ts_target 切换之前的 栈指针 stsizediff = ts_target-&gt;stack_start - (char*)stackref // 修改寄存器，将指针指向 ts_target 当时的位置 __asm__ volatile ( "addl %0, %%esp\n" "addl %0, %%ebp\n" : : "r" (stsizediff) ); /* -------- 现在 已经是在 ts_target 中执行 ----------- */ // 从 heap 恢复数据到栈上 slp_restore_state() // 异或清零 err=0 __asm__ volatile ("xorl %%eax, %%eax" : "=a" (err)); &#125; // 恢复之前保存的寄存器 __asm__ volatile ("movl %0, %%ebx" : : "m" (ebx)); __asm__ volatile ("movl %0, %%ebp" : : "m" (ebp)); __asm__ volatile ("fldcw %0" : : "m" (cw)); __asm__ volatile ("" : : : "esi", "edi"); return err;&#125; slp_save_state123456789101112131415161718192021222324// 将 target gr 之前的所有栈都保存到 heap 中static int GREENLET_NOINLINE(slp_save_state)(char* stackref)&#123; /* must free all the C stack up to target_stop */ char* target_stop = ts_target-&gt;stack_stop; // 获取到 目标栈底 PyGreenlet* owner = ts_current; // 当前 gr assert(owner-&gt;stack_saved == 0); // 当前 gr 并未保存数据 if (owner-&gt;stack_start == NULL) // already finished, main=1 owner = owner-&gt;stack_prev; /* not saved if dying */ else owner-&gt;stack_start = stackref; // 更新当前 gr 最终栈指针 // 循环，将目标栈下方的，所有 gr 全保存到 heap 中 while (owner-&gt;stack_stop &lt; target_stop) &#123; if (g_save(owner, owner-&gt;stack_stop)) return -1; /* XXX */ owner = owner-&gt;stack_prev; &#125; if (owner != ts_target) &#123; if (g_save(owner, target_stop)) return -1; /* XXX */ &#125; return 0;&#125; g_save1234567891011121314151617181920212223242526// 真正完成将栈中数据保存到 heapstatic int g_save(PyGreenlet* g, char* stop) &#123; /* Save more of g's stack into the heap -- at least up to 'stop' 高 g-&gt;stack_stop |________| | | | __ stop . . . . . | | ==&gt; . . |________| _______ | | | | | | | | 低 g-&gt;stack_start | | |_______| g-&gt;stack_copy */ intptr_t sz1 = g-&gt;stack_saved; // 已经在 heap 上的大小 intptr_t sz2 = stop - g-&gt;stack_start; // 实际栈大小 assert(g-&gt;stack_start != NULL); // g 并未结束 if (sz2 &gt; sz1) &#123; // 栈地址 增大了 // 栈增大，需要扩充空间，从 stack_copy -&gt; sz2 char* c = (char*)PyMem_Realloc(g-&gt;stack_copy, sz2); memcpy(c+sz1, g-&gt;stack_start+sz1, sz2-sz1); g-&gt;stack_copy = c; // 更新 heap 地址 g-&gt;stack_saved = sz2; // 更新 heap 大小 &#125; return 0;&#125; slp_restore_state1234567891011121314151617181920// 剪切 heap 数据到 C 栈，找到还在栈中的 prev grstatic void GREENLET_NOINLINE(slp_restore_state)(void) &#123; PyGreenlet* g = ts_target; PyGreenlet* owner = ts_current; /* Restore the heap copy back into the C stack */ if (g-&gt;stack_saved != 0) &#123; memcpy(g-&gt;stack_start, g-&gt;stack_copy, g-&gt;stack_saved); PyMem_Free(g-&gt;stack_copy); g-&gt;stack_copy = NULL; g-&gt;stack_saved = 0; &#125; if (owner-&gt;stack_start == NULL) owner = owner-&gt;stack_prev; /* greenlet is dying, skip it */ while (owner &amp;&amp; owner-&gt;stack_stop &lt;= g-&gt;stack_stop) // 比 stack_stop 小的 都已经被保存到 heap 上了 // 只有找到在目标上方的，作为 prev owner = owner-&gt;stack_prev; g-&gt;stack_prev = owner;&#125; 小结1main -&gt; gr1 -&gt; gr2 -&gt; gr1 ---return----&gt; to main 切换是调用 g_switch g_switch中有个 while 循环，会根据目标的走不同的分支 1234567891011121314while (target) &#123; if (PyGreenlet_ACTIVE(target)) &#123; err = g_switchstack(); break; &#125; if (!PyGreenlet_STARTED(target)) &#123; err = g_initialstub(&amp;dummymarker); if (err == 1) &#123; continue; &#125; break; &#125; target = target-&gt;parent;&#125; main -&gt; gr1 -&gt; gr2，目标都是未启动的，都走g_initialstub分支 在g_initialstub分支中，如果是未启动的，会直接开始执行 Python 代码 123456789err = g_switchstack(); // 切换栈，等待返回if (err == 1) &#123; result = PyEval_CallObjectWithKeywords( run, args, kwargs); g_switch(parent, result, NULL);&#125;return err; 所以main -&gt; gr1 -&gt; gr2会在PyEval中一直嵌套，直到 gr2 中执行到gr1.swtich() 注意，此时 gr1 的数据保存在 heap 上，C调用链处于g_switch -&gt; g_initialstub-&gt; g_switchstack -&gt; slp_switch状态 此时，gr1 已经 Active。产生调用链gr2.run() -&gt; g_switch(gr1) -&gt; g_switchstack -&gt; slp_switch 在 slp_switch 中，因为 gr1.Active，会开始恢复 gr1 的数据，恢复到 gr1 的执行序列中 12345if (!PyGreenlet_ACTIVE(ts_target)) return 1; # 第一次切换，就直接 返回 1slp_restore_state() # 恢复 栈 __asm__ volatile ... # 恢复 寄存器retrun 0; 根据第 6 步，会产生返回链slp_switch.return 0 -&gt; g_switchstack -&gt; g_initialstub -&gt; g_switch 在g_switch中因为 err=0，break 循环，处理结果并返回，完成整个流程]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>greenlet</tag>
        <tag>coroutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】—— 系列文章目录及介绍]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.0.Python%20Web%20%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[声明文章中出现的前文/前面，皆指同系列中的文章。上面，皆指同篇文章中的内容。文章中的注释内容，来源于源码和官网文档。文章中的源码，皆根据情况进行了删减、更改，读者需配合源码自行脑补。 欢迎读者留言(Mail: he11o76120 at gmail)，指出错误，共同交流。 目录 【Python Web 系列】WSGI 【Python Web 系列】Flask 源码分析 【Python Web 系列】Flask 一些 trick 【Python Web 系列】Django 源码分析 【Python Web 系列】Django 一些 trick 【Python Web 系列】Tornado 源码分析]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】Flask 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.2.Flask%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[参考 Flask 官网 werkzeug 官网 Demo12345678910# Flask.__version__ == 1.0.2from flask import Flaskapp = Flask(__name__)@app.route("/")def hello(): return "Hello World!"if __name__ == '__main__': app.run() Flask1234567class Flask(_PackageBoundObject): def wsgi_app(self, environ, start_response): ... def __call__(self, environ, start_response): return self.wsgi_app(environ, start_response) Flask实例化后，就是一个符合 WSGI 规定的，可调用对象。再来看看实例化都要干些啥。 init123456789101112131415def __init__(...): self.config = self.make_config() self.view_functions = &#123;&#125; self.error_handler_spec = &#123;&#125; self.before_request_funcs = &#123;&#125; self.before_first_request_funcs = [] self.after_request_funcs = &#123;&#125; self.teardown_request_funcs = &#123;&#125; self.teardown_appcontext_funcs = [] self.url_value_preprocessors = &#123;&#125; self.url_default_functions = &#123;&#125; self.url_map = Map() self.blueprints = &#123;&#125; self._blueprint_order = [] self.extensions = &#123;&#125; 看名字就知道，主要是对每次请求，创建一个处理通道。 @app.route12345678910111213def route(self, rule, **options): def decorator(f): endpoint = options.pop('endpoint', None) self.add_url_rule(rule, endpoint, f, **options) return f return decoratordef add_url_rule(self, rule, endpoint=None, view_func=None, provide_automatic_options=None, **options): ... rule = Rule(rule, methods=methods, **options) self.url_map.add(rule) self.view_functions[endpoint] = view_func 把路由 rule，加到 url_map 里；把 rule 对应的 endpint 跟 view_func，通过字典 view_functions 进行关联。 app.run1# 自行脑补 run 仅仅在开发环境使用。我们可以自行脑补出代码：”创建一个符合 WSGI 的服务器，从浏览器接收 HTTP 请求，封装 environ，调用 app.call“。生产环境一般都通过配置文件，指定 WSGI app 所在位置。我们直接来看，这种情况下怎么运行。 wsgi_app123456789101112131415161718def wsgi_app(self, environ, start_response): ctx = RequestContext(self, environ) # flask.ctx.RequestContext error = None try: try: ctx.push() # Binds the request context to the current context." response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) 整个请求都在这部分完成：请求上下文的压栈，请求路由分发，错误处理，返回内容，上下文出栈。 接下来就到了Flask 的精华部分，Context！ ContextRequestContext1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class RequestContext(object): """The request context contains all request relevant information. It is created at the beginning of the request and pushed to the `_request_ctx_stack` and removed at the end of it. It will create the URL adapter and request object for the WSGI environment provided. """ def __init__(self, app, environ, request=None): self.app = app self.request = Request(environ) self.url_adapter = app.create_url_adapter(self.request) self.flashes = None self.session = None # 请求上下文可以 Push 多次 # 如果缺少 application context，会为每层都添加一个 self._implicit_app_ctx_stack = [] # 请求结束后，'after_request'执行前，执行 self._after_request_functions = [] # 调用 werkzeug.routing.MapAdapter().match # 对 request.url_rule/view_args，进行赋值 self.match_request() # _app_ctx_stack.top.g 处理 def push(self): """Binds the request context to the current context.""" top = _request_ctx_stack.top app_ctx = _app_ctx_stack.top if app_ctx is None or app_ctx.app != self.app: app_ctx = self.app.app_context() app_ctx.push() self._implicit_app_ctx_stack.append(app_ctx) else: self._implicit_app_ctx_stack.append(None) _request_ctx_stack.push(self) # 处理 self.session # 从 self.request.cookies 加载，没有则创建一个 NullSession def pop(self, exc=_sentinel): # exc 处理 # self.app.do_teardown_request(exc) rv = _request_ctx_stack.pop() assert rv is self, ... def auto_pop(self, exc): self.pop(exc) 说的好有道理，RequestContext(app, env)，包含了请求需要的全部信息。在请求前创建，并 push 到_request_ctx_stack，请求结束后，弹出。从代码中，还能看见另一个上下文_app_ctx_stack，即应用上下文。在创建请求上下文的同时，若_app_ctx_stack.top不存在，会先把self.app入栈。 那么，是时候看看这个ctx_stack是个什么东西。 Local12345678910111213141516171819try: from greenlet import getcurrent as get_identexcept ImportError: try: from thread import get_ident except ImportError: from _thread import get_identclass Local(object): def __init__(self): self.__storage__ = &#123;&#125; def __setattr__(self, name, value): ident = get_ident() storage = self.__storage__ try: storage[ident][name] = value except KeyError: storage[ident] = &#123;name: value&#125; 利用get_ident获取到协程/线程号，通过这个唯一id，在字典中实现线程安全。 LocalStack1234567891011121314151617181920212223class LocalStack(object): """ from werkzeug.local import LocalStack &gt;&gt;&gt; ls = LocalStack() &gt;&gt;&gt; ls.push(42) &gt;&gt;&gt; ls.top 42 &gt;&gt;&gt; ls.push(23) &gt;&gt;&gt; ls.top 23 &gt;&gt;&gt; ls.pop() 23 &gt;&gt;&gt; ls.top 42 """ def __init__(self): self._local = Local() def push(self, obj): rv = getattr(self._local, 'stack', None) if rv is None: self._local.stack = rv = [] rv.append(obj) return rv 在线程安全的基础上，用列表，实现栈操作。 ctx_stack123456789101112131415161718192021# flask.globalsdef _lookup_req_object(name): top = _request_ctx_stack.top if top is None: raise RuntimeError(_request_ctx_err_msg) return getattr(top, name)def _find_app(): top = _app_ctx_stack.top if top is None: raise RuntimeError(_app_ctx_err_msg) return top.app_request_ctx_stack = LocalStack()_app_ctx_stack = LocalStack()current_app = LocalProxy(_find_app)request = LocalProxy(partial(_lookup_req_object, 'request'))session = LocalProxy(partial(_lookup_req_object, 'session'))g = LocalProxy(partial(_lookup_app_object, 'g'))# LocalProxy 就是对象访问的代理封装 可见，经常使用的 request/session，都是线程安全的。并且，都是从最顶层请求上下文中获取到。 获取到上下文之后，自然继续执行wsgi_app()12response = self.full_dispatch_request()return response(environ, start_response) full_dispatch_request123456789101112131415def full_dispatch_request(self): # 处理第一个请求前置 func self.try_trigger_before_first_request_functions() try: # 发送信号 request-started request_started.send(self) # 调用 request 处理函数 rv = self.preprocess_request() if rv is None: # 根据 url_map，找到定义的 url 处理函数 rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) # 调用 make_response &amp; process_response return self.finalize_request(rv) 嗯，这个地方就是 Flask 的视图执行逻辑了。路由以及对应的装饰器函数，都在此处被执行。很明显，只要preprocess_request有返回结果，就会跳过定义的视图函数。整个运行期间，只要有错误，就会调用注册的错误处理函数。 注意，错中错在此处并没有捕捉，在最外层的 wsgi_app() 中进行了捕捉，然后会尝试调用注册的 500 错误处理过程。 preprocess_request123456789101112131415161718def preprocess_request(self): bp = _request_ctx_stack.top.request.blueprint # @url_value_preprocessor -&gt; &#123;None:[], bp:[]&#125; funcs = self.url_value_preprocessors.get(None, ()) if bp is not None and bp in self.url_value_preprocessors: funcs = chain(funcs, self.url_value_preprocessors[bp]) for func in funcs: func(request.endpoint, request.view_args) # @before_request -&gt; &#123;None:[], bp:[]&#125; funcs = self.before_request_funcs.get(None, ()) if bp is not None and bp in self.before_request_funcs: funcs = chain(funcs, self.before_request_funcs[bp]) for func in funcs: rv = func() if rv is not None: return rv 嗯，通过两个装饰器，在 view_func 之前运行指定函数。需要注意的是： 两个装饰器都以 blueprint 为单位，None 为所有 bp 共享 @url_value_preprocessor装饰的 func，接收两个参数，并且忽略返回值。通常用于对 url args 进行处理 @before_request装饰的 func，不接收参数，且只要有返回值，就直接 return。通常用于获取 db 连接，获取 session info 装饰器处理完，自然就开始执行真正匹配到的 view_func。 dispatch_request123456789101112def dispatch_request(self): req = _request_ctx_stack.top.request if req.routing_exception is not None: self.raise_routing_exception(req) rule = req.url_rule # 在 RequestContext 初始化时 创建 if getattr(rule, 'provide_automatic_options', False) \ and req.method == 'OPTIONS': return self.make_default_options_response() # 在 add_url_rule 填充 view_functions return self.view_functions[rule.endpoint](**req.view_args) 一目了然，通过 endpoint 获取到可调用对象，以关键字形式，传入 url 参数，返回结果。 接下来自然是 错误处理/返回结果。 handle_user_exception1234567891011121314def handle_user_exception(self, e): """ _find_error_handler(self, e).__doc__ Return a registered error handler for an exception in this order: blueprint handler for a specific code, app handler for a specific code, blueprint handler for an exception class, app handler for an exception class, or ``None`` if a suitable handler is not found. """ exc_type, exc_value, tb = sys.exc_info() # @errorhandler -&gt; error_handler_spec -&gt; &#123;bp:&#123;code:&#123;cls:func,..&#125;&#125;&#125; handler = self._find_error_handler(e) if handler is None: reraise(exc_type, exc_value, tb) return handler(e) 错误处理，会按照 code 优先，bp 优先的顺序寻找注册的错误处理函数，得到一个 rv。 finalize_request1234567891011121314def finalize_request(self, rv, from_error_handler=False): # 封装 Response() response = self.make_response(rv) try: # 调用 @after_request response = self.process_response(response) # 发送信号 request_finished.send(self, response=response) except Exception: if not from_error_handler: raise self.logger.exception('Request finalizing failed with an ' 'error while handling an error') return response 这个函数，会在两个地方被调用： 正常处理完，会被 full_dispatch_request 调用 执行 full_dispatch_request 报错，会被 wsgi_app 捕捉到，然后执行 handle_exception(内部错误)，被调用 process_response123456789101112131415161718192021def process_response(self, response): ctx = _request_ctx_stack.top bp = ctx.request.blueprint # @after_this_request -&gt; _after_request_functions -&gt; [] funcs = ctx._after_request_functions # @after_request -&gt; after_request_funcs -&gt; &#123;bp:&#123;&#125;, None:&#123;&#125;&#125; if bp is not None and bp in self.after_request_funcs: funcs = chain(funcs, reversed(self.after_request_funcs[bp])) if None in self.after_request_funcs: funcs = chain(funcs, reversed(self.after_request_funcs[None])) # 链式处理 response for handler in funcs: response = handler(response) # 处理 session if not self.session_interface.is_null_session(ctx.session): self.session_interface.save_session(self, ctx.session, response) return response 这里又有两个装饰器，其中一个很少用的是@after_this_request，它在 view_func 内部使用。 返回一个 Response 实例对象，回到 wsgi_app 中继续执行 return response(environ, start_response)。 Response1return response(environ, start_response) 我们已经知道，WSGI 规定 app 必须保证在 return iterable 之前，必须调用 start_response。那么，必然在 Response 中定义了 call 方法，并且会在其中调用 start_response。 12345678910class BaseResponse: def get_wsgi_response(self, environ): headers = self.get_wsgi_headers(environ) app_iter = self.get_app_iter(environ) return app_iter, self.status, headers.to_wsgi_list() def __call__(self, environ, start_response): app_iter, status, headers = self.get_wsgi_response(environ) start_response(status, headers) return app_iter 至此，Flask 作为 WSGI app 的整个流程已经走完。 小结123456789101112131415161718192021222324252627282930313233343536@app.route(&apos;/&apos;) 调用 add_url_rule()，填充 view_functions[endpoint] = view_func@app.errorhandler(404)@bp.errorhandler(ExceptionClass) 根据 code/cls，填充 error_handler_spec[None/bp] = &#123;code: &#123;cls: func&#125;&#125;@app.before_first_request before_first_request_funcs.append(f) 特点：不接收参数，且忽略返回值@app.url_value_preprocessor@bp.url_value_preprocessor url_value_preprocessors.setdefault(None/bp, []).append(func) 特点：func(request.endpoint, request.view_args)，忽略返回值@app.before_request@bp.before_request before_request_funcs.setdefault(None/bp, []).append(f) 特点：func()，具有 截取特性@app.after_request@bp.after_request after_request_funcs.setdefault(None/bp, []).append(f) 特点：response = handler(response)，具有叠加特性@app.teardown_request@bp.teardown_request teardown_request_funcs.setdefault(None/bp, []).append(f) 特点：called after each request, even if an exception has occurred. 在 RequestContext.pop() 时被调用，执行完后会发送信号`request_tearing_down`@app.teardown_appcontext teardown_appcontext_funcs.append(f) 特点：Called right before the application context is popped. 在 AppContext.pop() 是被调用，执行完后发送信号`appcontext_tearing_down` Flask is a microframework. 在内部大量使用装饰器，作为整个处理流程的中间环节。 利用 werkzeug 的 Request/Response，作为一进一出，配上一堆装饰器构成中间处理流程，这就是 Flask。微小，但包容。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】Django 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.4.Django%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[留坑，待上传]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】WSGI]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.1.WSGI%2F</url>
    <content type="text"><![CDATA[前言对一个 Python Web 开发者来说，PEP333/PEP3333，是必须熟悉的。都什么年代了，我们自然直接看 3333。 PEP 3333PEP3333，描述了 Web 服务器与 Python Web 应用程序或框架之间的建议标准接口，以促进跨各种 Web 服务器的应用程序的可移植性，形成类似于Java 的 “servlet” API。 CGI：Common Gateway Interface，通用网关接口 WSGI：(Python)Web Server Gateway Interface，Python服务器网关接口 接口说明WSGI 接口有两个方面：服务器/网关侧，以及应用程序/框架侧。服务器调用应用程序提供的可调用对象。提供该对象的具体方式取决于服务器或网关，可以通过脚本或配置文件的形式指定。可调用对象，是指一个函数/方法/具有__call__方法的实例。 为了适配 Py3 中的字符串 Unicode，WSGI 定义了两种字符串： Native字符串（str），用于请求/响应标头和元数据 Bytestrings(bytes)，用于请求响应体 这就要注意了，在 Py3 中，str对应UnicodeType，bytestring对应BytesType。而上述Native字符串，encode(‘latin-1’) 后得到 Bytestrings。意味着，str 虽然是 Unicode，但也只是支持ISO-8859-1编码部分(\u0000~\u00FF)。 应用程序侧应用程序/框架，提供给 Server 的可调用对象，接受两个位置参数environ/start_response 位置 1：environ，一个字典，封装了请求的相关信息 + CGI 风格的环境变量 位置 2：start_response，一个可调用对象，传入status, response_header[, exc_info]三个位置参数 status 是形如 200 OK 的状态字符串 headers 是一个元组列表，形如 [(header_name, header_value)]，注意大小写不敏感 可选参数 exc_info，在传递错误信息时使用 客户端侧，不使用start_response()的返回值 app(environ，start_response)返回一个能迭代出 bytestrings 的可迭代对象 应用程序必须保证，先调用 start_response，才迭代出 bytestrings 服务器侧在服务器侧最终的结果，是直接通过app(environ，start_response)得到 start_response 必须返回一个可调用对象，接收一个bytestring 对象作为参数 仅对响应内容进行编码传输，不更改内容，且不返回迭代器的任何属性 如果能够调用close(iterable)，服务器必须请求结束后调用该方法 WSGI服务器、网关和中间件不能拖延任何块的传输，要么立即发送块，要么保证应用程序侧连接不断开 中间件只要符合 WSGI 协议，就可以接入到整个应用链中。因此，诞生了中间件Middleware。其可以： 从 server 端接收，并改写信息，定位到不同的应用程序 从 app 端接收，改写信息，发送不同的格式内容 环境变量environ 字典中，不仅含有 CGI 中的部分参数，还包含 WSGI 定义的变量。 CGI 中的变量，注意也必须是 string 类型： REQUEST_METHOD： 请求方法，是个字符串，’GET’, ‘POST’等 SCRIPT_NAME： HTTP 请求的 path 中的用于查找到 app 对象的部分，比如 Web 服务器可以根据 path 的一部分来决定请求由哪个virtual host处理 PATH_INFO： HTTP 请求的 path 中剩余的部分，也就是 application 要处理的部分 QUERY_STRING： HTTP 请求中的查询字符串，URL中?后面的内容 CONTENT_TYPE： HTTP headers中的content-type内容 CONTENT_LENGTH： HTTP headers中的content-length内容 SERVER_NAME和SERVER_PORT： 服务器名和端口，这两个值和前面的SCRIPT_NAME, PATH_INFO拼起来可以得到完整的URL路径 SERVER_PROTOCOL： HTTP 协议版本，HTTP/1.0或者HTTP/1.1 HTTP_*： 和请求中的headers对应示例：1234567891011121314151617181920&quot;SERVER_NAME&quot;: &quot;DESKTOP&quot;,&quot;SERVER_PORT&quot;: &quot;8080&quot;,&quot;CONTENT_LENGTH&quot;: &quot;&quot;,&quot;SCRIPT_NAME&quot;: &quot;&quot;,&quot;SERVER_PROTOCOL&quot;: &quot;HTTP/1.1&quot;,&quot;SERVER_SOFTWARE&quot;: &quot;WSGIServer/0.2&quot;,&quot;REQUEST_METHOD&quot;: &quot;GET&quot;,&quot;QUERY_STRING&quot;: &quot;&quot;,&quot;CONTENT_TYPE&quot;: &quot;text/plain&quot;,&quot;HTTP_HOST&quot;: &quot;127.0.0.1:8080&quot;,&quot;HTTP_CONNECTION&quot;: &quot;keep-alive&quot;,&quot;HTTP_CACHE_CONTROL&quot;: &quot;max-age=0&quot;,&quot;HTTP_USER_AGENT&quot;: &quot;Mozilla/5.0 ,&quot;HTTP_UPGRADE_INSECURE_REQUESTS&quot;: &quot;1&quot;,&quot;HTTP_ACCEPT&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.8&quot;,&quot;HTTP_DNT&quot;: &quot;1&quot;,&quot;HTTP_ACCEPT_ENCODING&quot;: &quot;gzip, deflate, br&quot;,&quot;HTTP_ACCEPT_LANGUAGE&quot;: &quot;zh-CN,zh;q=0.9,ca;q=0.8&quot;,&quot;HTTP_COOKIE&quot;:&quot;csrftoken=w6V4gyp0o9doePer5oDrlDCwtxeaWxq&quot;, WSGI 变量： wsgi.version：表示WSGI版本，一个元组(1, 0)，表示版本1.0 wsgi.url_scheme：http或者https wsgi.input：一个类文件的输入流，application可以通过这个获取HTTP request body wsgi.errors：一个输出流，当应用程序出错时，可以将错误信息写入这里 wsgi.multithread：当application对象可能被多个线程同时调用时，这个值需要为True wsgi.multiprocess：当application对象可能被多个进程同时调用时，这个值需要为True wsgi.run_once：当server期望application对象在进程的生命周期内只被调用一次时，该值为True示例：12345678&quot;wsgi.input&quot;: &quot;&lt;_io.BufferedReader name=448&gt;&quot;,&quot;wsgi.errors&quot;: &quot;&lt;_io.TextIOWrapper name=&apos;&lt;stderr&gt;&apos; mode=&apos;w&apos; encoding=&apos;UTF-8&apos;&gt;&quot;,&quot;wsgi.version&quot;: &quot;(1, 0)&quot;,&quot;wsgi.run_once&quot;: &quot;False&quot;,&quot;wsgi.url_scheme&quot;: &quot;http&quot;,&quot;wsgi.multithread&quot;: &quot;True&quot;,&quot;wsgi.multiprocess&quot;: &quot;False&quot;,&quot;wsgi.file_wrapper&quot;: &quot;&lt;class &apos;wsgiref.util.FileWrapper&apos;&gt;&quot; DemoSimpleApp12345def simple_app(environ, start_response): status = '200 OK' response_headers = [('Content-type', 'text/html; charset=utf-8')] start_response(status, response_headers) return [b"&lt;h1&gt;Hello,world! I'm Lx.&lt;/h1&gt;"] SimpleServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import socketfrom io import StringIOimport sysimport datetimeimport osclass SimpleServer(object): def __init__(self, address, application): self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) self.socket.bind(address) self.socket.listen(1) self.host = address[0] self.port = address[1] self.application = application self.headers_set = [] def serve_forever(self): while True: self.connection, client_address = self.socket.accept() self.handle_request() def handle_request(self): request_data = self.connection.recv(1024).decode() self.get_url_parameter(request_data) result = self.application(self.get_environ(), self.start_response) self.finish_response(result) print(f"[&#123;time.strftime('%Y-%m-%d %H:%M:%S')&#125;]", f"&#123;self.request_headline&#125; &#123;self.headers_set[0]&#125;") def get_url_parameter(self, reqest_data): request_lines = reqest_data.splitlines() self.request_headline = request_lines[0] self.request_dict = &#123;'Path': request_lines[0]&#125; for itm in request_lines[1:]: if ':' in itm: self.request_dict[itm.split(':')[0]] = itm.split(':')[1] self.request_method, self.path, self.request_version = \ self.request_dict.get('Path').split() def get_environ(self): env = &#123; 'REQUEST_METHOD': self.request_method, 'PATH_INFO': self.path, 'SERVER_NAME': self.host, 'SERVER_PORT': str(self.port), 'USER_AGENT': self.request_dict.get('User-Agent') &#125; environ = dict(os.environ.items()) environ['wsgi.version'] = "(1, 0)", environ['wsgi.input'] = StringIO(), environ['wsgi.errors'] = sys.stderr environ['wsgi.version'] = (1, 0) environ['wsgi.multithread'] = False environ['wsgi.multiprocess'] = True environ['wsgi.run_once'] = True if environ.get('HTTPS', 'off') in ('on', '1'): environ['wsgi.url_scheme'] = 'https' else: environ['wsgi.url_scheme'] = 'http' environ.update(env) return environ def start_response(self, status, response_headers, exc_info=None): headers = [ ('Date', time.strftime('%a, %d %b %Y %H:%M:%S GMT')), ('Server', 'SimpleServer'), ] self.headers_set[:] = [status, response_headers + headers] def finish_response(self, app_data): try: response = 'HTTP/1.1 &#123;&#125;\r\n'.format(self.headers_set[0]) for header in self.headers_set[1]: response += '&#123;0&#125;: &#123;1&#125;\r\n'.format(*header) response += '\r\n' response = response.encode() if isinstance(app_data, bytes): response += app_data else: for info in app_data: response += info self.connection.sendall(response) finally: self.connection.close() SimpleServerApp1234def SimpleServerApp(): httpd = SimpleServer(('0.0.0.0', 8080), simple_app) print('WSGI Server Start Serving...http://127.0.0.1:8080') httpd.serve_forever() Middleware1234567891011121314151617181920212223242526272829import osfrom werkzeug.wrappers import Request, Responsefrom werkzeug.wsgi import SharedDataMiddlewareclass Shortly: def dispatch_request(self, request): response = Response() response.headers['Content-Type'] = 'text/html' if request.path == '/': response.data = '&lt;h1&gt;Hello World!&lt;/h1&gt;' else: response.data = "Path&gt;&gt;&gt;%s" % request.path return response def wsgi_app(self, environ, start_response): request = Request(environ) response = self.dispatch_request(request) return response(environ, start_response) def __call__(self, environ, start_response): return self.wsgi_app(environ, start_response)def create_app(with_static=True): app = Shortly() if with_static: app.wsgi_app = SharedDataMiddleware(app.wsgi_app, &#123; '/static': os.path.join(os.path.dirname(__file__), 'static') &#125;) return app]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>WSGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python 协程系列】asyncio 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F3.%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3%2F3.3.asyncio%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[参考资料 Library:asyncio PEP 3156 前言事件驱动主要是将耗时的 I/O 操作转换为待处理的事件，当某个事件触发后会调用相应的回调。 单线程中处理非常大的并发量 非同步运行，代码复杂，调试困难 遇到代码耗时操作/三方库阻塞，会导致整个事件循环阻塞 从 Py3.3 开始，代号 Tulip 的项目开始启动，一直到 Py3.6 才最终成为正式系统库——asyncio。该模块中提供了一些基础设施： event loop transport and protocol abstractions a higher-level schedule 从 demo 开始12345678910import asyncioasync def compute(x, y): print("Compute %s + %s ..." % (x, y)) await asyncio.sleep(1.0) return x + yloop = asyncio.get_event_loop()loop.run_until_complete(compute(1, 2))loop.close() 如上，利用async def 创建 Native Coroutine ，获取 event loop，执行 Coroutine，结束监听。 get_event_loop123456789101112131415161718192021222324# loop = asyncio.get_event_loop()def get_event_loop(): """ Return an asyncio event loop. """ # 利用 threading.local() 记录 running_loop, pid current_loop = _get_running_loop() if current_loop is not None: return current_loop # 默认为 DefaultEventLoopPolicy().get_event_loop() return get_event_loop_policy().get_event_loop()# windows_events.py.775class _WindowsDefaultEventLoopPolicy(events.BaseDefaultEventLoopPolicy): _loop_factory = SelectorEventLoopDefaultEventLoopPolicy = _WindowsDefaultEventLoopPolicy# unix_events.py.1083class _UnixDefaultEventLoopPolicy(events.BaseDefaultEventLoopPolicy): _loop_factory = _UnixSelectorEventLoop ...DefaultEventLoopPolicy = _UnixDefaultEventLoopPolicy 默认的 DefaultEventLoopPolicy 是一个区分平台的类，实例化后调用基类中的 get_event_loop 方法。1234567891011121314151617181920212223242526class BaseDefaultEventLoopPolicy(AbstractEventLoopPolicy): _loop_factory = None class _Local(threading.local): _loop = None _set_called = False def __init__(self): self._local = self._Local() def get_event_loop(self): if (self._local._loop is None and not self._local._set_called and isinstance(threading.current_thread(), threading._MainThread)): self.set_event_loop(self.new_event_loop()) if self._local._loop is None: raise RuntimeError('There is no current event loop in thread %r.' % threading.current_thread().name) return self._local._loop def set_event_loop(self, loop): self._local._set_called = True self._local._loop = loop def new_event_loop(self): return self._loop_factory() 在初始化后，同样产生一个线程变量来保存 loop。从代码中可以看出，仅主线程能自动产生 event_loop，对等线程尝试获取 loop 将报错。 1234567891011121314151617181920212223242526272829303132333435363738class _UnixDefaultEventLoopPolicy(events.BaseDefaultEventLoopPolicy): """UNIX event loop policy with a watcher for child processes.""" _loop_factory = _UnixSelectorEventLoop def __init__(self): super().__init__() self._watcher = None def _init_watcher(self): with events._lock: if self._watcher is None: # pragma: no branch self._watcher = SafeChildWatcher() if isinstance(threading.current_thread(), threading._MainThread): self._watcher.attach_loop(self._local._loop) def set_event_loop(self, loop): """Set the event loop. As a side effect, if a child watcher was set before, then calling .set_event_loop() from the main thread will call .attach_loop(loop) on the child watcher. """ super().set_event_loop(loop) if self._watcher is not None and \ isinstance(threading.current_thread(), threading._MainThread): self._watcher.attach_loop(loop) def get_child_watcher(self): if self._watcher is None: self._init_watcher() return self._watcher def set_child_watcher(self, watcher): if self._watcher is not None: self._watcher.close() self._watcher = watcher 在 Unix 平台上，_UnixDefaultEventLoopPolicy 对基类的set_event_loop进行了覆盖。增加了对子进程的 watcher。若提前在对等线程中执行了_watcher=SafeChildWatcher()，在主线程 set loop 时，会调用 attach_loop，添加信号处理机制。 最终返回的 loop，是一个 _UnixSelectorEventLoop 实例对象。 Loop 实例化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class _UnixSelectorEventLoop(selector_events.BaseSelectorEventLoop): """Unix event loop. Adds signal handling and UNIX Domain Socket support to SelectorEventLoop. """ def __init__(self, selector=None): super().__init__(selector) self._signal_handlers = &#123;&#125;class BaseSelectorEventLoop(base_events.BaseEventLoop): """Selector event loop. See events.EventLoop for API specification. """ def __init__(self, selector=None): super().__init__() if selector is None: """ if 'KqueueSelector' in globals(): DefaultSelector = KqueueSelector elif 'EpollSelector' in globals(): DefaultSelector = EpollSelector elif 'DevpollSelector' in globals(): DefaultSelector = DevpollSelector elif 'PollSelector' in globals(): DefaultSelector = PollSelector else: DefaultSelector = SelectSelector """ selector = selectors.DefaultSelector() logger.debug('Using selector: %s', selector.__class__.__name__) self._selector = selector self._make_self_pipe() self._transports = weakref.WeakValueDictionary()class BaseEventLoop(events.AbstractEventLoop): def __init__(self): self._timer_cancelled_count = 0 self._closed = False self._stopping = False self._ready = collections.deque() self._scheduled = [] self._default_executor = None self._internal_fds = 0 # Identifier of the thread running the event loop, or None if the # event loop is not running self._thread_id = None self._clock_resolution = time.get_clock_info('monotonic').resolution self._exception_handler = None self.set_debug((not sys.flags.ignore_environment and bool(os.environ.get('PYTHONASYNCIODEBUG')))) # In debug mode, if the execution of a callback or a step of a task # exceed this duration in seconds, the slow callback/task is logged. self.slow_callback_duration = 0.1 self._current_handle = None self._task_factory = None self._coroutine_wrapper_set = False if hasattr(sys, 'get_asyncgen_hooks'): # Python &gt;= 3.6 # A weak set of all asynchronous generators that are # being iterated by the loop. self._asyncgens = weakref.WeakSet() else: self._asyncgens = None # Set to True when `loop.shutdown_asyncgens` is called. self._asyncgens_shutdown_called = False 在 _UnixSelectorEventLoop 实例化过程中： events.AbstractEventLoop 定义了抽象类接口 BaseEventLoop 实现抽象类接口，定义了大量的状态量 BaseSelectorEventLoop 创建 selector，实现kqueue/epoll/pool等 _UnixSelectorEventLoop 添加了一些信号处理及 UNIX 套接字支持 run_until_complete123456789101112131415161718192021222324252627282930313233# loop.run_until_complete(compute(1, 2))class BaseEventLoop(events.AbstractEventLoop): def run_until_complete(self, future): # assert not self._closed self._check_closed() # new_task = True # if obj is not a Future instance # 或设置了 obj._asyncio_future_blocking new_task = not futures.isfuture(future) # 返回一个 Future 对象 future = tasks.ensure_future(future, loop=self) if new_task: future._log_destroy_pending = False # 添加回调, pool.stop() future.add_done_callback(_run_until_complete_cb) try: self.run_forever() except: if new_task and future.done() and not future.cancelled(): # The coroutine raised a BaseException. Consume the exception # to not log a warning, the caller doesn't have access to the # local task. future.exception() raise finally: future.remove_done_callback(_run_until_complete_cb) if not future.done(): raise RuntimeError('Event loop stopped before Future completed.') return future.result() 从代码中可以看出，最终还是调用run_forever来执行事件。run until通过添加回调，当指定 Future 完成后，结束整个 pool。 ensure_future12345678910111213141516171819202122232425262728293031323334353637def ensure_future(coro_or_future, *, loop=None): if futures.isfuture(coro_or_future): # 已经是 Future 对象，直接返回 if loop is not None and loop is not coro_or_future._loop: # Future 对象不能绑定不同 loop raise ValueError('loop argument must agree with Future') return coro_or_future elif coroutines.iscoroutine(coro_or_future): # Coro ，返回一个 Task 对象，Future 的子类 if loop is None: loop = events.get_event_loop() task = loop.create_task(coro_or_future) if task._source_traceback: del task._source_traceback[-1] return task elif compat.PY35 and inspect.isawaitable(coro_or_future): # awaitable 对象，封装成 Coro，调用其 __await__ 方法 return ensure_future(_wrap_awaitable(coro_or_future), loop=loop) else: raise TypeError('An asyncio.Future, a coroutine or an awaitable is ' 'required')class BaseEventLoop(events.AbstractEventLoop): def create_task(self, coro): self._check_closed() if self._task_factory is None: # 实例化过程中，在 pool._ready 中放入封装的 handler() task = tasks.Task(coro, loop=self) if task._source_traceback: del task._source_traceback[-1] else: task = self._task_factory(self, coro) return task@coroutinedef _wrap_awaitable(awaitable): return (yield from awaitable.__await__()) 在 ensure_future 中隐藏了非常重要的代码：如何将 coro 与 pool 关联起来。 Task(coro, loop=self)1234567891011121314151617181920212223242526272829303132# tasks.Task(coro, loop=self)class Task(futures.Future): def __init__(self, coro, *, loop=None): super().__init__(loop=loop) self._coro = coro self._loop.call_soon(self._step) # Weak set containing all tasks alive. self.__class__._all_tasks.add(self)class Future: def __init__(self, *, loop=None): if loop is None: self._loop = events.get_event_loop() else: self._loop = loop self._callbacks = []class BaseEventLoop(events.AbstractEventLoop): def call_soon(self, callback, *args): self._check_closed() handle = self._call_soon(callback, args) if handle._source_traceback: del handle._source_traceback[-1] return handle def _call_soon(self, callback, args): handle = events.Handle(callback, args, self) if handle._source_traceback: del handle._source_traceback[-1] self._ready.append(handle) return handle Task 是 Future 的子类，在实例化过程中： 将 loop/coro 保存在 Task 属性中 通过loop.call_soon(task._step)，将task._step()作为回调，传入到 loop 中 将task._step封装成 Handle 对象，放入 Loop._ready 双端队列 add_done_callback12345678910111213141516# future.add_done_callback(_run_until_complete_cb)def _run_until_complete_cb(fut): fut._loop.stop() # pool._stopping = Trueclass Future: def add_done_callback(self, fn): """Add a callback to be run when the future becomes done. The callback is called with a single argument - the future object. If the future is already done when this is called, the callback is scheduled with call_soon. """ if self._state != _PENDING: self._loop.call_soon(fn, self) else: self._callbacks.append(fn) 此处，注册回调，在 Future 完成后，stop event loop。 run_forever12345678910111213141516171819202122232425262728293031class BaseEventLoop(events.AbstractEventLoop): def run_forever(self): # 1. 状态检查 self._check_closed() if self.is_running(): raise RuntimeError('This event loop is already running') if events._get_running_loop() is not None: raise RuntimeError( 'Cannot run the event loop while another loop is running') # 2. 准备环境 self._set_coroutine_wrapper(self._debug) self._thread_id = threading.get_ident() if self._asyncgens is not None: old_agen_hooks = sys.get_asyncgen_hooks() sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook, finalizer=self._asyncgen_finalizer_hook) try: events._set_running_loop(self) while True: # 3. 执行调度 self._run_once() if self._stopping: break finally: # 4. 退出 self._stopping = False self._thread_id = None events._set_running_loop(None) self._set_coroutine_wrapper(False) if self._asyncgens is not None: sys.set_asyncgen_hooks(*old_agen_hooks) 在run_forever中，通过while True不断的执行run_once方法，完成整个事件驱动的循环调度。通过_stopping属性，控制循环的退出。 _run_once12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class BaseEventLoop(events.AbstractEventLoop): def __init__(self): self._timer_cancelled_count = 0 self._ready = collections.deque() self._scheduled = [] def _run_once(self): sched_count = len(self._scheduled) if (sched_count &gt; _MIN_SCHEDULED_TIMER_HANDLES and # 100 self._timer_cancelled_count / sched_count &gt; _MIN_CANCELLED_TIMER_HANDLES_FRACTION): # 0.5 # Remove delayed calls that were cancelled if their number # is too high new_scheduled = [] for handle in self._scheduled: if handle._cancelled: handle._scheduled = False else: new_scheduled.append(handle) heapq.heapify(new_scheduled) self._scheduled = new_scheduled self._timer_cancelled_count = 0 else: # Remove delayed calls that were cancelled from head of queue. while self._scheduled and self._scheduled[0]._cancelled: self._timer_cancelled_count -= 1 handle = heapq.heappop(self._scheduled) handle._scheduled = False # 省略了 debug, timeout 处理 timeout = 0 # 调用 pool/epoll 等，得到 [(key, mask),] 事件列表 event_list = self._selector.select(timeout) # 遍历 event_list，根据 mask 调用 Loop.remove / Loop._add_callback # 在 _add_callback 中会调用 Loop._ready.append(handle) self._process_events(event_list) # Handle 'later' callbacks that are ready. end_time = self.time() + self._clock_resolution while self._scheduled: handle = self._scheduled[0] if handle._when &gt;= end_time: break handle = heapq.heappop(self._scheduled) handle._scheduled = False self._ready.append(handle) # This is the only place where callbacks are actually *called*. # All other places just add them to ready. ntodo = len(self._ready) for i in range(ntodo): handle = self._ready.popleft() if handle._cancelled: continue # 省略了 debug 处理 handle._run() handle = None # Needed to break cycles when an exception occurs. 在 Task 实例化过程中，已经将task._step封装成 handler 放入了 _ready 队列中。在 _run_once 中，取出 handle 执行 run 方法。 handle._run()12345678910111213141516class Handle: def _run(self): try: self._callback(*self._args) except Exception as exc: cb = _format_callback_source(self._callback, self._args) msg = 'Exception in callback &#123;&#125;'.format(cb) context = &#123; 'message': msg, 'exception': exc, 'handle': self, &#125; if self._source_traceback: context['source_traceback'] = self._source_traceback self._loop.call_exception_handler(context) self = None # Needed to break cycles when an exception occurs. 可见 handler._run，实际上就是执行 callback。对于封装的 Task，此处将执行 Task()._step()方法。 task._step12345678910111213141516171819202122232425262728293031323334# Task(coro, loop=self)class Task(futures.Future): def _step(self, exc=None): coro = self._coro self.__class__._current_tasks[self._loop] = self # Call either coro.throw(exc) or coro.send(None). try: if exc is None: # We use the `send` method directly, because coroutines # don't have `__iter__` and `__next__` methods. result = coro.send(None) else: result = coro.throw(exc) except StopIteration as exc: if self._must_cancel: # Task is cancelled right before coro stops. self._must_cancel = False self.set_exception(futures.CancelledError()) else: # 会调用 self._schedule_callbacks() self.set_result(exc.value) except futures.CancelledError: super().cancel() # I.e., Future.cancel(self). except Exception as exc: self.set_exception(exc) except BaseException as exc: self.set_exception(exc) raise else: ... finally: self.__class__._current_tasks.pop(self._loop) self = None # Needed to break cycles when an exception occurs. 在 task.step 中，会执行 coro.send(None)，进入到协程代码执行阶段。代码正常执行完，会raise StopIteration(val)，然后进入到 set_result环节。 在future.set_result()中，将该 future 注册的所有回调，通过 loop.call_soon 放入执行队列，等待执行。例如，run_until_complete 中，注册了回调_run_until_complete_cb，执行后将退出 loop 循环。 asyncio.sleep(1.0)123456789101112131415161718192021222324252627282930313233343536373839404142# await asyncio.sleep(1.0)@coroutinedef sleep(delay, result=None, *, loop=None): """Coroutine that completes after a given time (in seconds).""" if delay == 0: yield return result if loop is None: loop = events.get_event_loop() # futures.Future(loop=self) future = loop.create_future() # def call_later(self, delay, callback, *args) h = future._loop.call_later(delay, futures._set_result_unless_cancelled, future, result) try: return (yield from future) finally: h.cancel()class BaseEventLoop(events.AbstractEventLoop): def call_at(self, when, callback, *args): self._check_closed() timer = events.TimerHandle(when, callback, args, self) heapq.heappush(self._scheduled, timer) timer._scheduled = True return timer def call_later(self, delay, callback, *args): timer = self.call_at(self.time() + delay, callback, *args) return timerdef _set_result_unless_cancelled(fut, result): if fut.cancelled(): return # fut._result = result # fut._state = _FINISHED fut.set_result(result) 我们已经知道，await AwaitableObject，会挂起协程，直到 AwaitableObject 运行结束。执行 asyncio.sleep(1.0)： 创建一个 future 对象 通过 loop.call_later 创建一个 TimerHandle() 对象 将 time 的回调置为 _set_result_unless_cancelled 将 time 放入 loop._scheduled 数组，等待 1s 后触发，执行 执行后，将传入的 result 赋值给 future._result 在等待的时间内，将继续执行代码yield from future yield from future回忆下，字节码YIELD_FROM的执行逻辑：123456789101112131415TARGET(YIELD_FROM) &#123; PyObject *v = POP(); PyObject *receiver = TOP(); if (PyGen_CheckExact(receiver) || PyCoro_CheckExact(receiver)) &#123; // 如果是 generaotr / corotine，调用 Send() retval = _PyGen_Send((PyGenObject *)receiver, v); &#125; else &#123; // 其他 Awaitable 对象，迭代下一个元素 _Py_IDENTIFIER(send); if (v == Py_None) retval = Py_TYPE(receiver)-&gt;tp_iternext(receiver); else retval = _PyObject_CallMethodIdObjArgs(receiver, &amp;PyId_send, v, NULL); &#125;&#125; 在看下 Future 的定义：12345678910class Future: def __iter__(self): if not self.done(): self._asyncio_future_blocking = True yield self # This tells Task to wait for completion. assert self.done(), "yield from wasn't used with future" return self.result() # May raise too. if compat.PY35: __await__ = __iter__ # make compatible with 'await' expression 在 compute() 中 await asyncio.sleep(1.0)，然后又yield from future 在 Future 中，如果未 done，将一直 yield self 当 event loop 监听到 timer 触发，将在run_once中执行 timer._run 最终执行Future.set_result(result)，改变 future 状态，return result asyncio.sleep 创建的 futer，至此完全结束，返回 await 位置，继续执行。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>coroutine</tag>
        <tag>asyncio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python 协程系列】Python 原生协程]]></title>
    <url>%2F2018%2F09%2F12%2F3.%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3%2F3.2.Python%20%E5%8E%9F%E7%94%9F%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[参考资料 Data Model PEP492 PEP525 前言1234567891011121314PEP 255 -- Simple GeneratorsPython-Version: 2.2PEP 342 -- Coroutines via Enhanced GeneratorsPython-Version: 2.5PEP 380 -- Syntax for Delegating to a SubgeneratorPython-Version: 3.3PEP 492 -- Coroutines with async and await syntaxPython-Version: 3.5PEP 525 -- Asynchronous GeneratorsPython-Version: 3.6 emm…上面算是 Python 中 Coroutines 的发展史了，具体内容可以参考 PEP。 名词解释Generator1234567891011def _g(): yield 1GeneratorType = type(_g())Generator functions A function or method which uses the yield statement. 不能 yield from Native corotine When called always returns an iterator object.iterator 通过 iterator.__next__() 方法，执行 body 直到 yield Native coroutine1234567891011async def _c(): passCoroutineType = type(_c())Coroutine functions A function or method which is defined using async def. When called always returns an coroutine object.Coroutine Objects 是 awaitable，可以调用 __await__() 不支持 __iter__ 、__next__ 、迭代 Asynchronous generator、1234567async def _ag(): yieldAsyncGeneratorType = type(ag())Asynchronous generator functions 同时使用 async def + yield When called always returns an asynchronous iterator object. Asynchronous iterator1234567Asynchronous iterable 异步可迭代对象，定义了 __aiter__ 方法，可以用作 asycn for 返回一个异步迭代器Asynchronous iterator 异步迭代器，定义了 __anext__ 方法，返回一个 awaitable 类似的 class 同时定义 aiter + anext，既是异步可迭代，又是异步迭代器 1234567891011121314151617181920212223242526272829303132333435363738# 定义对象class AsyncIterable: # 实现 __aiter__、__anext__方法 # 或者 C_API：tp_as_async.am_aiter/am_anext # 停止迭代 must raise StopAsyncIteration def __aiter__(self): return self async def __anext__(self): data = await self.fetch_data() if data: return data else: raise StopAsyncIteration async def fetch_data(self): ...# 迭代，并且支持 async for-else 逻辑async for TARGET in ITER: BLOCKelse: BLOCK2# 执行逻辑iter = (ITER)iter = type(iter).__aiter__(iter)running = Truewhile running: try: TARGET = await type(iter).__anext__(iter) except StopAsyncIteration: running = False else: BLOCKelse: BLOCK2 Generator-based coroutine12345678910111213@types.coroutinedef gen(): yield 1Generator-based coroutine function 被 @types.coroutine 装饰的 generaotr func 可以使用 yield from Native corotine 执行了 func.__code__.co_flags |= CO_ITERABLE_COROUTINE When called 返回一个 Generator-based coroutineGenerator-based coroutine Returned from a generator-based coroutine function. Coroutine1234Coroutine object Co-routine 协作式例程，简称 协程 Either native coroutine object or generator-based coroutine object. 必须使用 an event loop or a scheduler to run coroutines. Future-like object1234567Future-like object 定义了 __await__ 方法，或 tp_as_async-&gt;am_await 方法 returning an iterator. 可以在 coroutine 中被 await 消费 执行 await Future-like-obj 会一直挂起，直到 __await__ 方法完成 and returns the result. Awaitable123456789101112131415Awaitable def isawaitable(object): &quot;&quot;&quot; 改动自 inspect.isawaitable() &quot;&quot;&quot; # Native coroutine a = isinstance(object, types.CoroutineType) # Generator-based coroutine b = isinstance(object, types.GeneratorType) and bool(object.gi_code.co_flags &amp; CO_ITERABLE_COROUTINE) # Future-like object c = isinstance(object, collections.abc.Awaitable) return a or b or c Asynchronous context manager异步上下文管理求，定义了 __aenter__ and __aexit__ 方法，可以用作 async with。12345678910111213141516171819202122232425262728293031323334353637383940# 定义管理器class AsyncContextManager: async def __aenter__(self): await log('entering context') async def __aexit__(self, exc_type, exc, tb): await log('exiting context') # __aenter__ and __aexit__. Both must return an awaitable.# 实现async with EXPR as VAR: BLOCK# 执行逻辑mgr = (EXPR)aexit = type(mgr).__aexit__aenter = type(mgr).__aenter__(mgr)VAR = await aentertry: BLOCKexcept: if not await aexit(mgr, *sys.exc_info()): raiseelse: await aexit(mgr, None, None, None)# It is a SyntaxError to use async with outside of an async def function.# demoasync def commit(session, data): ... async with session.transaction(): ... await session.update(data) ... async with lock: ... 生成器12345678910111213141516171819def gen_func(): result1 = yield 'yield-1' print(f'result 1: &#123;result1&#125;') result2 = yield 'yield-2' print(f'result 2: &#123;result2&#125;')gen = gen_func()import inspect; assert inspect.isgeneratorfunction(gen_func)import types; assert isinstance(gen, types.GeneratorType)print(gen.send(None))print(gen.send('send-1'))try: gen.throw(GeneratorExit)except (StopIteration, GeneratorExit): passelse: raise RuntimeError("generator ignored GeneratorExit") 先看看数据结构吧。 PyGen_Type123456789101112131415161718# genobject.c.737static PyMethodDef gen_methods[] = &#123; &#123;&quot;send&quot;,(PyCFunction)_PyGen_Send, METH_O, send_doc&#125;, &#123;&quot;throw&quot;,(PyCFunction)gen_throw, METH_VARARGS, throw_doc&#125;, &#123;&quot;close&quot;,(PyCFunction)gen_close, METH_NOARGS, close_doc&#125;, &#123;NULL, NULL&#125; /* Sentinel */&#125;;PyTypeObject PyGen_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) &quot;generator&quot;, /* tp_name */ sizeof(PyGenObject), /* tp_basicsize */ 0, /* tp_as_async */ PyObject_SelfIter, /* tp_iter */ (iternextfunc)gen_iternext, /* tp_iternext */ gen_methods, /* tp_methods */&#125;; PyGenObject123456789101112131415161718192021/* _PyGenObject_HEAD defines the initial segment of generator and coroutine objects. */#define _PyGenObject_HEAD(prefix) \ PyObject_HEAD \ /* Note: gi_frame can be NULL if the generator is "finished" */ \ struct _frame *prefix##_frame; \ /* True if generator is being executed. */ \ char prefix##_running; \ /* The code object backing the generator */ \ PyObject *prefix##_code; \ /* List of weak reference. */ \ PyObject *prefix##_weakreflist; \ /* Name of the generator. */ \ PyObject *prefix##_name; \ /* Qualified name of the generator. */ \ PyObject *prefix##_qualname;typedef struct &#123; /* The gi_ prefix is intended to remind of generator-iterator. */ _PyGenObject_HEAD(gi)&#125; PyGenObject; PyGen_New1234567891011121314151617181920212223242526// genobject.c.833PyObject * PyGen_New(PyFrameObject *f) &#123; return gen_new_with_qualname(&amp;PyGen_Type, f, NULL, NULL);&#125;static PyObject *gen_new_with_qualname(PyTypeObject *type, PyFrameObject *f, PyObject *name, PyObject *qualname)&#123; PyGenObject *gen = PyObject_GC_New(PyGenObject, type); gen-&gt;gi_frame = f; f-&gt;f_gen = (PyObject *) gen; // 记录在案！ gen-&gt;gi_code = (PyObject *)(f-&gt;f_code); gen-&gt;gi_running = 0; // 未执行 gen-&gt;gi_weakreflist = NULL; if (name != NULL) gen-&gt;gi_name = name; else gen-&gt;gi_name = ((PyCodeObject *)gen-&gt;gi_code)-&gt;co_name; if (qualname != NULL) gen-&gt;gi_qualname = qualname; else gen-&gt;gi_qualname = gen-&gt;gi_name; _PyObject_GC_TRACK(gen); // 挂载到 GC 链 return (PyObject *)gen;&#125; 简单的把 Frame-&gt;code_obj，封装成 GenObj，同时关联到 Frame-&gt;f_gen 上。 这里必须复习下 PyFrameObject:123456789101112131415161718192021222324252627typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* PyCodeObject 对象 */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* 运行时栈 栈底 */ PyObject **f_stacktop; /* 运行时栈 栈顶 */ PyObject *f_trace; /* Trace function */ /* 用于 generator 交换错误信息 */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; /* Borrowed reference to a generator, or NULL */ PyObject *f_gen; int f_lasti; /* 上一条字节码指令在 f_code 中的偏移位置 */ int f_lineno; /* 当前字节码，对应源代码行号 通过 PyFrame_GetLineNumber() 调用*/ int f_iblock; /* index in f_blockstack */ char f_executing; /* whether the frame is still executing */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* block 堆栈 */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; PyGen_Send123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146PyObject * _PyGen_Send(PyGenObject *gen, PyObject *arg) &#123; return gen_send_ex(gen, arg, 0, 0);&#125;static PyObject *gen_send_ex(PyGenObject *gen, PyObject *arg, int exc, int closing)&#123; PyThreadState *tstate = PyThreadState_GET(); PyFrameObject *f = gen-&gt;gi_frame; PyObject *result; /* `gen` is either: * a generator with CO_FUTURE_GENERATOR_STOP flag; * a coroutine; * a generator with CO_ITERABLE_COROUTINE flag (decorated with types.coroutine decorator); * an async generator. */ if (gen-&gt;gi_running) &#123; // 有意思，Gen / Coro / AsyncGen 都走这里 char *msg = "generator already executing"; if (PyCoro_CheckExact(gen)) &#123; msg = "coroutine already executing"; &#125; else if (PyAsyncGen_CheckExact(gen)) &#123; msg = "async generator already executing"; &#125; PyErr_SetString(PyExc_ValueError, msg); return NULL; &#125; if (f == NULL || f-&gt;f_stacktop == NULL) &#123; if (PyCoro_CheckExact(gen) &amp;&amp; !closing) &#123; /* `gen` is an exhausted coroutine: raise an error, except when called from gen_close(), which should always be a silent method. */ PyErr_SetString( PyExc_RuntimeError, "cannot reuse already awaited coroutine"); &#125; else if (arg &amp;&amp; !exc) &#123; /* `gen` is an exhausted generator: only set exception if called from send(). */ if (PyAsyncGen_CheckExact(gen)) &#123; PyErr_SetNone(PyExc_StopAsyncIteration); &#125; else &#123; PyErr_SetNone(PyExc_StopIteration); &#125; &#125; return NULL; &#125; if (f-&gt;f_lasti == -1) &#123; /* 上一条字节码指令在 f_code 中的偏移位置，即 gen 未曾执行 */ if (arg &amp;&amp; arg != Py_None) &#123; // 第一次只能 send(None) char *msg = "can't send non-None value to a " "just-started generator"; if (PyCoro_CheckExact(gen)) &#123; msg = NON_INIT_CORO_MSG; &#125; else if (PyAsyncGen_CheckExact(gen)) &#123; msg = "can't send non-None value to a " "just-started async generator"; &#125; PyErr_SetString(PyExc_TypeError, msg); return NULL; &#125; &#125; else &#123; /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); *(f-&gt;f_stacktop++) = result; &#125; /* Generators always return to their most recent caller, not * necessarily their creator. */ Py_XINCREF(tstate-&gt;frame); assert(f-&gt;f_back == NULL); f-&gt;f_back = tstate-&gt;frame; // 构建 frame 链，准备执行函数调用 /* 更改状态，在新的 Frame 下执行 */ gen-&gt;gi_running = 1; result = PyEval_EvalFrameEx(f, exc); // 执行 gen 代码 gen-&gt;gi_running = 0; /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f-&gt;f_back == tstate-&gt;frame); Py_CLEAR(f-&gt;f_back); if (result &amp;&amp; f-&gt;f_stacktop == NULL) &#123; /* Case 1. 处理 return 而不是 yield */ if (result == Py_None) &#123; /* Delay exception instantiation if we can */ if (PyAsyncGen_CheckExact(gen)) &#123; PyErr_SetNone(PyExc_StopAsyncIteration); &#125; else &#123; PyErr_SetNone(PyExc_StopIteration); &#125; &#125; else &#123; /* Async generators 只能 return None */ assert(!PyAsyncGen_CheckExact(gen)); _PyGen_SetStopIterationValue(result); &#125; Py_CLEAR(result); &#125; else if (!result &amp;&amp; PyErr_ExceptionMatches(PyExc_StopIteration)) &#123; ... /* Case 2. 处理 raise StopIteration Check 是否 from __future__ import generator_stop PEP479: 在 Gen 中 raise StopIteration 会被转换为 RuntimeError Py3.5 利用 generator_stop 实现 Py3.6 会发出警告 Py3.7 会默认生效 */ &#125; else if (PyAsyncGen_CheckExact(gen) &amp;&amp; !result &amp;&amp; PyErr_ExceptionMatches(PyExc_StopAsyncIteration)) &#123; /* Case 3. 处理 AsyncGen 中 raise StopAsyncIteration */ const char *msg = "async generator raised StopAsyncIteration"; _PyErr_FormatFromCause(PyExc_RuntimeError, "%s", msg); &#125; if (!result || f-&gt;f_stacktop == NULL) &#123; /* 生成器结束，销毁 freame */ PyObject *t, *v, *tb; t = f-&gt;f_exc_type; v = f-&gt;f_exc_value; tb = f-&gt;f_exc_traceback; f-&gt;f_exc_type = NULL; f-&gt;f_exc_value = NULL; f-&gt;f_exc_traceback = NULL; Py_XDECREF(t); Py_XDECREF(v); Py_XDECREF(tb); gen-&gt;gi_frame-&gt;f_gen = NULL; gen-&gt;gi_frame = NULL; Py_DECREF(f); &#125; return result;&#125; CodeObject123456789101112131415161718192021# t.pydef gen(): yield 1&gt;&gt;&gt; co = compile(open(&apos;t.py&apos;).read(),&apos;t.py&apos;,&apos;exec&apos;); import dis; dis.dis(co) 1 0 LOAD_CONST 0 (&lt;code object gen at 0x0000028821955270, file &quot;t.py&quot;, line 1&gt;) 2 LOAD_CONST 1 (&apos;gen&apos;) 4 MAKE_FUNCTION 0 6 STORE_NAME 0 (gen) 8 LOAD_CONST 2 (None) 10 RETURN_VALUE&gt;&gt;&gt; gen = co.co_consts[0]; dis.dis(gen) 2 0 LOAD_CONST 1 (1) 2 YIELD_VALUE 4 POP_TOP 6 LOAD_CONST 0 (None) 8 RETURN_VALUE.. opcode:: YIELD_VALUE Pops TOS and yields it from a :term:`generator`. 看看YIELD_VALUE会干些什么。 YIELD_VALUE12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)&#123; PyThreadState *tstate = PyThreadState_GET(); return tstate-&gt;interp-&gt;eval_frame(f, throwflag);&#125;PyObject *_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)&#123; /* 通过 f-&gt;f_lasti 记录了字节码执行位置 通过 f-&gt;f_stacktop 记录栈帧位置 实现，生成器的 send/yield */ next_instr = first_instr; // 指向 co-&gt;co_code if (f-&gt;f_lasti &gt;= 0) &#123; // f-&gt;f_lasti 记录了上一条指令偏移量 next_instr += f-&gt;f_lasti / sizeof(_Py_CODEUNIT) + 1; &#125; stack_pointer = f-&gt;f_stacktop; f-&gt;f_stacktop = NULL; /* remains NULL unless yield suspends frame */ f-&gt;f_executing = 1; if (co-&gt;co_flags &amp; (CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR)) &#123; // 生成器在 except 中 if (!throwflag &amp;&amp; f-&gt;f_exc_type != NULL &amp;&amp; f-&gt;f_exc_type != Py_None) &#123; // 从 caller 中，获取 exc 信息 swap_exc_state(tstate, f); &#125; else save_exc_state(tstate, f); &#125; for (;;) &#123; switch (opcode) &#123; TARGET(YIELD_VALUE) &#123; retval = POP(); if (co-&gt;co_flags &amp; CO_ASYNC_GENERATOR) &#123; PyObject *w = _PyAsyncGenValueWrapperNew(retval); retval = w; &#125; f-&gt;f_stacktop = stack_pointer; why = WHY_YIELD; goto fast_yield; &#125; &#125;fast_yield: if (co-&gt;co_flags &amp; (CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR)) &#123; /* 遍历所有 block, 查找是否在 except 中 */ int i; for (i = 0; i &lt; f-&gt;f_iblock; i++) &#123; if (f-&gt;f_blockstack[i].b_type == EXCEPT_HANDLER) &#123; break; &#125; &#125; if (i == f-&gt;f_iblock) // generator 不保存 caller 的 exc 信息 restore_and_clear_exc_state(tstate, f); else swap_exc_state(tstate, f); &#125; if (tstate-&gt;use_tracing) &#123; ... &#125; /* pop frame */exit_eval_frame: if (PyDTrace_FUNCTION_RETURN_ENABLED()) dtrace_function_return(f); Py_LeaveRecursiveCall(); f-&gt;f_executing = 0; tstate-&gt;frame = f-&gt;f_back; return _Py_CheckFunctionResult(NULL, retval, "PyEval_EvalFrameEx");&#125; 小结1234567891011121314151617181920212223242526PyGen_New(FrameObject f) gen-&gt;gi_frame = f; f-&gt;f_gen = (PyObject *) gen; // 记录在案！ gen-&gt;gi_code = (PyObject *)(f-&gt;f_code);创建 Generator 时： 会将当前 Frame 作为参数传入 并且将 Frame 固定在新创建的 gen 上PyGen_Send(PyGenObject *gen, PyObject *arg) PyFrameObject *f = gen-&gt;gi_frame; result = PyEval_EvalFrameEx(f, exc); PyEval_EvalFrameEx -&gt; PyEval_EvalFrameDefault: if (f-&gt;f_lasti &gt;= 0) &#123; next_instr += f-&gt;f_lasti / sizeof(_Py_CODEUNIT) + 1; &#125; yield: tstate-&gt;frame = f-&gt;f_back; retrun result if (result &amp;&amp; f-&gt;f_stacktop == NULL) &#123; 释放资源 &#125; return result执行 gen.send() ： 会提取 gen-&gt;gi_frame，调用 EvalFrame 执行字节码 通过 f-&gt;f_lasti，记录当前执行的位置 遇到 yield，会将线程对应的 Frame 切换到 gen 的 caller if gen 消耗完，会在 PyGen_Send 中释放 gen-&gt;frame, gen自身 从 PyGen_Send 中 return result 到 caller Native 协程1234567891011121314151617import collections, inspectasync def func(): print(1)async def native_co_func(): print(0) await func()native_co = native_co_func()assert isinstance(native_co, collections.Coroutine)assert inspect.isawaitable(native_co)try: native_co.send(None)except StopIteration: pass Native Coroutines(原生协程)，源自 PEP 492，从 Py3.5 开始引入。不惜增加关键字async awite来打造属于 Python 协程。 老样子，先看数据结构。 PyCoro_Type123456789101112131415161718192021222324252627# genobject.c.983static PyMethodDef coro_methods[] = &#123; /* 注意跟 gen_methods[] 对比，目标函数都是同一个 */ &#123;"send",(PyCFunction)_PyGen_Send, METH_O, coro_send_doc&#125;, &#123;"throw",(PyCFunction)gen_throw, METH_VARARGS, coro_throw_doc&#125;, &#123;"close",(PyCFunction)gen_close, METH_NOARGS, coro_close_doc&#125;, &#123;NULL, NULL&#125; /* Sentinel */&#125;;static PyAsyncMethods coro_as_async = &#123; (unaryfunc)coro_await, /* am_await */ 0, /* am_aiter */ 0 /* am_anext */&#125;;PyTypeObject PyCoro_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "coroutine", /* tp_name */ sizeof(PyCoroObject), /* tp_basicsize */ # 生成器，并未定义 tp_as_async 方法 &amp;coro_as_async, /* tp_as_async */ # 原生协程，不支持迭代器协议 0, /* tp_iter */ 0, /* tp_iternext */ coro_methods, /* tp_methods */&#125;; 从定义可以看出，协程和生成器一样，都有同样的send/throw/close方法，并且协程支持await方法。 PyCoroObject1234567/* _PyGenObject_HEAD defines the initial segment of generator and coroutine objects. */# genobject.h.51typedef struct &#123; _PyGenObject_HEAD(cr)&#125; PyCoroObject; 从上可以看出，协程和生成器，在C层面结构体定义是一模一样。或者说，在 Python 中生成器是协程的基础。 Chain coroutines1234567891011121314import asyncioasync def compute(x, y): print("Compute %s + %s ..." % (x, y)) await asyncio.sleep(1.0) return x + yasync def print_sum(x, y): result = await compute(x, y) print("%s + %s = %s" % (x, y, result))loop = asyncio.get_event_loop()loop.run_until_complete(print_sum(1, 2))loop.close() 小结Python在编译时，通过对 fun.__code__.co_flags 字段，进行区分： CO_GENERATOR 用于 def + yield inspect.CO_GENERATOR == 32 isinstance(gen(), types.GeneratorType) CO_COROUTINE 用于 async def inspect.CO_COROUTINE == 128 isinstance(coro(), types.CoroutineType) CO_ITERABLE_COROUTINE 用于 @types.coroutine+def+yield inspect.CO_ITERABLE_COROUTINE == 256 isinstance(co_gen(), types.GeneratorType) bool(co_gen.__code__.co_flags &amp; 256) == True CO_ASYNC_GENERATOR 用于 async def + yield [+ await] inspect.CO_ASYNC_GENERATOR == 512 isinstance(async_gen(), types.AsyncGeneratorType) bool(async_gen.__code__.co_flags &amp; 512) == True 原生协程没有实现 __iter__ and __next__methods，因此 不能用于 iter(), list(), tuple() and other built-ins. 不能用于 for..in 迭代 普通生成器不能 yield from 原生协程，否则 TypeError. 生成器协程 (即：@types.coroutine) 可以使用 yield from 原生协程对象 异步生成器12345678910111213141516import asyncioasync def ticker(delay, to): for i in range(to): yield i await asyncio.sleep(delay)async def run(): async for i in ticker(1, 10): print(i)loop = asyncio.get_event_loop()try: loop.run_until_complete(run())finally: loop.close() Asynchronous Generators(异步生成器)，源自PEP 525，从 Py3.6 开始引入： 简单的说，就是 async + yield 支持异步迭代协议：aiter、anext，可以用作 async for 跟协程类似，也需要 event loop 来执行 性能上，同常规生成器类似，比异步迭代器快 PyAsyncGen_Type1234567891011121314151617181920212223242526# genobject.h.1420static PyMethodDef async_gen_methods[] = &#123; &#123;"asend", (PyCFunction)async_gen_asend, METH_O, async_asend_doc&#125;, &#123;"athrow",(PyCFunction)async_gen_athrow, METH_VARARGS, async_athrow_doc&#125;, &#123;"aclose", (PyCFunction)async_gen_aclose, METH_NOARGS, async_aclose_doc&#125;, &#123;NULL, NULL&#125; /* Sentinel */&#125;;static PyAsyncMethods async_gen_as_async = &#123; 0, /* am_await */ # 支持 异步迭代协议 PyObject_SelfIter, /* am_aiter */ (unaryfunc)async_gen_anext /* am_anext */&#125;;PyTypeObject PyAsyncGen_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "async_generator", /* tp_name */ &amp;async_gen_as_async, /* tp_as_async */ # 异步生成器，本身不支持 普通迭代协议 0, /* tp_iter */ 0, /* tp_iternext */ async_gen_methods, /* tp_methods */ _PyGen_Finalize, /* tp_finalize */&#125;; 属性123456789101112async def genfunc(): yield 1 yield 2agen = genfunc()assert agen.__aiter__() is genassert await agen.__anext__() == 1assert await agen.__anext__() == 2await agen.__anext__() # This line will raise StopAsyncIteration. 12345678910111213# agen.__aiter__(): Returns agen.# agen.__anext__(): Returns an awaitable,# agen.asend(val): Returns an awaitable,# agen.athrow(typ, [val, [tb]]): Returns an awaitable,# agen.aclose(): Returns an awaitable,# agen.__name__ and agen.__qualname__: 可读可写# agen.ag_await: 正等待的对象(None). 类似当前可用的 gi_yieldfrom for generators and cr_await for coroutines.# agen.ag_frame, agen.ag_running, and agen.ag_code: 同生成器一样# StopIteration and StopAsyncIteration 被替换为 RuntimeError，并且不上抛。 终止当 异步生成器，若在 async with 语句块内使用 yield ，生成器被gc时，会导致占用的资源无法释放。 为此： 引入了 aclose 方法，类似于普通生成器的 close()，只是需要 event loop 来执行 aclose()。 try finally 语句块下，不能使用 yield，否则 Raise a RuntimeError。注意 async with 等效于 try。 sys module添加两个方法：set_asyncgen_hooks() 、 get_asyncgen_hooks()1234567891011121314151617# asyncio/base_events.pyclass BaseEventLoop: def run_forever(self): ... old_hooks = sys.get_asyncgen_hooks() # returns a namedtuple-like structure with firstiter and finalizer fields. sys.set_asyncgen_hooks(finalizer=self._finalize_asyncgen) # set_asyncgen_hooks is thread-specific try: ... finally: sys.set_asyncgen_hooks(*old_hooks) ... def _finalize_asyncgen(self, gen): self.create_task(gen.aclose()) sys.set_asyncgen_hooks() accepts two arguments: firstiter: a callable which will be called when an asynchronous generator is iterated for the first time. finalizer: a callable which will be called when an asynchronous generator is about to be GCed. 过程调用123456789101112131415def foo(): return 1def bar(): print(foo())import disdis.dis(bar)4 0 LOAD_GLOBAL 0 (print) 2 LOAD_GLOBAL 1 (foo) 4 CALL_FUNCTION 0 6 CALL_FUNCTION 1 8 POP_TOP 10 LOAD_CONST 0 (None) 12 RETURN_VALUE 123456789101112131415161718async def foo(): return 1async def bar(): print(await foo())import disdis.dis(bar)4 0 LOAD_GLOBAL 0 (print) 2 LOAD_GLOBAL 1 (foo) 4 CALL_FUNCTION 0 6 GET_AWAITABLE 8 LOAD_CONST 0 (None) 10 YIELD_FROM 12 CALL_FUNCTION 1 14 POP_TOP 16 LOAD_CONST 0 (None) 18 RETURN_VALUE 对比两个版本，发现多出：GET_AWAITABLE、YIELD_FROM CALL_FUNCTION：执行 foo()，获取到 coroutine object，并入栈 GET_AWAITABLE：从栈顶弹出一个对象，获取到 awaitable 对象并入栈 YIELD_FROM：获取栈顶元素 v=POP()，调用 _PyGen_Send(…, v)，并返回结果 GET_AWAITABLE123456789101112131415161718192021# ceval.c.2040TARGET(GET_AWAITABLE) &#123; PyObject *iterable = TOP(); PyObject *iter = _PyCoro_GetAwaitableIter(iterable); if (iter != NULL &amp;&amp; PyCoro_CheckExact(iter)) &#123; PyObject *yf = _PyGen_yf((PyGenObject*)iter); /* `iter` is a coroutine object that is being awaited, `yf` is a pointer to the current awaitable being awaited on. asert yf == NULL raise RuntimeError("coroutine is being awaited already") */ &#125; SET_TOP(iter); /* Even if it's NULL */ if (iter == NULL) &#123; goto error; &#125; PREDICT(LOAD_CONST); DISPATCH();&#125; 调用 GetAwaitableIter，传入一个 iterable，得到一个 awaitable对象，否则 会报错。 _PyCoro_GetAwaitableIter123456789101112131415161718192021222324252627282930313233343536# genobject.c.876/* * 核心逻辑：returns an awaitable for `o`: * - `o` if `o` is a coroutine-object; * - `type(o)-&gt;tp_as_async-&gt;am_await(o)` * * Raises a TypeError if it's not possible to return * an awaitable and returns NULL. */PyObject * _PyCoro_GetAwaitableIter(PyObject *o)&#123; unaryfunc getter = NULL; PyTypeObject *ot; if (PyCoro_CheckExact(o) || gen_is_coroutine(o)) &#123; return o; /* 'o' is a coroutine. */ &#125; ot = Py_TYPE(o); if (ot-&gt;tp_as_async != NULL) &#123; getter = ot-&gt;tp_as_async-&gt;am_await; &#125; if (getter != NULL) &#123; PyObject *res = (*getter)(o); return res; &#125; return NULL;&#125;# genobject.c.933static PyObject * coro_await(PyCoroObject *coro)&#123; PyCoroWrapper *cw = PyObject_GC_New(PyCoroWrapper, &amp;_PyCoroWrapper_Type); cw-&gt;cw_coroutine = coro; return (PyObject *)cw;&#125; 如上，coroutine 是天然的 awaitable对象。或者调用 type(o)-&gt;tp_as_async-&gt;am_await(o) 得到一个 awaitable对象。 实现了 tp_as_async 方法的有：coroutine、aiter_wrapper、async_generator_asend、async_generator_athrow。 PyCoroWrapper_Type123456789101112131415161718192021222324252627# genobject.c.1088static PyMethodDef coro_wrapper_methods[] = &#123; &#123;"send",(PyCFunction)coro_wrapper_send, METH_O, coro_send_doc&#125;, &#123;"throw",(PyCFunction)coro_wrapper_throw, METH_VARARGS, coro_throw_doc&#125;, &#123;"close",(PyCFunction)coro_wrapper_close, METH_NOARGS, coro_close_doc&#125;, &#123;NULL, NULL&#125; /* Sentinel */&#125;;# genobject.c.859typedef struct &#123; PyObject_HEAD PyCoroObject *cw_coroutine;&#125; PyCoroWrapper;# genobject.c.1095PyTypeObject _PyCoroWrapper_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "coroutine_wrapper", sizeof(PyCoroWrapper), /* tp_basicsize */ # 实现 迭代器协议 PyObject_SelfIter, /* tp_iter */ (iternextfunc)coro_wrapper_iternext, /* tp_iternext */ # 实现 协程的method coro_wrapper_methods, /* tp_methods */&#125;; YIELD_FROM1234567891011121314151617181920212223242526272829303132333435363738# ceval.c.2076TARGET(YIELD_FROM) &#123; PyObject *v = POP(); PyObject *receiver = TOP(); int err; if (PyGen_CheckExact(receiver) || PyCoro_CheckExact(receiver)) &#123; // 如果是 generaotr / corotine，调用 Send() retval = _PyGen_Send((PyGenObject *)receiver, v); &#125; else &#123; // 其他 Awaitable 对象，迭代下一个元素 _Py_IDENTIFIER(send); if (v == Py_None) retval = Py_TYPE(receiver)-&gt;tp_iternext(receiver); else retval = _PyObject_CallMethodIdObjArgs(receiver, &amp;PyId_send, v, NULL); &#125; Py_DECREF(v); if (retval == NULL) &#123; // 进入销毁流程 PyObject *val; if (tstate-&gt;c_tracefunc != NULL &amp;&amp; PyErr_ExceptionMatches(PyExc_StopIteration)) call_exc_trace(tstate-&gt;c_tracefunc, tstate-&gt;c_traceobj, tstate, f); err = _PyGen_FetchStopIterationValue(&amp;val); if (err &lt; 0) goto error; Py_DECREF(receiver); SET_TOP(val); DISPATCH(); &#125; /* receiver remains on stack, retval is value to be yielded */ f-&gt;f_stacktop = stack_pointer; why = WHY_YIELD; /* and repeat... */ assert(f-&gt;f_lasti &gt;= (int)sizeof(_Py_CODEUNIT)); f-&gt;f_lasti -= sizeof(_Py_CODEUNIT); goto fast_yield;&#125;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>coroutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 协程系列 —— 系列文章目录及介绍]]></title>
    <url>%2F2018%2F09%2F12%2F3.%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3%2F3.0.Python%20%E5%8D%8F%E7%A8%8B%E7%B3%BB%E5%88%97%2F</url>
    <content type="text"><![CDATA[声明文章中出现的前文/前面，皆指同系列中的文章。上面，皆指同篇文章中的内容。文章中的注释内容，来源于源码和官网文档。文章中的源码，皆根据情况进行了删减、更改，读者需配合源码自行脑补。 欢迎读者留言(Mail: he11o76120 at gmail)，指出错误，共同交流。 目录 【Python 协程系列】greenlet 源码分析 【Python 协程系列】asyncio 源码分析 【Python 协程系列】Python 原生协程 【Python 协程系列】Gevent 源码分析]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】Tornado 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.6.Tornado%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[参考资料 Tornado GitHub: 5.1 前言 Tornado is a Python web framework and asynchronous networking library。 包含以下几个方面： A web framework，继承 RequestHandler 创建 application Client- and server-side implementions of HTTP (HTTPServer and AsyncHTTPClient). An asynchronous networking library including the classes IOLoop and IOStream A coroutine library (tornado.gen)，现已经推荐使用 Native Cocoutine。 虽然兼容其他WSGI server/client，但无法发挥 Tornado 的高并发、长连接特点 从上图可以看出，Tornado 可以分为四层： EVENT 处理 IO 事件，这一层已经由 asyncio 来实现 TCP 实现了 TCP 服务器，负责数据传输 HTTP/HTTPS，基于 HTTP 协议，实现了 服务端和客户端 WEB框架，基于认证/DB/Wsgi/模板/本地化，实现 Web 框架 Tornado 使用单线程的事件循环来处理每个连接，在 Tornado5.0+，Py3.5+中： IOLoop 已是对官方库 asyncio.io_loop 的封装 异步占位符 Future，现已推荐使用 Native coroutines Demo12345678910111213import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): self.write("Hello, world")if __name__ == "__main__": application = tornado.web.Application([ (r"/", MainHandler), ]) application.listen(4000) tornado.ioloop.IOLoop.current().start() Application123456# tornado.web.pyclass Application(ReversibleRouter): """ A collection of request handlers that make up a web application.""" def __init__(self, handlers=None, default_host=None, transforms=None, **settings): ... web.Application 是 tornado 作为 Web 框架最核心的类。在初始化时传入了： handlers，路由及对应 处理类列表 settings，UI模块、静态文件等配置参数 transforms，分块压缩配置 1234567# application.listen(4000)class Application(ReversibleRouter): def listen(self, port, address="", **kwargs): from tornado.httpserver import HTTPServer server = HTTPServer(self, **kwargs) server.listen(port, address) return server 在 application.listen 中，可以发现，实际上调用的是 HTTPServer().listen()。 HTTPServer()12345678910111213141516171819202122232425262728293031class Configurable(object): def __new__(cls, *args, **kwargs): base = cls.configurable_base() init_kwargs = &#123;&#125; if cls is base: impl = cls.configured_class() if base.__impl_kwargs: init_kwargs.update(base.__impl_kwargs) else: impl = cls init_kwargs.update(kwargs) if impl.configurable_base() is not base: return impl(*args, **init_kwargs) instance = super(Configurable, cls).__new__(impl) instance.initialize(*args, **init_kwargs) return instanceclass HTTPServer(TCPServer, Configurable, httputil.HTTPServerConnectionDelegate): def __init__(self, *args, **kwargs): pass def initialize(self, request_callback, no_keep_alive=False, xheaders=False, ssl_options=None, protocol=None, decompress_request=False, chunk_size=None, max_header_size=None, idle_connection_timeout=None, body_timeout=None, max_body_size=None, max_buffer_size=None, trusted_downstream=None): ... TCPServer.__init__(self,...) 我们注意到，HTTPServer 继承了 Configurable，并且后者定义了 new 方法。在 new 方法中，整合实例化参数，调用 initialize，构建实例化对象并返回。其中： 参数 request_callback == Application() 将自身初始化为 TCPServer 对象 TCPServer.listen12345678910class TCPServer(object): def listen(self, port, address=""): sockets = bind_sockets(port, address=address) self.add_sockets(sockets) def add_sockets(self, sockets): for sock in sockets: self._sockets[sock.fileno()] = sock self._handlers[sock.fileno()] = add_accept_handler( sock, self._handle_connection) 如上，HTTPServer.listen 继承父类 TCPServer.listen。在 add_sockets 中，将执行很重要一个函数add_accept_handler。 add_accept_handler12345678910111213141516171819202122232425def add_accept_handler(sock, callback): io_loop = IOLoop.current() removed = [False] def accept_handler(fd, events): # for 循环，限制单次处理最大 128 个 for i in xrange(_DEFAULT_BACKLOG): if removed[0]: return try: connection, address = sock.accept() except socket.error as e: if errno_from_exception(e) in _ERRNO_WOULDBLOCK: return if errno_from_exception(e) == errno.ECONNABORTED: continue raise set_close_exec(connection.fileno()) callback(connection, address) def remove_handler(): io_loop.remove_handler(sock) removed[0] = True io_loop.add_handler(sock, accept_handler, IOLoop.READ) return remove_handler 在 add_accept_handler 中，将 socket 放入 io_loop，当有连接请求，会调用闭包函数 accept_handler。在其中执行 sock.accept()，获取与客户端连接 conn，调用回调函数 TCPServer._handle_connection，处理连接。 TCPServer._handle_connection123456789101112131415161718192021class TCPServer(object): def _handle_connection(self, connection, address): # Socket-based non-blocking Rader&amp;Witer，有省略 stream = IOStream(connection, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size) future = self.handle_stream(stream, address) if future is not None: IOLoop.current().add_future(gen.convert_yielded(future), lambda f: f.result())class HTTPServer(TCPServer,...): def handle_stream(self, stream, address): context = _HTTPRequestContext(stream, address, self.protocol, self.trusted_downstream) conn = HTTP1ServerConnection( stream, self.conn_params, context) self._connections.add(conn) conn.start_serving(self) 如上，正式在 handle_connection 中，执行了 io_loop.add_future。将 conn 封装非阻塞的 IOStream， 然后添加上下文 _HTTPRequestContext，封装成 HTTP1Connection，放入了 io_loop 中。 HTTP1ServerConnection123456789101112131415161718192021222324252627282930313233"""conn.start_serving(self) # self, 在此处是 HTTPServer"""class HTTP1ServerConnection(object): def start_serving(self, delegate): self._serving_future = self._server_request_loop(delegate) self.stream.io_loop.add_future(self._serving_future, lambda f: f.result()) @gen.coroutine def _server_request_loop(self, delegate): try: while True: conn = HTTP1Connection(self.stream, False, self.params, self.context) request_delegate = delegate.start_request(self, conn) try: ret = yield conn.read_response(request_delegate) except (iostream.StreamClosedError, iostream.UnsatisfiableReadError): return except _QuietException: # This exception was already logged. conn.close() return except Exception: gen_log.error("Uncaught exception", exc_info=True) conn.close() return if not ret: return yield gen.moment finally: delegate.on_close(self) 通过 while 循环，不断的读取数据，完成请求处理。在其中，delegate.start_request，调用的是HTTPServer().start_request。 注意，这个地方，有一个小技巧： _server_request_loop，本身是一个 yiled 生成器 gen.coroutine 装饰器，会调用 next()，消费生成器 12345678910result = func(*args, **kwargs)if isinstance(result, GeneratorType): ... # 此处，会消费 gen，进入 _server_request_loop # 然后进入，conn.read_response(request_delegate)，获取结果 yielded = next(result) future = _create_future() runner = Runner(result, future, yielded) future.add_done_callback(lambda _: runner) start_request12345678910111213# request_delegate = delegate.start_request(self, conn) class HTTPServer(TCPServer, Configurable, httputil.HTTPServerConnectionDelegate): def start_request(self, server_conn, request_conn): if isinstance(self.request_callback, httputil.HTTPServerConnectionDelegate): delegate = self.request_callback.start_request(server_conn, request_conn) else: delegate = _CallableAdapter(self.request_callback, request_conn) if self.xheaders: delegate = _ProxyAdapter(delegate, request_conn) return delegate 在 HTTPServer.initialize() 中，request_callback 被初始化为 Application()。 1234# Application -&gt; ReversibleRouter -&gt; Router -&gt; HTTPServerConnectionDelegateclass Router(httputil.HTTPServerConnectionDelegate): def start_request(self, server_conn, request_conn): return _RoutingDelegate(self, server_conn, request_conn) 根据 Application 继承链，将调用 Router.start_request，得到一个 RoutingDelegate 对象。被 yield conn.read_response(request_delegate) 消费。 read_response12345678910111213# yield conn.read_response(_RoutingDelegate())class HTTP1Connection(httputil.HTTPConnection): def read_response(self, delegate): if self.params.decompress: delegate = _GzipMessageDelegate(delegate, self.params.chunk_size) return self._read_message(delegate) @gen.coroutine def _read_message(self, delegate): """ 读取 IOStream 1. yield header_data 2. start_line, headers 解析请求行 3. headers_received(start_line, headers)，匹配 Handler """ 此处，再次通过 @gen.coroutine 生成器，消费 _read_message。在 read_response，从 socket 读取数据，供用户代码使用。当 read_message 把请求头 yield 之后，会返回到 `@gen.coroutine` 装饰器代码逻辑中：1234567# result: read_message 生成器yielded = next(result) # yielded: 生成器 next 的结果，请求头# 返回到此处，继续执行future = _create_future() # future：新的 Future 对象runner = Runner(result, future, yielded)future.add_done_callback(lambda _: runner) 此时，会进入 Runner 的实例化流程，然后调用 run 方法： 1234567891011class Runner(object): def __init__(self, gen, result_future, first_yielded): ... if self.handle_yield(first_yielded): gen = result_future = first_yielded = None self.run() def run(self): ... while True: value = future.result() yielded = self.gen.send(value) 在此处，循环消费 read_message，直到读取完所有请求体。注意，在读取到请求头，再次进入 read_message 时，会先解析请求行，找到 handler。 实例化 HandlerDelegate 对象123456789101112131415161718192021222324# delegate.headers_received(start_line, headers)class _RoutingDelegate(httputil.HTTPMessageDelegate): def __init__(self, router, server_conn, request_conn): self.server_conn = server_conn self.request_conn = request_conn self.delegate = None self.router = router # 用户的 Application def headers_received(self, start_line, headers): # 1. 封装 request 对象 request = httputil.HTTPServerRequest( connection=self.request_conn, server_connection=self.server_conn, start_line=start_line, headers=headers) # 在 Application 中寻找对应的 router，_HandlerDelegate 对象 # 封装到 _RoutingDelegate.delegate 属性上 self.delegate = self.router.find_handler(request) if self.delegate is None: app_log.debug("Delegate for %s %s request not found", start_line.method, start_line.path) self.delegate = _DefaultMessageDelegate(self.request_conn) return self.delegate.headers_received(start_line, headers) 然后进入 _RoutingDelegate.finish()，进入到_RoutingDelegate.delegate.finish()。HandlerDelegate 实例对象，包含很多信息：123456789101112131415161718192021class _HandlerDelegate(httputil.HTTPMessageDelegate): def __init__(self, application, request, handler_class, handler_kwargs, path_args, path_kwargs): self.application = application self.connection = request.connection self.request = request self.handler_class = handler_class self.handler_kwargs = handler_kwargs or &#123;&#125; self.path_args = path_args or [] self.path_kwargs = path_kwargs or &#123;&#125; self.chunks = [] self.stream_request_body = _has_stream_request_body(self.handler_class) def execute(self): # 创建用户 handler 类实例对象 self.handler = self.handler_class(self.application, self.request, **self.handler_kwargs) ... # 准备执行 用户代码 self.handler._execute(transforms, *self.path_args, **self.path_kwargs) 在 execute 中，会实例化 HandClass 对象，调用 _execute 准备执行用户代码。注意，execute 也是一个被 @gen.coroutine 装饰的函数。 RequestHandler._execute()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class RequestHandler(object): @gen.coroutine def _execute(self, transforms, *args, **kwargs): """Executes this request with the given output transforms.""" self._transforms = transforms try: if self.request.method not in self.SUPPORTED_METHODS: raise HTTPError(405) self.path_args = [self.decode_argument(arg) for arg in args] self.path_kwargs = dict((k, self.decode_argument(v, name=k)) for (k, v) in kwargs.items()) # If XSRF cookies are turned on, reject form submissions without # the proper cookie if self.request.method not in ("GET", "HEAD", "OPTIONS") and \ self.application.settings.get("xsrf_cookies"): self.check_xsrf_cookie() result = self.prepare() if result is not None: result = yield result if self._prepared_future is not None: # Tell the Application we've finished with prepare() # and are ready for the body to arrive. future_set_result_unless_cancelled(self._prepared_future, None) if self._finished: return if _has_stream_request_body(self.__class__): # In streaming mode request.body is a Future that signals # the body has been completely received. The Future has no # result; the data has been passed to self.data_received # instead. try: yield self.request.body except iostream.StreamClosedError: return method = getattr(self, self.request.method.lower()) result = method(*self.path_args, **self.path_kwargs) if result is not None: result = yield result if self._auto_finish and not self._finished: self.finish() except Exception as e: try: self._handle_request_exception(e) except Exception: app_log.error("Exception in exception handler", exc_info=True) finally: # Unset result to avoid circular references result = None if (self._prepared_future is not None and not self._prepared_future.done()): # In case we failed before setting _prepared_future, do it # now (to unblock the HTTP server). Note that this is not # in a finally block to avoid GC issues prior to Python 3.4. self._prepared_future.set_result(None) 如上，execute 的代码逻辑，跟 Django/Flask 类似： 处理 405 处理 XSRF prepare-&gt;hook before method 调用 method() 用户代码执行 self.write() 写入结果 自动/手动执行 sefl.finish() 完成请求 调用 RequestHandler.flush() WEB 框架层执行结束 HTTP 层开始执行，write data to socket 小结Tornador 作为 WEB 框架，会经历以下几个步骤： 准备阶段 接收路由表，参数，创建 Application 实例对象 Socket.bind+listen 创建 HTTPServer 实例化对象，其继承自 TCPServer TCPServer.listen，将执行 socket.bind+listen，并将 sock-handle_connection 放入 io_loop 中 启动事件循环 最刚开始，io_loop 只监听了 bind 的 Socket 连接请求 Accept() 一旦监听到请求，将执行回调，在 handle_connection 中将执行 sock.accept()，获取到 conn 将 conn 封装成非阻塞的 IOStream，添加上下文，封装成协程对象，放入 io_loop HTTP 请求处理 在 HTTP1Connection 中，read_message，读取请求体，解析请求行，匹配 Handler 进入 RequestHandler._execute() 执行用户层代码逻辑 返回 HTTP 层，将数据写入到 socket 完成请求响应 IOLoop1234567891011121314151617181920212223class IOLoop(Configurable): @staticmethod def current(instance=True): """ Returns the current thread's `IOLoop` """ if asyncio is None: ... else: try: loop = asyncio.get_event_loop() except (RuntimeError, AssertionError): if not instance: return None raise try: # IOLoop._ioloop_for_asyncio = dict() return IOLoop._ioloop_for_asyncio[loop] except KeyError: if instance: from tornado.platform.asyncio import AsyncIOMainLoop current = AsyncIOMainLoop(make_current=True) else: current = None return current 如上，当存在 asyncio 模块时，返回的是 AsyncIOMainLoop() 对象 AsyncIOMainLoop12345678910111213141516171819202122232425262728293031323334353637class AsyncIOMainLoop(BaseAsyncIOLoop): def initialize(self, **kwargs): super(AsyncIOMainLoop, self).initialize(asyncio.get_event_loop(), **kwargs)class BaseAsyncIOLoop(IOLoop): def initialize(self, asyncio_loop, **kwargs): self.asyncio_loop = asyncio_loop self.handlers = &#123;&#125; # Set of fds listening for reads/writes self.readers = set() self.writers = set() self.closing = False for loop in list(IOLoop._ioloop_for_asyncio): if loop.is_closed(): del IOLoop._ioloop_for_asyncio[loop] IOLoop._ioloop_for_asyncio[asyncio_loop] = self super(BaseAsyncIOLoop, self).initialize(**kwargs)class IOLoop(Configurable): def initialize(self, make_current=None): if make_current is None: if IOLoop.current(instance=False) is None: self.make_current() elif make_current: current = IOLoop.current(instance=False) # AsyncIO loops can already be current by this point. if current is not None and current is not self: raise RuntimeError("current IOLoop already exists") self.make_current() class Configurable(object): def __new__(cls, *args, **kwargs): ... instance = super(Configurable, cls).__new__(impl) instance.initialize(*args, **init_kwargs) return instance 如上，实例化时，通过不断的 super() 调用 initialize，将 asyncio_loop 封装成 AsyncIOMainLoop 对象返回。 start123456789101112class BaseAsyncIOLoop(IOLoop): def start(self): try: old_loop = asyncio.get_event_loop() except (RuntimeError, AssertionError): old_loop = None try: self._setup_logging() asyncio.set_event_loop(self.asyncio_loop) self.asyncio_loop.run_forever() finally: asyncio.set_event_loop(old_loop) 执行 AsyncIOMainLoop().start()，最终调用的是 asyncio_loop.run_forever()。在 asyncio 模块介绍中，已经知道：在run_forever中，通过while True不断的执行run_once方法，完成整个事件驱动的循环调度。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python 协程系列】Gevent 源码分析]]></title>
    <url>%2F2018%2F09%2F12%2F3.%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3%2F3.2.Gevnt%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[参考资料 gevent.org GitHub:1.3.6 前言 gevent is a coroutine -based Python networking library that uses greenlet to provide a high-levelsynchronous API on top of the libev or libuv event loop. Features include: Fast event loop based on libev or libuv. Lightweight execution units based on greenlets. API that re-uses concepts from the Python standard library (for examples there are events and queues). Cooperative sockets with SSL support Cooperative DNS queries performed through a threadpool, dnspython, or c-ares. Monkey patching utility to get 3rd party modules to become cooperative TCP/UDP/HTTP servers Subprocess support (through gevent.subprocess) Thread pools Monkey PatchGevent 最著名的莫过于Monkey patch。它将部分标准库的同步代码，用异步进行了实现。123456789101112131415# gevent.monkey.py__all__ = [ 'patch_all', 'patch_builtins', 'patch_dns', 'patch_os', 'patch_select', 'patch_signal', 'patch_socket', 'patch_ssl', 'patch_subprocess', 'patch_sys', 'patch_thread', 'patch_time',] 我们可以猜测到，在 path_ 中，必然会执行 `import lib, setattr(lib, , gevent.*)` 下面我们只看其中一个例子 patch_socket。 patch_socket123456789101112131415161718192021@_ignores_DoNotPatchdef patch_socket(dns=True, aggressive=True): from gevent import socket if dns: items = socket.__implements__ # pylint:disable=no-member else: items = set(socket.__implements__) - set(socket.__dns__) """ gevent 重新实现的方法 _implements = [ 'create_connection', 'socket', 'SocketType', 'fromfd', 'socketpair', ] """ _patch_module('socket', items=items) if aggressive: if 'ssl' not in socket.__implements__: remove_item(socket, 'ssl') patch_socket 中，根据参数决定 patch 的 items。然后调用 patch_module。1234567891011121314151617181920212223def _patch_module(name, items=None, _warnings=None, _notify_did_subscribers=True): gevent_module = getattr(__import__('gevent.' + name), name) module_name = getattr(gevent_module, '__target__', name) target_module = __import__(module_name) patch_module(target_module, gevent_module, items=items, _warnings=_warnings, _notify_did_subscribers=_notify_did_subscribers) return gevent_module, target_moduledef patch_module(target_module, source_module, items=None,**kwargs): ... for attr in items: patch_item(target_module, attr, getattr(source_module, attr))def patch_item(module, attr, newitem): olditem = getattr(module, attr, _NONE) if olditem is not _NONE: saved.setdefault(module.__name__, &#123;&#125;).setdefault(attr, olditem) setattr(module, attr, newitem) 在 patch_module 中，导入原生和 Gevent 重写的 module。遍历 items 利用 setattr 完成替换工作。 Demo12from gevent import timetime.sleep(1) 运行发现，time.sleep(1) 同样会阻塞。 123456# gevent.time.py__implements__ = [ 'sleep',]from gevent.hub import sleepsleep = sleep 如上，gevent.time 模块，仅对 sleep 函数进行 patch。 sleep1234567891011121314def sleep(seconds=0, ref=True): hub = _get_hub_noargs() loop = hub.loop if seconds &lt;= 0: waiter = Waiter(hub) loop.run_callback(waiter.switch, None) waiter.get() else: with loop.timer(seconds, ref=ref) as t: # Sleeping is expected to be an "absolute" measure with # respect to time.time(), not a relative measure, so it's # important to update the loop's notion of now before we start loop.update_now() hub.wait(t) 在 sleep 中，出现了 hub/loop/waiter。我们一个个的看。 get_hub_noargs123456def get_hub_noargs(): hub = _threadlocal.hub # 又是线程变量 if hub is None: hubtype = get_hub_class() hub = _threadlocal.hub = hubtype() # gevent.hub.Hub() return hub 返回一个 Hub() 实例化对象。1234567891011121314151617181920212223242526272829303132333435363738394041class Hub(WaitOperationsGreenlet): """ A greenlet that runs the event loop. It is created automatically by :func:`get_hub`.""" def __init__(self, loop=None, default=None): WaitOperationsGreenlet.__init__(self, None, None) self.thread_ident = get_thread_ident() if hasattr(loop, 'run'): if default is not None: raise TypeError("Unexpected argument: default") self.loop = loop elif get_loop() is not None: self.loop = get_loop() else: if default is None and self.thread_ident != MAIN_THREAD_IDENT: default = False loop = self.backend self.loop = self.loop_class(flags=loop, default=default) self._resolver = None self._threadpool = None self.format_context = GEVENT_CONFIG.format_context if loop is None: self.minimal_ident = hub_ident_registry.get_ident(self)# WaitOperationsGreenlet -&gt; SwitchOutGreenletWithLoop -&gt; TrackedRawGreenlet -&gt; greenletclass TrackedRawGreenlet(greenlet): def __init__(self, function, parent): greenlet.__init__(self, function, parent) current = getcurrent() # greenlet.getcurrent() self.spawning_greenlet = wref(current) # See Greenlet for how trees are maintained. try: self.spawn_tree_locals = current.spawn_tree_locals except AttributeError: self.spawn_tree_locals = &#123;&#125; if current.parent: current.spawn_tree_locals = self.spawn_tree_locals]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】Django 一些 trick]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.5.Django%20%E4%B8%80%E4%BA%9B%20trick%2F</url>
    <content type="text"><![CDATA[留坑，待上传]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python Web 系列】Flask 一些 trick]]></title>
    <url>%2F2018%2F09%2F12%2F2.Python%20Web%2F2.3.Flask%20%E4%B8%80%E4%BA%9B%20trick%2F</url>
    <content type="text"><![CDATA[留坑，待上传]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPython3.6源码分析——系列文章目录及介绍]]></title>
    <url>%2F2018%2F08%2F05%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.%20%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[参考本文的参考资料主要来源于三处： 陈儒先生所著《Python 源码剖析》，且文章中多次引用书中图片，在此统一声明，文章中将不再重复说明。 GitHub 源码，对应 CPython 3.6 版本。 PEP 提案，各章节单独列出。 声明《源码剖析》对应 Py2.5，本文对应 Py3.6。两个版本除了在类机制上差别较大，其余部分皆整体类似，细节不同。 文章中出现的前文，皆指同系列中的文章。上面，皆指同篇文章中的内容。文章中的注释内容，来源于源码和官网文档。文章中的源码，皆根据情况进行了删减、更改，读者需配合源码自行脑补。 欢迎读者留言(Mail: he11o76120 at gmail)，指出错误，共同交流。 目录 PyObject/PyObjectType PyLongObject PyBytesObject/PyUnicodeObject PyListObject PyDictObject PyCodeObject/PyFrameObject Python 一般字节码执行 Python 控制字节码执行 Python 异常控制 Python 函数机制 Python 类机制 Python 自定义类 Python 环境初始化 Python 多线程机制 Python 内存管理机制 Python 垃圾回收]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 垃圾回收]]></title>
    <url>%2F2018%2F08%2F05%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.15.%20Python%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[前言垃圾回收一般分为两个阶段： 垃圾检测，从所有已分配的内存中识别出可以回收和不可以回收的内存 垃圾回收，是系统从掌握在检测阶段标识出的可回收内存 Python 基于古老的引用计数，必须在每次分配和释放内存时，加入 计数 的动作。引用计数，其特点和缺点都很明显 优点：实时性，发生在整个程序运行期间 缺点：循环引用 Python 为了解决循环引用，引入了标记清除和分代收集两种技术。 标记清除标记清除（Mark——Sweep）同样遵循垃圾回收的两个阶段，其工作过程如下： 寻找根对象(root object)的集合，即全局引用和函数栈中的引用。这些引用都是不可删除的。 从根对象出发，沿着集合中的对象的每一个引用，都是可到达的(reachable)，这些对象都是不可删除的 检测完成后，能区分出可删除和不可删除的。 整体上，就是遍历一张有向图。节点为对象，边为对象间的引用。利用BFS/DFS，遍历所有出度，利用三色标记，区分出可到达，最终找到孤立的节点，即可删除对象。 标记清除，主要是为了打破循环引用存在，而针对 PyLongObject、PyUnicodeObject，等对象是不可能出现循环引用的。因此，只需要检查 container 对象。所以 Python 将所有 container 对象组织成一个双向链表。 123456789PyObject * PyList_New(Py_ssize_t size)&#123; PyListObject *op; ... op = PyObject_GC_New(PyListObject, &amp;PyList_Type); ... _PyObject_GC_TRACK(op); return (PyObject *) op;&#125; 查看容器对象 PyListObject，可以发现创建对象是通过PyObject_GC_New。创建完对象后，通过宏_PyObject_GC_TRACK，把对象放入 containner 链表中。 PyObject_GC_New12345678910111213141516171819202122232425262728293031323334353637383940414243// objimpl.h.252typedef union _gc_head &#123; struct &#123; union _gc_head *gc_next; union _gc_head *gc_prev; Py_ssize_t gc_refs; &#125; gc; double dummy; /* force worst-case alignment */&#125; PyGC_Head;static PyObject * _PyObject_GC_Alloc(int use_calloc, size_t basicsize)&#123; PyObject *op; PyGC_Head *g; // 分配内存 size_t size = sizeof(PyGC_Head) + basicsize; if (use_calloc) g = (PyGC_Head *)PyObject_Calloc(1, size); else g = (PyGC_Head *)PyObject_Malloc(size); // 初始化 gc.gc_refs g-&gt;gc.gc_refs = 0; _PyGCHead_SET_REFS(g, GC_UNTRACKED); // 分代收集 generations[0].count++; /* number of allocated GC objects */ if (generations[0].count &gt; generations[0].threshold &amp;&amp; enabled &amp;&amp; generations[0].threshold &amp;&amp; !collecting &amp;&amp; !PyErr_Occurred()) &#123; collecting = 1; collect_generations(); collecting = 0; &#125; // 根据 g 地址，找到 ob 地址 // #define AS_GC(o) ((PyGC_Head *)(o)-1) // #define FROM_GC(g) ((PyObject *)(((PyGC_Head *)g)+1)) op = FROM_GC(g); return op;&#125; 可以发现，在创建对象时，同时申请了两块内存，PyGC_Head + PyListObject。最终还是调用的上一节上到的 PyObject_Malloc。在 object 和 gc head 之间，通过宏进行地址转换。注意其中的SET_REFS(g, GC_UNTRACKED);。 _PyObject_GC_TRACK1234567891011121314#define _PyObject_GC_TRACK(o) do &#123; \ PyGC_Head *g = AS_GC(o); \ if (_PyGCHead_REFS(g) != _PyGC_REFS_UNTRACKED) \ Py_FatalError("GC object already tracked"); \ _PyGCHead_SET_REFS(g, _PyGC_REFS_REACHABLE); \ g-&gt;gc.gc_next = _PyGC_generation0; \ g-&gt;gc.gc_prev = _PyGC_generation0-&gt;gc.gc_prev; \ g-&gt;gc.gc_prev-&gt;gc.gc_next = g; \ _PyGC_generation0-&gt;gc.gc_prev = g; \ &#125; while (0);#define _PyObject_GC_UNTRACK(o) do &#123; \ ... \ _PyGCHead_SET_REFS(g, _PyGC_REFS_UNTRACKED); 如上，通过两个指针，构成了双向链表。当创建 List 对象后，就把其挂载到链表上。并且可以发现_PyGC_generation0始终指向链表头。注意其中的SET_REFS()。 分代收集研究表明：无论任何语言开发的任何程序，都存在一定比例(80%-98%)的内存块生存期比较短，而另一些生存期特别长。 分代搜集，以空间换时间，是支撑 JAVA 的关键技术。其总体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合称为一个代，垃圾收集的频率与代的存活时间成反比。 若内存块 M 经过3次垃圾收集后依然存活，就将M划分到集合A中 新创建的对象，都划分到集合B中 一段时间后，B 中也有一批存活的对象，将其划分到A中 集合 A 因收集频率低，会存在一些已经被销毁的对象尸体（空间换时间） 在 Python 中，总共有三个代。上面的 GC_TRACK 中，存在的变量 _PyGC_generation0 即是一个内部指针，指向 第0代 的内存块集合。 generations12345678910111213141516171819struct gc_generation &#123; PyGC_Head head; int threshold; int count;&#125;;// 一个代，就是一个链表#define NUM_GENERATIONS 3#define GEN_HEAD(n) (&amp;generations[n].head)/* linked lists of container objects */static struct gc_generation generations[NUM_GENERATIONS] = &#123; /* PyGC_Head, threshold, count */ &#123;&#123;&#123;GEN_HEAD(0), GEN_HEAD(0), 0&#125;&#125;, 700, 0&#125;, &#123;&#123;&#123;GEN_HEAD(1), GEN_HEAD(1), 0&#125;&#125;, 10, 0&#125;, &#123;&#123;&#123;GEN_HEAD(2), GEN_HEAD(2), 0&#125;&#125;, 10, 0&#125;,&#125;;PyGC_Head *_PyGC_generation0 = GEN_HEAD(0); 如上，Python 内部维护这一个 3个对象的数组generations。通过这个数组，控制着三条可收集对象链表，这就是 Python 分代收集的三个代。上面的 GC_TRACK 中，存在的变量 _PyGC_generation0 即是一个内部指针，指向 第0代 的内存块集合。 12345678910111213141516static PyObject * _PyObject_GC_Alloc(int use_calloc, size_t basicsize)&#123; ... /* 增加 0 代 count */ generations[0].count++; // 判断是否触发 回收条件 if (generations[0].count &gt; generations[0].threshold &amp;&amp; enabled &amp;&amp; generations[0].threshold &amp;&amp; !collecting &amp;&amp; !PyErr_Occurred()) &#123; collecting = 1; collect_generations(); collecting = 0; &#125;&#125; 在PyObject_GC_Alloc，我们能看见，每次创建完对象会先进程收集检测。然后才再宏中加入到_PyGC_generation0链上。一旦满足判断条件，就会调用collect_generations开始回收。 collect_generations123456789101112131415161718static Py_ssize_t collect_generations(void)&#123; int i; Py_ssize_t n = 0; for (i = NUM_GENERATIONS-1; i &gt;= 0; i--) &#123; if (generations[i].count &gt; generations[i].threshold) &#123; if (i == NUM_GENERATIONS - 1 // 最大代，直接回收 &amp;&amp; long_lived_pending &lt; long_lived_total / 4) // 默认 0, 0 continue; // 执行回收 n = collect_with_callback(i); break; &#125; &#125; return n;&#125; 从上面的代码，能看出回收策略： 回收操作是由第一代触发 通过两个参数，long_lived_*，决定第三代是否执行回收 回收从 old-&gt;new，只要执行一次回收，就会 break，不在执行其他代 collect123456789101112/* Invoke progress callbacks to notify clients that garbage collection * is starting or stopping */static Py_ssize_tcollect_with_callback(int generation)&#123; Py_ssize_t result, collected, uncollectable; invoke_gc_callback("start", generation, 0, 0); result = collect(generation, &amp;collected, &amp;uncollectable, 0); invoke_gc_callback("stop", generation, collected, uncollectable); return result;&#125; 显然，大头都在 collect源码中。 collect 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192static Py_ssize_tcollect(int generation, Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable, int nofail)&#123; int i; Py_ssize_t m = 0; /* # objects collected */ Py_ssize_t n = 0; /* # unreachable objects that couldn't be collected */ PyGC_Head *young; /* the generation we are examining */ PyGC_Head *old; /* next older generation */ PyGC_Head unreachable; /* non-problematic unreachable trash */ PyGC_Head finalizers; /* objects with, &amp; reachable from, __del__ */ PyGC_Head *gc; _PyTime_t t1 = 0; /* initialize to prevent a compiler warning */ struct gc_generation_stats *stats = &amp;generation_stats[generation]; /* 1. 老代.count+1，当代+年轻代.count=0 */ if (generation+1 &lt; NUM_GENERATIONS) generations[generation+1].count += 1; for (i = 0; i &lt;= generation; i++) generations[i].count = 0; /* 2. 将年轻代链表，合并到当前代 */ for (i = 0; i &lt; generation; i++) &#123; /* gc_list_merge(PyGC_Head *from, PyGC_Head *to) append list `from` onto list `to`; `from` becomes an empty list */ gc_list_merge(GEN_HEAD(i), GEN_HEAD(generation)); &#125; /* handy references */ young = GEN_HEAD(generation); if (generation &lt; NUM_GENERATIONS-1) old = GEN_HEAD(generation+1); else old = young; // 3. 通过下面两步，在链表上进行打破循环的的模拟，寻找 root object // 3.1. Set all gc_refs = ob_refcnt. update_refs(young); // 3.2. 从 gc_refs 中减去内部引用。gc_refs&gt;0，表示 reachable subtract_refs(young); /* 4.Move the unreachable objects from young to unreachable. */ gc_list_init(&amp;unreachable); move_unreachable(young, &amp;unreachable); // 5.如果可能，将当代中的 reachable 合并到更老代中 if (young != old) &#123; if (generation == NUM_GENERATIONS - 2) &#123; long_lived_pending += gc_list_size(young); &#125; gc_list_merge(young, old); &#125; else &#123; /* We only untrack dicts in full collections, to avoid quadratic dict build-up. See issue #14775. */ untrack_dicts(young); long_lived_pending = 0; long_lived_total = gc_list_size(young); &#125; /* 6.收集含有 tp_finalize(__del__) 的对象，放入 finalizers：PEP-442 */ gc_list_init(&amp;finalizers); move_legacy_finalizers(&amp;unreachable, &amp;finalizers); /* 被 finalizers 引用的对象，也不能直接删除，也放入 finalizers */ move_legacy_finalizer_reachable(&amp;finalizers); /* 7. 处理弱引用，尝试调用 callback 函数 */ m += handle_weakrefs(&amp;unreachable, old); /* 8. 尝试调用 tp_finalize 方法，完成回收前的 用户定义工作 */ finalize_garbage(&amp;unreachable); if (check_garbage(&amp;unreachable)) &#123; revive_garbage(&amp;unreachable); gc_list_merge(&amp;unreachable, old); &#125; else &#123; /* 9. 尝试调用 tp_clear 方法，打破循环引用 */ delete_garbage(&amp;unreachable, old); &#125; /* 10.将含有 tp_finalize(__del__) 的对象，放入 old 代 */ handle_legacy_finalizers(&amp;finalizers, old); /* 11.释放所有的 free list */ if (generation == NUM_GENERATIONS-1) &#123; clear_freelists(); &#125;&#125; collect 简略大致 collect 过程： 老代.count+1，当代+年轻代.count=0 将 年轻代，合并到当前代中 在当前代链表上，寻找 root object 遍历当前代，生成 unreachable 链表 将当代 reachable 合并到更老的 代中 遍历 unreachable 链表，收集含有 del的对象，以及这些对象所引用的对象，放入 finalizers 处理弱引用 weakref，尝试调用回调 尝试调用 tp_finalize 方法，完成回收前的 用户定义工作 尝试调用 tp_clear 方法，打破循环引用 将含有 tp_finalize(del) 的对象，放入 old 代 释放所有的 free list。 小结Python 垃圾回收最主要的方式是通过对象的引用计数实现，只要 ref 降为0，就触发操作。为了避免频繁的操作带来性能问题，Python 中大量使用内存池计数。从系统层面的 arena-&gt;pool-&gt;block，到对象层面的各种对象池共享机制。 为了解决循环引用，Python 又引入了标记清除和分代收集两种技术。将可能出现循环引用的对象，通通关联到 generations 上。用三个元素，来表示三个不同的代。在每次创建对象时，根据 分代数量，判断是否需要进行分代回收。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 内存管理机制]]></title>
    <url>%2F2018%2F08%2F05%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.14.Python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考 PEP445 default-memory-allocators 内存策略1234567891011121314151617181920212223242526An object allocator for Python. Here is an introduction to the layers of the Python memory architecture, showing where the object allocator is actually used (layer +2), It is called for every object allocation and deallocation (PyObject_New/Del). This is also the place where the cyclic garbage collector operates selectively on container objects. _____ ______ ______ ________ [ int ] [ dict ] [ list ] ... [ string ] Python core |+3 | &lt;----- Object-specific memory -----&gt; | &lt;-- Non-object memory --&gt; | _______________________________ | | [ Python&apos;s object allocator ] | |+2 | ####### Object memory ####### | &lt;------ Internal buffers ------&gt; | ______________________________________________________________ | [ Python&apos;s raw memory allocator (PyMem_ API) ] |+1 | &lt;----- Python memory (under PyMem manager&apos;s control) ------&gt; | | __________________________________________________________________ [ Underlying general-purpose allocator (ex: C library malloc) ] 0 | &lt;------ Virtual memory allocated for the python process -------&gt; | ========================================================================= _______________________________________________________________________ [ OS-specific Virtual Memory Manager (VMM) ]-1 | &lt;--- Kernel dynamic storage allocation &amp; management (page-based) ---&gt; | __________________________________ __________________________________ [ ] [ ]-2 | &lt;-- Physical memory: ROM/RAM --&gt; | | &lt;-- Secondary storage (swap) --&gt; | 通过obmalloc.c这段注释，我们可以获取到很多内容： Python 内存管理，是分层次的 对象的创建、销毁、 GC 都发生在+2层 在最顶层，不同的对象有着不同的分配策略 从分层机制上看，似乎这个 allocator 不是固定的，那么是不是意味着可以自定义？答案是肯定的，在 3.6 中可以通过环境变量 PYTHONMALLOC 改变分配器，甚至是自定义，参考Environment variables。 Default Memory Allocators123456Python has a pymalloc allocator optimized for small objects (smaller orequal to 512 bytes) with a short lifetime. It uses memory mappings called“arenas” with a fixed size of 256 KiB. It falls back to PyMem_RawMalloc()and PyMem_RawRealloc() for allocations larger than 512 bytes.pymalloc is the default allocator of the PYMEM_DOMAIN_MEM (ex: PyMem_Malloc()) and PYMEM_DOMAIN_OBJ (ex: PyObject_Malloc()) domains. 如上，Py3.6 内存分配结构中，+1/+2 层都默认使用 pymalloc allocator。对 &lt;= 512字节的小对象进行了优化，共用256kb字节的“arena”空间。 123PYMEM_DOMAIN_RAW：PyMem_RawMalloc（），PyMem_RawRealloc（） ，PyMem_RawFree（）PYMEM_DOMAIN_MEM：PyMem_Malloc（），PyMem_Realloc（）， PyMem_Free（）PYMEM_DOMAIN_OBJ：PyObject_Malloc（），PyObject_Realloc（） ，PyObject_Free（） 目前存在 3 个 allocator 域，其中 PYMEM_DOMAIN_RAW 不需要持有GIL，另外两层默认都使用 pymalloc allocator，且必须持有 GIL。 +1/+2 层 API12345678910111213141516171819202122232425262728// obmalloc.ctypedef struct &#123; /* user context passed as the first argument to the 4 functions */ void *ctx; /* allocate a memory block */ void* (*malloc) (void *ctx, size_t size); /* allocate a memory block initialized by zeros */ void* (*calloc) (void *ctx, size_t nelem, size_t elsize); /* allocate or resize a memory block */ void* (*realloc) (void *ctx, void *ptr, size_t new_size); /* release a memory block */ void (*free) (void *ctx, void *ptr);&#125; PyMemAllocatorEx;static PyMemAllocatorEx _PyMem = &#123; NULL, _PyObject_Malloc, _PyObject_Calloc, _PyObject_Realloc, _PyObject_Free&#125; _PyObject ;void * PyMem_Malloc(size_t size) &#123; return _PyMem.malloc(_PyMem.ctx, size);&#125;void * PyObject_Malloc(size_t size) &#123; return _PyObject.malloc(_PyObject.ctx, size);&#125; 因为 +1/+2 层 allocator 默认是 pymalloc，所以调用的都是相同 API，PyObject_ *。 SMALL_REQUEST_THRESHOLD1234567891011121314151617/* * Max size threshold below which malloc requests are considered to be * small enough in order to use preallocated memory pools. You can tune * this value according to your application behaviour and memory needs. * * Note: a size threshold of 512 guarantees that newly created dictionaries * will be allocated from preallocated memory pools on 64-bit. * * The following invariants must hold: * 1) ALIGNMENT &lt;= SMALL_REQUEST_THRESHOLD &lt;= 512 * 2) SMALL_REQUEST_THRESHOLD is evenly divisible by ALIGNMENT * * Although not required, for better performance and space efficiency, * it is recommended that SMALL_REQUEST_THRESHOLD is set to a power of 2. */#define SMALL_REQUEST_THRESHOLD 512#define NB_SMALL_SIZE_CLASSES (SMALL_REQUEST_THRESHOLD / ALIGNMENT) SMALL_REQUEST_THRESHOLD变量，定义了小对象的阈值，默认为 512 字节。 ALIGNMENT12345678910/* * Alignment of addresses returned to the user. 8-bytes alignment works * on most current architectures (with 32-bit or 64-bit address busses). * The alignment value is also used for grouping small requests in size * classes spaced ALIGNMENT bytes apart. * * You shouldn't change this unless you know what you are doing. */#define ALIGNMENT 8 /* must be 2^N */#define ALIGNMENT_SHIFT 3 定义地址对齐大小，默认为8字节对齐。同时还用作 classes 中小对象的分组，即 8 个一组。 分配策略摘要123456789101112131415161718192021222324252627/* * For small requests, the allocator sub-allocates &lt;Big&gt; blocks of memory. * Requests greater than SMALL_REQUEST_THRESHOLD bytes are routed to the * system&apos;s allocator. 对于小对象，分配器将从 block 中分配，超过阈值512字节，将调用 malloc 直接分配 * Small requests are grouped in size classes spaced 8 bytes apart, due * to the required valid alignment of the returned address. Requests of * a particular size are serviced from memory pools of 4K (one VMM page). * Pools are fragmented on demand and contain free lists of blocks of one * particular size class. In other words, there is a fixed-size allocator * for each size class. Free pools are shared by the different allocators * thus minimizing the space reserved for a particular size class. 小对象，按大小进行分组，因为对齐原因，间隔8个字节，即8、16、24字节。 * For small requests we have the following table: * * Request in bytes Size of allocated block Size class idx * ---------------------------------------------------------------- * 1-8 8 0 * 9-16 16 1 * ... ... ... * 505-512 512 63 * * 0, SMALL_REQUEST_THRESHOLD + 1 and up: routed to the underlying * allocator. */ 也就是说，对于小对象，会阶段性的分配固定大小的字节数。例如 10 字节，会分配一个 idx=1, size=16字节的block。对于 0 或 大于阈值的对象，会委托给底层的 malloc 进行分配。 block123456789101112/* When you say memory, my mind reasons in terms of (pointers to) blocks */typedef uint8_t block;/* Pool for small blocks. */struct pool_header &#123; union &#123; block *_padding; uint count; &#125; ref; /* number of allocated blocks */ block *freeblock; /* pool's free list head */ uint szidx; /* block size class index */ ...&#125;;typedef struct pool_header *poolp; 可以发现，一个 block 就是一个地址，就是一个 pool 中的一部分。 Poolpool 结构12345678/* * Size of the pools used for small blocks. Should be a power of 2, * between 1K and SYSTEM_PAGE_SIZE, that is: 1k, 2k, 4k. */#define SYSTEM_PAGE_SIZE (4 * 1024)#define SYSTEM_PAGE_SIZE_MASK (SYSTEM_PAGE_SIZE - 1)#define POOL_SIZE SYSTEM_PAGE_SIZE /* must be 2^N */#define POOL_SIZE_MASK SYSTEM_PAGE_SIZE_MASK pool 是一组大小相等的 block 的集合，一个 pool 大小默认为一个系统页表大小，即 4k。 1234567891011121314typedef uint8_t block;struct pool_header &#123; union &#123; block *_padding; uint count; &#125; ref; /* number of allocated blocks */ block *freeblock; /* 下一个可用 block 起始位置 */ struct pool_header *nextpool; /* next pool of this size class */ struct pool_header *prevpool; /* previous pool "" */ uint arenaindex; /* index into arenas of base adr */ uint szidx; /* block size class index */ uint nextoffset; /* 下一个可用 block 的偏移量 */ uint maxnextoffset; /* 最大 有效 偏移量 */&#125;;typedef struct pool_header *poolp; pool_header 指向 pool 的起始位置，除了 header 本身所占空间，剩下的都是 block 可用内存。pool-&gt;szidx 指定了 class size index，即指定了这个 pool 所有 block 的大小。 pool 状态12345678910111213141516used state 初始状态，至少有一个 block 在用，至少有一个 block 未空 通过 pool_header-&gt;nextpool/prevpool 组成双向链表 只剩一个未用时，使用 malloc 会转换为 full state 只剩一个在用时，使用 free 会转换为 empty statefull state 全部在用 从 usedpools[] list 解链，不与任何东西链接在一起 在转换为 used state 之前，nextpool/prevpool 是没有意义的 在 free 之后，会转换为 used state，并重新放入 usedpools[] 表头empty state 全部未用 不在 usedpools[] 链上 其 nextpool 指向对应的 arena_object&apos;s 表头 prevpool 是没有意义的 如果下一次使用的 class size 与之前相同，就能跳过一些初始化环节 Pool 有三种状态，并且存在一个 usedpools[]，将可以使用的 pool，组成双向链表。 Pool init12345678910111213141516171819202122232425262728init_pool: /* 处理 usedpools[] 此处略，见 Arena.usedpools */ pool-&gt;ref.count = 1; // 已分配数 1 if (pool-&gt;szidx == size) &#123; bp = pool-&gt;freeblock; pool-&gt;freeblock = *(block **)bp; if (use_calloc) memset(bp, 0, nbytes); return (void *)bp; &#125; // 设置 class size index pool-&gt;szidx = size; // 计算实际 block 大小：(size+1) &lt;&lt; ALIGNMENT_SHIFT=3 size = INDEX2SIZE(size); // 第一个 blcok 位置，跳过 header 部分 bp = (block *)pool + POOL_OVERHEAD; // 下一个可用 blcok 偏移量，跳过 头+ 1个 block pool-&gt;nextoffset = POOL_OVERHEAD + (size &lt;&lt; 1); // 最大偏移量：池大小 - 最后一个 block pool-&gt;maxnextoffset = POOL_SIZE - size; // 下一个可用 block 起始位置 pool-&gt;freeblock = bp + size; // 构建 freeblock 链表头(尾) *(block **)(pool-&gt;freeblock) = NULL; if (use_calloc) memset(bp, 0, nbytes); // 返回第一个 block 指针 return (void *)bp; 初始化完成后，内存布局见下图：上图，实线是指针指向，虚线是数值等于。 freeblock 链表12*(block **)p = lastfree = pool-&gt;freeblock;pool-&gt;freeblock = (block *)p; 释放 block 时，pool-&gt;freeblock 指向下一个可用的 block 起始位置，但 *freeblock为 NULL。将要释放的 p，所指向地址的值 *p设置为 freeblock。通过一种巧妙地利用删除了的 block，构建链表。见图： Arena1234567891011#define ARENA_SIZE (256 &lt;&lt; 10) /* 256KB */struct arena_object &#123; uintptr_t address; // pool 起始地址 block* pool_address; // 指向下一个 pool uint nfreepools; // 可用的 pool 数 uint ntotalpools; // pool 总数 struct pool_header* freepools; // 可用 pool 指针 struct arena_object* nextarena; struct arena_object* prevarena;&#125;; 通过 malloc/mmap 获取虚拟地址空间，每个 arenas 默认为 256k。而默认 pool 为 4k，意味着每个 arena 默认有64个 pool。通过内部的两个指针，组成跟 pool 类似的链式结构。 pymalloc allocator 会创建一个 256kb 的固定的大小，作为 arena 维护的空间。用完后，会再再次创建一倍空间，默认是没有上限的。 arena 内部只是管理着 pool 的集合，并未指定集合中 pool 的类型。意味着其 pool-&gt;szidx 可以是不同大小。 arena 链123456789101112131415// 单链表，未使用的 arenastatic struct arena_object* unused_arena_objects = NULL;// 双向链表，部分可用的 arenastatic struct arena_object* usable_arenas = NULL;/* 所有 pool 都未用： nextarena 指向下一个 都未用的 arena unused_arena_objects 为表头，指向 当前 所有 pool 都已用： nextarena/prevarena 无意义，不在链上 部分 pool 可用： nextarena/prevarena 与 其他 usable_arenas 组成双向链表 usable_arenas 为表头，指向 当前*/ 注意，所有的 arena 都在数组 arenas 中。通过 maxarenas 记录个数。 new_arena()1234567891011#define INITIAL_ARENA_OBJECTS 16static struct arena_object* arenas = NULL;static uint maxarenas = 0;static struct arena_object* new_arena(void)&#123; if (unused_arena_objects == NULL) &#123; /* 不存在 未使用的 arena 链表，先构建一个 */ ... &#125; /* 获取一个 unused_arena_objects */&#125; 申请 arena 大概分为两步，第一步先判断是否需要扩充未使用的 unused_arena_objects，第二获取到unused_arena_objects。此处，调用位置在 Alloc 不存在可用 pool。 创建 unused_arena_objects123456789101112131415161718192021222324252627static struct arena_object* new_arena(void)&#123; /* 若 不存在可用的 arena，就先申请一个 arena 头部的空间 */ if (unused_arena_objects == NULL) &#123; uint i; uint numarenas; size_t nbytes; // 申请的 arena 数目，默认 16 个，每次都翻倍 numarenas = maxarenas ? maxarenas &lt;&lt; 1 : INITIAL_ARENA_OBJECTS; if (numarenas &lt;= maxarenas) return NULL; /* overflow */ // 16个 arena 头部数据长度 sizeof(arena_object) nbytes = numarenas * sizeof(*arenas); // PyMem_Raw 调用 realloc arenaobj = (struct arena_object *)PyMem_RawRealloc(arenas, nbytes); arenas = arenaobj; /* arenas中，所有 pool 都未用, nextarena 指向下一个 arena */ for (i = maxarenas; i &lt; numarenas; ++i) &#123; arenas[i].address = 0; /* 此时不存在 pool集合 */ /* 构造链表，表头 arena-&gt;next 为 NULL */ arenas[i].nextarena = i &lt; numarenas - 1 ? &amp;arenas[i+1] : NULL; &#125; // unused_arena_objects 指向 表头 unused_arena_objects = &amp;arenas[maxarenas]; maxarenas = numarenas; &#125; 申请一组 arena 头部空间。unused_arena_objects 指向的是数组尾部，即”表头”。 存在 unused_arena_objects123456789101112131415161718192021222324252627282930313233343536373839404142static struct arena_object* new_arena(void)&#123; /* 弹出未使用 arenae 链表 unused_arena_objects 第一个 */ arenaobj = unused_arena_objects; unused_arena_objects = arenaobj-&gt;nextarena; /* 申请 arena_object 管理的内存 _PyObject_Arena.alloc 是一个区分平台的函数 Linux 上，如不用 nmap，会直接调用 malloc(256kb) */ address = _PyObject_Arena.alloc(_PyObject_Arena.ctx, ARENA_SIZE); if (address == NULL) &#123; /* 创建失败，把 arena 放回未用链表头 */ arenaobj-&gt;nextarena = unused_arena_objects; unused_arena_objects = arenaobj; return NULL; &#125; // 改变 arena 指向的 pool 地址 arenaobj-&gt;address = (uintptr_t)address; ++narenas_currently_allocated; ++ntimes_arena_allocated; if (narenas_currently_allocated &gt; narenas_highwater) narenas_highwater = narenas_currently_allocated; /* 可用 pool 指针，释放 pool 时用到 */ arenaobj-&gt;freepools = NULL; /* pool_address 指向第一个 pool */ arenaobj-&gt;pool_address = (block*)arenaobj-&gt;address; /* nfreepools 为可用的 pool 数 256k/4k = 64 */ arenaobj-&gt;nfreepools = ARENA_SIZE / POOL_SIZE; // 将 pool 起始地址调整为系统页的边界 excess = (uint)(arenaobj-&gt;address &amp; POOL_SIZE_MASK); if (excess != 0) &#123; // 弹出一个 立马使用 --arenaobj-&gt;nfreepools; // 改变 下一个指向位置 arenaobj-&gt;pool_address += POOL_SIZE - excess; &#125; arenaobj-&gt;ntotalpools = arenaobj-&gt;nfreepools; return arenaobj;&#125; 创建新的 arena 时，判断存在可用的 unused_arena_objects，将执行上面的代码。把一个 arena 从链中摘下，申请256kb内存，构建出64个 pool 集合。返回该 arena，跳转到Alloc 不存在可用 pool arena 中的 pool 链12345678910111213141516171819202122struct arena_object &#123; uintptr_t address; // 自身起始地址 block* pool_address; // 指向下一个 pool struct pool_header* freepools; // 未用 pools 表头&#125;;struct pool_header &#123; block *freeblock; /* 下一个可用 block 起始位置 */ struct pool_header *nextpool; /* next pool of this size class */ struct pool_header *prevpool; /* previous pool "" */&#125;;/*全部未用 empty pool 中所有 block 都未使用 通过 freepools + nextpool，构成单向链表部分使用 used pool 中存在被使用，且存在未被使用 block 通过 usedpools[] 维护链表全部使用 full 各自独立，不存在 链*/ 注意了，arena 中的 pool 并非相同大小，而 pool-&gt;nextpoll 是相同大小的 szidx。那么，这就意味着，必须有个地方，把 arena pool size 给关联起来，那就是 usedpools。 usedpools指针数组定义1234567891011121314151617181920typedef struct pool_header *poolp;// NB_SMALL_SIZE_CLASSES = SMALL_REQUEST_THRESHOLD / ALIGNMENT = 512/8 = 64static poolp usedpools[2 * ((NB_SMALL_SIZE_CLASSES + 7) / 8) * 8] = &#123; PT(0), PT(1), PT(2), PT(3), PT(4), PT(5), PT(6), PT(7) ...&#125;// 等效于#define PTA(x) ((poolp )((uint8_t *)&amp;(usedpools[2*(x)]) - 2*sizeof(block *)))static poolp usedpools[2 * 64] = &#123; PTA(0), PTA(0), PTA(1), PTA(1), ...&#125;/* 指针，`block *` 为四个字节 那么 usedpools[2*(x=3)]，所指向的值为 usedpools[6] - 8 整个 usedpools 数组，都是指针，都是4个字节 那么，`- 8`，就是位置左移 2，即指向了`usedpools[4]` 意思就是，usedpools[6] == &amp;usedpools[4]*/ 再来看 pool_header 的定义。 pool 结构体定义12345678910111213141516struct pool_header &#123; union &#123; block *_padding; uint count; &#125; ref; /* number of allocated blocks */ block *freeblock; /* 下一个可用 block 起始位置 */ struct pool_header *nextpool; /* next pool of this size class */ struct pool_header *prevpool; /* previous pool "" */ uint arenaindex; /* index into arenas of base adr */ uint szidx; /* block size class index */ uint nextoffset; /* 下一个可用 block 的偏移量 */ uint maxnextoffset; /* 最大 有效 偏移量 */&#125;/* ref + *freeblock，也正好是 8 个字节 pool-&gt;nextpool，就是 pool 指针后移8个字节 pool-&gt;prevpool，就是 pool 指针后移8+4个字节*/ 巧合的 8 字节，意味着有阴谋！ trick12345678910111213141516usedpools[6] == &amp;usedpools[6] -8 == &amp;usedpools[4]&gt;&gt;&gt; 初始状态 usedpools[6] 就是指向 usedpools[4]usedpools[6]-&gt;nextpool == &amp;usedpools[4] +8 == usedpools[6]&gt;&gt;&gt; 初始状态 usedpools[6]-&gt;nextpool 就是 usedpools[6]&gt;&gt;&gt; 初始状态 usedpools[i+i] == usedpools[i+i]-&gt;nextpool // 注意这里，很重要usedpools[6]-&gt;prevpool == &amp;usedpools[4] +12 == usedpools[7]&gt;&gt;&gt; 初始状态 usedpools[6]-&gt;prevpool，就是 usedpools[7]执行 usedpools[6]-&gt;nextpool = 一个 i=3 的 pool&gt;&gt;&gt; 就是对 usedpools 数组赋值，将位置 6 存储为一个 pool 地址&gt;&gt;&gt; 再然后，就可以直接用 usedpools[6]，获取到该 pool 地址执行 usedpools[6]-&gt;prevpool = 一个 i=3 的 pool&gt;&gt;&gt; 就是对 usedpools 数组赋值，将位置 7 存储为一个 pool 地址 嘿，饶了大半圈，结果原来时这么回事。用两个位置指针，模拟出 pool_head 的结构。初始状态[i+i] == [i+i]-&gt;next，一旦调用 [i+i]-&gt;next= pool，那么就可以直接取用 [i+i]。 再来看看如何对 usedpools 进行操作。 add by Alloc init1234567891011121314151617static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123;init_pool: next = usedpools[size + size]; /* 此时 [6] = &amp;[4] */ pool-&gt;nextpool = next; // pool-&gt;next = &amp;[4] pool-&gt;prevpool = next; // pool-&gt;prev = &amp;[4] next-&gt;nextpool = pool; // &amp;[4]-&gt;next == [6] &gt;&gt;&gt; [6] = pool next-&gt;prevpool = pool; // &amp;[4]-&gt;prev == [7] &gt;&gt;&gt; [7] = pool /* 结果就是: A-&gt;nextpool == &amp;[4] A-&gt;prevpool == &amp;[4] &amp;[4]-&gt;nextpool == [6] == A &amp;[4]-&gt;prevpool == [7] == A */&#125; 在 Pool init 中，我们省略了部分代码如上。可以发现，在初始化 pool 时，构造出一个双向链表，其中只有两个节点，A 与 虚拟的 usedpools。 add by Free fullFree block 时，遇到一个 full poll，会将其挂载到 usedpools[] 双向链表上。下面分两种情况查看：123456789101112131415static void _PyObject_Free(void *ctx, void *p) &#123; next = usedpools[size + size]; // &amp;[4] prev = next-&gt;prevpool; // [7] pool-&gt;nextpool = next; // A-&gt;nextpool == &amp;[4] pool-&gt;prevpool = prev; // A-&gt;prevpool == [7] == &amp;[4] next-&gt;prevpool = pool; // [7] = pool prev-&gt;nextpool = pool; // [6] = pool&#125;/* usedpools 为初始状态，结果等于 init pool。 A-&gt;nextpool == &amp;[4] A-&gt;prevpool == &amp;[4] &amp;[4]-&gt;nextpool == [6] == A &amp;[4]-&gt;prevpool == [7] == A*/ 1234567891011121314151617181920212223242526static void _PyObject_Free(void *ctx, void *p) &#123; next = usedpools[size + size]; // A prev = next-&gt;prevpool; // A-&gt;prevpool == &amp;[4] /* insert pool before next: prev &lt;-&gt; pool &lt;-&gt; next */ pool-&gt;nextpool = next; // B-&gt;nextpool == A pool-&gt;prevpool = prev; // B-&gt;prevpool == &amp;[4] next-&gt;prevpool = pool; // A-&gt;prevpool = B prev-&gt;nextpool = pool; // &amp;[4]-&gt;next == [6] = B&#125;/* usedpools 已经挂载了一个 A，现在新挂一个 B A-&gt;nextpool == &amp;[4] A-&gt;prevpool == B B-&gt;nextpool == A B-&gt;prevpool == &amp;[4] &amp;[4]-&gt;nextpool == [6] == B &amp;[4]-&gt;prevpool == [7] == A注意，不是直接挂载到头上，而是插入其中 &amp;[4] -next-&gt; B -next-&gt; A &amp;[4] &lt;-prev- B &lt;-prev- A但，通过 usedpools[6] 获取到的却是刚刚插入的 B*/ remove by Alloc full12345678910111213141516static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123;/* 假设： A-&gt;nextpool == &amp;[4] A-&gt;prevpool == &amp;[4] &amp;[4]-&gt;nextpool == [6] == A &amp;[4]-&gt;prevpool == [7] == A*/ /* Pool is full, unlink from used pools. */ next = pool-&gt;nextpool; // &amp;[4] pool = pool-&gt;prevpool; // &amp;[4] next-&gt;prevpool = pool; // [7] = &amp;[4] pool-&gt;nextpool = next; // [6] = &amp;[4] ...&#125; 在 Pool 满了之后，只是简单的将自己从双向链表中 摘掉。如果只有 1 个 usedpool，就会把 usepools 恢复到最开始的状态。 remove by Free empty123456789101112131415161718192021static void _PyObject_Free(void *ctx, void *p) &#123;/* 假设： A-&gt;nextpool == &amp;[4] A-&gt;prevpool == B B-&gt;nextpool == A B-&gt;prevpool == &amp;[4] &amp;[4]-&gt;nextpool == [6] == B &amp;[4]-&gt;prevpool == [7] == A*/ next = pool-&gt;nextpool; // A prev = pool-&gt;prevpool; // &amp;[4] next-&gt;prevpool = prev; // A-&gt;prevpool = &amp;[4] prev-&gt;nextpool = next; // &amp;[4]-&gt;nextpool = A&#125;/* 结果是： &amp;[4] -next-&gt; A &amp;[4] &lt;-prev- A*/ 在 Free 时，遇到 emtyp pool，如果 usedpool，不止一个，会将自己从双向链表中 摘掉。 PyObject_Alloc1234567891011121314151617static void * _PyObject_Malloc(void *ctx, size_t nbytes) &#123; return _PyObject_Alloc(0, ctx, 1, nbytes);&#125;static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize) &#123; size_t nbytes = nelem * elsize; /* The small block allocator. */ if ((nbytes - 1) &lt; SMALL_REQUEST_THRESHOLD) &#123; ... &#125; void *result; if (use_calloc) result = PyMem_RawCalloc(nelem, elsize); else result = PyMem_RawMalloc(nbytes); return result;&#125; 从这里，可以看出，小对象与大对象的处理方式不同，大对象直接调用 mallco。下面，主要看小对象的处理方式。 Alloc 存在可用 pool1234567891011121314151617181920212223242526272829303132333435363738394041static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123; // 前提条件，小对象 size = (uint)(nbytes - 1) &gt;&gt; ALIGNMENT_SHIFT; // 计算 pool-&gt;szidx pool = usedpools[size + size]; // 获取可用 szidx= size 的可用pool /* usedpools 中存在可用 pool */ if (pool != pool-&gt;nextpool) &#123; ++pool-&gt;ref.count; // 增加 使用计数 bp = pool-&gt;freeblock; // 可用的 blcok 起始地址 // 将 freeblock 在链表上移动，如果未到达尾部，则直接返回 if ((pool-&gt;freeblock = *(block **)bp) != NULL) &#123; if (use_calloc) memset(bp, 0, nbytes); return (void *)bp; &#125; // 已经到达 freelist 尾部，但存在 未使用过的 block if (pool-&gt;nextoffset &lt;= pool-&gt;maxnextoffset) &#123; // 下一个可用 block 起始位置，指向上一个 block 的结束为止 pool-&gt;freeblock = (block*)pool + pool-&gt;nextoffset; // 偏移位置后移 block size pool-&gt;nextoffset += INDEX2SIZE(size); // 再次设置 freelist 链表尾 *(block **)(pool-&gt;freeblock) = NULL; if (use_calloc) memset(bp, 0, nbytes); return (void *)bp; &#125; /* Pool is full, unlink from used pools. */ next = pool-&gt;nextpool; pool = pool-&gt;prevpool; next-&gt;prevpool = pool; pool-&gt;nextpool = next; if (use_calloc) memset(bp, 0, nbytes); return (void *)bp; &#125;&#125; 注意其中起始的两句，pool = usedpools[size + size] if(pool != pool-&gt;nextpool)。 在前面 usedpools 中，我们已经知道：初始状态 usedpools[i+i] == usedpools[i+i]-&gt;nextpool。那么，意味着此次，进入 if 的条件就是存在可用的 pool。 Alloc 不存在可用 pool1234567891011static struct arena_object* usable_arenas = NULL;static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123; // 前提条件 pool == pool-&gt;nextpool if (usable_arenas == NULL) &#123; /* 创建一个 arena */ usable_arenas = new_arena(); usable_arenas-&gt;nextarena = usable_arenas-&gt;prevarena = NULL; &#125; Alloc 不存在可用 free pool，即 usedpools 中不存在可用 pool。若不存在 可用arena，调用 new_arena() 获取一个 arena。接着在把它前后指针都置为NULL.。 Alloc 创建 pool12345678910111213141516171819202122232425262728static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123; /* 前提条件： pool == pool-&gt;nextpool usable_arenas != NULL */ /* Try to get a cached free pool. */ pool = usable_arenas-&gt;freepools; if (pool != NULL) &#123; /* 找到一个可用的 pool */ usable_arenas-&gt;freepools = pool-&gt;nextpool; --usable_arenas-&gt;nfreepools; // 处理 =0 的情况，从链中摘掉 usable_arenas ... init_pool: &#123; /* 初始化 pool */ ... return (void *)bp; &#125; &#125; /* Carve off a new pool. */ assert(usable_arenas-&gt;nfreepools &gt; 0); assert(usable_arenas-&gt;freepools == NULL); pool = (poolp)usable_arenas-&gt;pool_address; ... goto init_pool;&#125; 在 new_arena() 中，初始化时设定了arenaobj-&gt;freepools = NULL;，因此直接走 Carve off a new pool 环节。 Carve off a new pool1234567891011121314151617181920212223242526272829303132static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)&#123; /* 前提条件： usable_arenas != NULL usable_arenas-&gt;freepools == NULL */ /* Carve off a new pool. */ pool = (poolp)usable_arenas-&gt;pool_address; /* arenaindex: pool 所在 arena 位于 arenas 数组中的序号 */ pool-&gt;arenaindex = (uint)(usable_arenas - arenas); assert(&amp;arenas[pool-&gt;arenaindex] == usable_arenas); pool-&gt;szidx = DUMMY_SIZE_IDX; // 0xffff // 指向下一个 pool usable_arenas-&gt;pool_address += POOL_SIZE; // 调整剩余数量 --usable_arenas-&gt;nfreepools; if (usable_arenas-&gt;nfreepools == 0) &#123; assert(usable_arenas-&gt;nextarena == NULL || usable_arenas-&gt;nextarena-&gt;prevarena == usable_arenas); /* 全部Pool 用完，Unlink the arena */ usable_arenas = usable_arenas-&gt;nextarena; if (usable_arenas != NULL) &#123; usable_arenas-&gt;prevarena = NULL; assert(usable_arenas-&gt;address != 0); &#125; &#125; goto init_pool;&#125; 其中，涉及到arenaindex的使用，见PyObject_Free.address_in_range。 小结123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static void *_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize) &#123; // 如果是小对象，&lt;256字节，使用内存池 arena if ((nbytes - 1) &lt; SMALL_REQUEST_THRESHOLD) &#123; size = (uint)(nbytes - 1) &gt;&gt; ALIGNMENT_SHIFT; // 计算 pool-&gt;szidx pool = usedpools[size + size]; // 获取可用 szidx= size 的可用pool /* usedpools 中存在可用 pool */ if (pool != pool-&gt;nextpool) &#123; bp = pool-&gt;freeblock; // 分配 block /* 判断处理 freeblocks 链表状态： 存在已释放，未到达 freelist 尾部 已经到达 freelist 尾部，但存在 free block Pool is full, unlink from used pools. */ ... &#125; /* 不存在可用的pool, 那么就找一个 arena 创建 pool */ if (usable_arenas == NULL) &#123; /* 扩充 arenas 空间 */ usable_arenas = new_arena(); usable_arenas-&gt;nextarena = usable_arenas-&gt;prevarena = NULL; &#125; /* 从表头的 arena 中获取一个 pool */ pool = usable_arenas-&gt;freepools; if (pool != NULL) &#123; /* 找到一个可用的 pool */ usable_arenas-&gt;freepools = pool-&gt;nextpool; --usable_arenas-&gt;nfreepools; // 处理 =0 的情况，从链中摘掉 usable_arenas ... init_pool: &#123; /* 初始化 pool */ ... return (void *)bp; &#125; &#125; /* 获取失败，就创建一个 pool，然后转入：初始化 */ assert(usable_arenas-&gt;nfreepools &gt; 0); assert(usable_arenas-&gt;freepools == NULL); pool = (poolp)usable_arenas-&gt;pool_address; ... goto init_pool; &#125; // 否则，使用 mallcoc return PyMem_RawMalloc(nbytes);&#125; 复杂的逻辑，主要难点在于： 通过已经释放的区域，当做链表的中间环节 pool 内部指向， freeblocks 链表， arena 中的 pool 分布， arena 集合的分布， PyObject_Free12345678910static void _PyObject_Free(void *ctx, void *p) &#123; // 找到最近的 pool 地址 pool = POOL_ADDR(p); // 根据 pool，找到 arena，判断 p 是否在其中 if (address_in_range(p, pool)) &#123; ... // 小对象 return; &#125; PyMem_RawFree(p);&#125; 下面主要查看小对象的处理。 POOL_ADDR1234567pool = POOL_ADDR(p);/* 向下，找到距离 p 最近的 pool 地址 */#define POOL_ADDR(P) ((poolp)_Py_ALIGN_DOWN((P), POOL_SIZE))/* Round pointer "p" down to the closest "a"-aligned address &lt;= "p". */#define _Py_ALIGN_DOWN(p, a) ((void *)((uintptr_t)(p) &amp; ~(uintptr_t)((a) - 1))) address_in_range123456789static bool ATTRIBUTE_NO_ADDRESS_SAFETY_ANALYSISaddress_in_range(void *p, poolp pool)&#123; // &amp;arenas[pool-&gt;arenaindex] == pool 所在 arena uint arenaindex = *((volatile uint *)&amp;pool-&gt;arenaindex); return arenaindex &lt; maxarenas &amp;&amp; (uintptr_t)p - arenas[arenaindex].address &lt; ARENA_SIZE &amp;&amp; arenas[arenaindex].address != 0;&#125; 获取到 pool 所在 arena 地址，在通过 .address 获取到 pool 的起始地址。在创建 unused_arena_objects 中，所有初始 arena.address 都为0。通过计算指针差值，能就能得出 p 是否在 arena 中。 Free full pool12345678910111213141516171819202122232425static void _PyObject_Free(void *ctx, void *p) &#123; // 前提条件：address_in_range(p, pool) // 设置 freeblocks 链表 *(block **)p = lastfree = pool-&gt;freeblock; pool-&gt;freeblock = (block *)p; // lastfree 有效，表明当前 pool 未满 if (lastfree) &#123; ... &#125; // 当前 pool 处于 full 状态，释放 block 后，需要转为 used 状态 // 将 pool 放入 usedpools 头部 --pool-&gt;ref.count; size = pool-&gt;szidx; next = usedpools[size + size]; prev = next-&gt;prevpool; /* insert pool before next: prev &lt;-&gt; pool &lt;-&gt; next */ pool-&gt;nextpool = next; pool-&gt;prevpool = prev; next-&gt;prevpool = pool; prev-&gt;nextpool = pool; return;&#125; 如上，当 pool 已满时，释放后 block 后，需要将 pool 连接到可用的 pools 上。 Free used pool123456789101112131415161718192021222324static void _PyObject_Free(void *ctx, void *p) &#123; // 前提条件：address_in_range(p, pool) *(block **)p = lastfree = pool-&gt;freeblock; if (lastfree) &#123; /* ref.count &gt; 1 表明，还有其他的 pool 可使用 */ if (--pool-&gt;ref.count != 0) &#123; return; &#125; /* ref.count==1, free 之后就 emtpy了，应脱离 usedpools[] */ next = pool-&gt;nextpool; prev = pool-&gt;prevpool; next-&gt;prevpool = prev; prev-&gt;nextpool = next; /* 把 pool 关联到 arena-&gt;freepools 链上 */ struct arena_object* ao = &amp;arenas[pool-&gt;arenaindex]; pool-&gt;nextpool = ao-&gt;freepools; ao-&gt;freepools = pool; uint nf = ++ao-&gt;nfreepools; /* All the rest is arena management. */ ... &#125; 当释放一个 block，若 Pool 本身就是 used 状态，无需更多操作。反之，若 Pool 从 used 变为 empty 时，不仅要处理 pool，脱离 usedpools 链表，还要处理 arena。 Free arena management1234567891011121314151617181920212223static void _PyObject_Free(void *ctx, void *p) &#123; // 前提条件：address_in_range(p, pool) *(block **)p = lastfree = pool-&gt;freeblock; if (lastfree) &#123; /* All the rest is arena management. */ // ntotalpools &gt; pool-&gt;ref.count &gt; 1，不止一个且未满 struct arena_object* ao = &amp;arenas[pool-&gt;arenaindex]; uint nf = ++ao-&gt;nfreepools; // Case 1: pool 全部 free，销毁 arena if (nf == ao-&gt;ntotalpools) &#123;&#125; // Case 2: 仅此一个 pool 可用，挂载到 usable_arenas 链上 if (nf == 1) &#123;&#125; // Case 3: 如果当前 pool &lt;= next-&gt;nf，什么都不干 ... // Case 4：调整 usable_arenas 链表顺序，快满的 arena 首先被使用 ... return ; &#125;&#125; 在 pool 从 used 转变为 empty 时，arena 有可能出现 全部 free，以及，仅此一个 pool 可用两种状态。当满足仅此一个pool 为 usable 时，又要挂载链表，调整顺序。 Free a block then arena empty12345678910111213141516171819202122232425262728293031323334353637383940414243if (nf == ao-&gt;ntotalpools) &#123; // Case 1: pool 全部 free，销毁 arena /* Case 1. First unlink ao from usable_arenas. */ assert(ao-&gt;prevarena == NULL || ao-&gt;prevarena-&gt;address != 0); assert(ao -&gt;nextarena == NULL || ao-&gt;nextarena-&gt;address != 0); /* 调整 usable_arenas 链表 */ if (ao-&gt;prevarena == NULL) &#123; // ao 在表头 usable_arenas = ao-&gt;nextarena; assert(usable_arenas == NULL || usable_arenas-&gt;address != 0); &#125; else &#123; // ao 不在表头 assert(ao-&gt;prevarena-&gt;nextarena == ao); ao-&gt;prevarena-&gt;nextarena = ao-&gt;nextarena; &#125; if (ao-&gt;nextarena != NULL) &#123; // ao 不在末尾 assert(ao-&gt;nextarena-&gt;prevarena == ao); ao-&gt;nextarena-&gt;prevarena = ao-&gt;prevarena; &#125; // 挂载到 unused_arena_objects 链表 ao-&gt;nextarena = unused_arena_objects; unused_arena_objects = ao; /* Free the entire arena. ao-&gt;address */ _PyObject_Arena.free(_PyObject_Arena.ctx, (void *)ao-&gt;address, ARENA_SIZE); ao-&gt;address = 0; /* mark unassociated */ --narenas_currently_allocated; UNLOCK(); return;&#125; 如上，在 free block 遇到一个 emtpy 的 arena 时，会调整 used/unused 链表，并且 free(arena)。 Free a block then arena can use12345678910111213// Case 2: 仅此一个 pool 可用，挂载到 usable_arenas 链上if (nf == 1) &#123; ao-&gt;nextarena = usable_arenas; ao-&gt;prevarena = NULL; if (usable_arenas) usable_arenas-&gt;prevarena = ao; usable_arenas = ao; assert(usable_arenas-&gt;address != 0); UNLOCK(); return;&#125; 仅此一个 Pool 可用，那么意味着arena 之前不在 usable_arenas 链表上，直接挂载上去。 Free a block then 调整 usable 链表1234567// Case 3: 如果当前 pool &lt;= next-&gt;nf，什么都不干if (ao-&gt;nextarena == NULL || nf &lt;= ao-&gt;nextarena-&gt;nfreepools) &#123; return;&#125;// Case 4：调整 usable_arenas 链表顺序，快满的 arena 首先被使用 如上，调整 usable 顺序，始终保持 most full arena 在链表头，最先被使用。 小结Python 主要围绕几张链表来管理内存： free block 单链表，由 pool 管理 free pool 单链表，由 usedpools 管理 usable arena 双向链表，由 usable_arenas 管理 unusable arena 单链表，由 unused_arena_objects 管理 free 操作的对象是 block，blok 受 pool 管理，pool 在 arena 中，所有arena 构成数组 arenas。 free block 后，要将 block 挂载到 pool-&gt;freeblocks 上 如果 pool 变为 used，就把 pool 挂载到 usedpools[] 上 如果所在 arena，仅此一个可用，还得把 arena 从 unused_arena 脱离，挂载到 usable 上 如果 pool 变为 empty，就把 pool 从 usedpools 脱离，挂载到 arena-&gt;freepools 上 如果所在 arena 都 empty，还得把 arena 从 usable_arenas 脱离，释放内存，挂载到 unused_arena 上]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 多线程机制]]></title>
    <url>%2F2018%2F08%2F04%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.13.Python%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言Python 的 GIL 可谓“大名鼎鼎”，正是由它控制着字节码解释器的执行权限。跟操作系统的进程调度一样，Python 必然会存在一个调度机制，决定了什么时候该进行线程切换。Python 也通过时间片的方式，挂起当前线程，切换其他线程。1234567sys.getcheckinterval()、sys.setcheckinterval()在 Python3.2 中已经被弃用sys.getswitchinterval()、sys.setswitchinterval()/* microseconds (the Python API uses seconds, though) */#define DEFAULT_INTERVAL 5000static unsigned long gil_interval = DEFAULT_INTERVAL; 从3.2起，Python 的线程时间片控制，由以前的指令数改为了时间控制，默认0.005秒，可通过API进行更改。线程调度策略，依然是由操作系统决定，解释器仅参与GIL的释放和申请。 _thread123456789101112131415// _threadmodule.cPyMODINIT_FUNCPyInit__thread(void)&#123; m = PyModule_Create(&amp;threadmodule); PyThread_init_thread(); return m;&#125;static struct PyModuleDef threadmodule = &#123; ... &#125;static PyMethodDef thread_methods[] = &#123; &#123;"start_new_thread",(PyCFunction)thread_PyThread_start_new_thread, METH_VARARGS, start_new_doc&#125;, ...&#125; _thread是一个标准的 C 模块，通过上面这熟悉的套路，让我们可以直接在 Python 中使用 C 函数。创建线程正是通过_thread.start_new_thread()实现。 start_new_thread1234567891011121314151617181920212223242526272829static PyObject *thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)&#123; PyObject *func, *args, *keyw = NULL; struct bootstate *boot; long ident; if (!PyArg_UnpackTuple(fargs, "start_new_thread", 2, 3, &amp;func, &amp;args, &amp;keyw)) return NULL; assert PyCallable_Check(func), "first arg must be callable" assert PyTuple_Check(args), "2nd arg must be a tuple" assert keyw == NULL or PyDict_Check(keyw), "optional 3rd arg must be a dictionary" /* 创建 bootstate 结构 */ boot = PyMem_NEW(struct bootstate, 1); boot-&gt;interp = PyThreadState_GET()-&gt;interp; boot-&gt;func = func; boot-&gt;args = args; boot-&gt;keyw = keyw; boot-&gt;tstate = _PyThreadState_Prealloc(boot-&gt;interp); /* 初始化 Python 多线程环境 */ PyEval_InitThreads(); /* 创建系统 原生线程 */ ident = PyThread_start_new_thread(t_bootstrap, (void*) boot); return PyLong_FromLong(ident);&#125; 如上，在C函数中，func/args都是通过参数 fargs 以元组的形式传入。然后创建 boot 结构体，初始化线程环境，创建线程，返回线程 id。 PyEval_InitThreads1234567891011// ceval.c.230void PyEval_InitThreads(void)&#123; if (gil_created()) return; create_gil(); take_gil(PyThreadState_GET()); main_thread = PyThread_get_thread_ident(); if (!pending_lock) pending_lock = PyThread_allocate_lock();&#125; 此时，主线程暂未开启 GIL，直接进入创建 GIL环节，然后持有 GIL，创建信号量。完成后返回start_new_thread。 create_gil1234567891011121314151617static void create_gil(void)&#123;/* 基于 pthread 线程库static COND_T gil_cond; // PyCOND_T = PyCOND_T = pthread_cond_tstatic MUTEX_T gil_mutex; // MUTEX_T = PyMUTEX_T = pthread_mutex_t*/ /* 创建默认的互斥锁 pthread_mutex_init(&amp;gil_mutex, NULL) */ MUTEX_INIT(gil_mutex); /* 初始化条件变量 pthread_cond_init(&amp;gil_cond, NULL) */ COND_INIT(gil_cond); _Py_atomic_store_relaxed(&amp;gil_last_holder, 0); _Py_ANNOTATE_RWLOCK_CREATE(&amp;gil_locked); _Py_atomic_store_explicit(&amp;gil_locked, 0, _Py_memory_order_release);&#125; 利用 C 模块，创建互斥锁、初始化条件变量。改变 gil_locked 的值，完成 GIL 的创建工作。 take_gil123456789101112131415161718192021222324252627282930313233343536373839404142434445// ceval_gil.h.67static void take_gil(PyThreadState *tstate)&#123; MUTEX_LOCK(gil_mutex); // 加锁 if (!_Py_atomic_load_relaxed(&amp;gil_locked)) // 获取 GIL，若已释放，直接获取，跳转 goto _ready; while (_Py_atomic_load_relaxed(&amp;gil_locked)) &#123; // GIL 未释放 int timed_out = 0; unsigned long saved_switchnum; // 记录切换次数 saved_switchnum = gil_switch_number; // 利用 pthread_cond_tim 阻塞等待超时 COND_TIMED_WAIT(gil_cond, gil_mutex, INTERVAL, timed_out); /* 等待超时，仍未释放, 发送释放请求信号 */ if (timed_out &amp;&amp; _Py_atomic_load_relaxed(&amp;gil_locked) &amp;&amp; gil_switch_number == saved_switchnum) &#123; // 设置 gil_drop_request=1，eval_breaker=1 SET_GIL_DROP_REQUEST(); &#125; &#125;_ready: /* We now hold the GIL */ _Py_atomic_store_relaxed(&amp;gil_locked, 1); // 设置 GIL 占用 _Py_ANNOTATE_RWLOCK_ACQUIRED(&amp;gil_locked, /*is_write=*/1); if (tstate != (PyThreadState*)_Py_atomic_load_relaxed(&amp;gil_last_holder)) &#123; _Py_atomic_store_relaxed(&amp;gil_last_holder, (uintptr_t)tstate); ++gil_switch_number; &#125; if (_Py_atomic_load_relaxed(&amp;gil_drop_request)) &#123; // 重置 gil_drop_request=0 RESET_GIL_DROP_REQUEST(); &#125; if (tstate-&gt;async_exc != NULL) &#123; _PyEval_SignalAsyncExc(); &#125; MUTEX_UNLOCK(gil_mutex); // 解锁&#125; 整个申请释放GIL的过程，都被互斥锁 gil_mutex 锁住。如果 GIL 被占用，将进行等待，超时后改变全局变量，给持有线程发送信号。竞争到 GIL 后，重置全局变量，返回PyEval_InitThreads。 PyThread_allocate_lock12345678910111213141516171819static PyThread_type_lock pending_lock = 0; /* for pending calls */PyThread_type_lock PyThread_allocate_lock(void)&#123; sem_t *lock; // 声明信号量指针 int status, error = 0; if (!initialized) PyThread_init_thread(); lock = (sem_t *)PyMem_RawMalloc(sizeof(sem_t)); if (lock) &#123; // 初始化信号量，0表示仅当前进程内使用，1表示信号量初始值 status = sem_init(lock,0,1); CHECK_STATUS("sem_init"); &#125; return (PyThread_type_lock)lock;&#125; 创建一个初始状态为1的信号量，返回PyEval_InitThreads。 PyThread_start_new_thread1234567891011121314151617// ident = PyThread_start_new_thread(t_bootstrap, (void*) boot);longPyThread_start_new_thread(void (*func)(void *), void *arg)&#123; pthread_t th; // 创建线程对象 int status; if (!initialized) PyThread_init_thread(); status = pthread_create(&amp;th, (pthread_attr_t*)NULL, (void* (*)(void *))func, (void *)arg ); pthread_detach(th); // 设置为 joinable，自动释放资源 return (long) th; // 线程 id 存放在 &amp;th。&#125; 利用 pthread 库，创建新的线程，返回线程 id。此时新的线程，传入的 fun 是 函数 t_bootstrap，而参数 arg 是一个 bootstrap 结构体。 1234567struct bootstate &#123; PyInterpreterState *interp; PyObject *func; PyObject *args; PyObject *keyw; PyThreadState *tstate;&#125;; 线程开始执行，就是执行 t_bootstrap(bootstrap)。 t_bootstrap123456789101112131415161718192021static voidt_bootstrap(void *boot_raw)&#123; struct bootstate *boot = (struct bootstate *) boot_raw; PyThreadState *tstate; PyObject *res; tstate = boot-&gt;tstate; tstate-&gt;thread_id = PyThread_get_thread_ident(); _PyThreadState_Init(tstate); PyEval_AcquireThread(tstate); // 竞争 GIL nb_threads++; res = PyEval_CallObjectWithKeywords( // 执行函数 boot-&gt;func, boot-&gt;args, boot-&gt;keyw); ... PyMem_DEL(boot_raw); // 销毁线程 nb_threads--; PyThreadState_Clear(tstate); PyThreadState_DeleteCurrent(); PyThread_exit_thread();&#125; PyEval_AcquireThread123456789101112// ceval.c.272voidPyEval_AcquireThread(PyThreadState *tstate)&#123; assert tstate != NULL /* Check someone has called PyEval_InitThreads() to create the lock */ assert(gil_created()); take_gil(tstate); if (PyThreadState_Swap(tstate) != NULL) Py_FatalError( "PyEval_AcquireThread: non-NULL old thread state");&#125; 很明显，在take_gil中进入等待 GIL。获得 GIL 后，执行PyEval_CallObjectWithKeywords，执行相应用户代码。 线程切换EvalFrameDefault123456789101112131415161718192021222324252627282930313233343536PyObject *_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)&#123; ... for (;;) &#123; if (_Py_atomic_load_relaxed(&amp;eval_breaker)) &#123; if (_Py_OPCODE(*next_instr) == SETUP_FINALLY || _Py_OPCODE(*next_instr) == YIELD_FROM) &#123; goto fast_next_opcode; &#125; if (_Py_atomic_load_relaxed(&amp;pendingcalls_to_do)) &#123; if (Py_MakePendingCalls() &lt; 0) goto error; &#125; if (_Py_atomic_load_relaxed(&amp;gil_drop_request)) &#123; /* Give another thread a chance */ if (PyThreadState_Swap(NULL) != tstate) Py_FatalError("ceval: tstate mix-up"); drop_gil(tstate); /* Other threads may run now */ take_gil(tstate); /* Check if we should make a quick exit. */ if (_Py_Finalizing &amp;&amp; _Py_Finalizing != tstate) &#123; drop_gil(tstate); PyThread_exit_thread(); &#125; if (PyThreadState_Swap(tstate) != NULL) Py_FatalError("ceval: orphan tstate"); &#125; &#125; ... &#125;&#125; 如上，当检测到 eval_breaker、gil_drop_request 时，会被动的释放 GIL，跟其他线程一起再次竞争 GIL。从源码中还能发现，遇到SETUP_FINALLY、YIELD_FROM是不会被调度的。 pysleep123456789// timemodule.c.224static PyObject * time_sleep(PyObject *self, PyObject *obj)&#123; _PyTime_t secs; // typedef int64_t _PyTime_t; ... if (pysleep(secs) != 0) return NULL; ...&#125; 用户可以通过 time.sleep() 主动挂起线程，释放GIL。 1234567891011121314151617181920212223242526272829static int pysleep(_PyTime_t secs)&#123; _PyTime_t deadline, monotonic; struct timeval timeout; int err = 0; deadline = _PyTime_GetMonotonicClock() + secs; do &#123; if (_PyTime_AsTimeval(secs, &amp;timeout, _PyTime_ROUND_CEILING) &lt; 0) return -1; /* Linux上，通过宏 保存 ThreadState 状态，释放 GIL */ Py_BEGIN_ALLOW_THREADS // 调用 select，利用 timeout 参数，实现挂起线程 err = select(0, (fd_set *)0, (fd_set *)0, (fd_set *)0, &amp;timeout); // 宏调用 PyEval_RestoreThread，竞争 GIL Py_END_ALLOW_THREADS /* sleep was interrupted by SIGINT */ if (PyErr_CheckSignals()) return -1; monotonic = _PyTime_GetMonotonicClock(); secs = deadline - monotonic; if (secs &lt; 0) break; /* retry with the recomputed delay */ &#125; while (1); return 0;&#125; 如上，pysleep是一个区分平台的函数。上面只列出了 Linux 下的代码，利用宏，实现 GIL 的释放和再次申请。 线程销毁12345678res = PyEval_CallObjectWithKeywords( // 执行函数 boot-&gt;func, boot-&gt;args, boot-&gt;keyw);...PyMem_DEL(boot_raw);nb_threads--;PyThreadState_Clear(tstate);PyThreadState_DeleteCurrent();PyThread_exit_thread(); 子线程的整个生命周期都在t_bootstrap函数中，一旦函数执行完成，将会进入线程销毁环节。 123456789void PyThreadState_Clear(PyThreadState *tstate)&#123; if (Py_VerboseFlag &amp;&amp; tstate-&gt;frame != NULL) fprintf(stderr, "PyThreadState_Clear: warning: thread still has a frame\n"); Py_CLEAR(tstate-&gt;frame); Py_CLEAR(tstate-&gt;dict); ...&#125; 清理当前线程持有的对象。 123456789101112131415161718192021222324252627282930313233void PyThreadState_DeleteCurrent()&#123; PyThreadState *tstate = GET_TSTATE(); tstate_delete_common(tstate); // 调整链表 if (autoInterpreterState &amp;&amp; PyThread_get_key_value(autoTLSkey) == tstate) PyThread_delete_key_value(autoTLSkey); SET_TSTATE(NULL); PyEval_ReleaseLock(); // 释放 GIL&#125;static voidtstate_delete_common(PyThreadState *tstate)&#123; PyInterpreterState *interp; interp = tstate-&gt;interp; HEAD_LOCK(); // PyThread_acquire_lock(head_mutex, WAIT_LOCK) if (tstate-&gt;prev) tstate-&gt;prev-&gt;next = tstate-&gt;next; else interp-&gt;tstate_head = tstate-&gt;next; if (tstate-&gt;next) tstate-&gt;next-&gt;prev = tstate-&gt;prev; HEAD_UNLOCK(); // PyThread_release_lock(head_mutex) if (tstate-&gt;on_delete != NULL) &#123; tstate-&gt;on_delete(tstate-&gt;on_delete_data); &#125; PyMem_RawFree(tstate);&#125;PyEval_ReleaseLock(void)&#123; drop_gil((PyThreadState*)_Py_atomic_load_relaxed( &amp;_PyThreadState_Current));&#125; 调整 ThreadState 链表，删除当前 tstate，释放内存。完事后释放 GIL，结束整个线程。 GIL 总结1234567891011121314typedef struct _Py_atomic_int &#123; atomic_int _value;&#125; _Py_atomic_int;static _Py_atomic_int gil_locked = &#123;-1&#125;;static _Py_atomic_int gil_drop_request = &#123;0&#125;;static _Py_atomic_int eval_breaker = &#123;0&#125;;static _Py_atomic_int pendingcalls_to_do = &#123;0&#125;;static long main_thread = 0;static PyThread_type_lock pending_lock = 0; /* for pending calls */static COND_T gil_cond;static MUTEX_T gil_mutex; 源码参见ceval_gil.h： GIL 实际上是一个 原子变量 gil_locked，初始为 -1，表示未启用 互斥锁 gil_mutex 保护修改动作 条件变量 gil_cond 用于等待 GIL 持有 GIL 的线程执行 PyEval_EvalFrameEx 期间，必须能够接收到其他线程发送的释放请求 每次循环都将检查变量 gil_drop_request/eval_breaker 部分指令如’YIELD_FROM’会忽略释放请求 想要申请 GIL 的线程，必须在条件变量 cil_cond 上等待，直至超时 超时时间可通过sys.{get,set}switchinterval()进行获取、修改 等待超时且未释放，会设置 gil_drop_request/eval_breaker = 1 子线程获取到 GIL 后，会在 t_bootstrap 函数内，完成其整个生命周期 Threading1234567891011# Rename some stuff so "from threading import *" is safe_start_new_thread = _thread.start_new_thread_allocate_lock = _thread.allocate_lock_set_sentinel = _thread._set_sentinelget_ident = _thread.get_identThreadError = _thread.error_active_limbo_lock = _allocate_lock()_active = &#123;&#125; # maps thread id to Thread object_limbo = &#123;&#125;_dangling = WeakSet() Threading 是线程标准库，通过源码可以发现，它纯粹就是对 _thread.c 的封装，甚至是直接改了个名。 Class Thread12345678910111213141516171819202122class Thread: def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None): self._target = target _dangling.add(self) .... def start(self): with _active_limbo_lock: _limbo[self] = self // 记录到 limbo _start_new_thread(self._bootstrap, ()) ... def _bootstrap(self): self._bootstrap_inner() def _bootstrap_inner(self): with _active_limbo_lock: _active[self._ident] = self del _limbo[self] // 从 limbo 移动到 active ... self.run() def run(self): self._target(*self._args, **self._kwargs) 查看 Thread 类可以发现，一层层嵌套，最终还是用 _thread.start_new_thread来创建新的线程，换汤不换药。 API12345def active_count(): with _active_limbo_lock: return len(_active) + len(_limbo)def current_thread(): return _active[get_ident()] 通过源码，能发现。threading 将已经 start，但暂未启动原生线程的放入了 limbo中。并且，只要放入了 limbo 就算是已经 active。对两个字典 active/limbo 的操作，都在 _thread.allocate_lock 的保护下。 另外，threading 模块还提供了一些其他线程间同步工具，例如递归锁RLock、条件变量Condition、信号量Semaphore、事件Event。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 环境初始化]]></title>
    <url>%2F2018%2F08%2F04%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.12.Python%20%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参考 Before Python Initialization 前言一步步走来，我们已经了解了 Python对象机制，字节码执行机制，函数调用，类实例创建机制。这些内容都是在 Python 环境已经初始化完成后，才进行的工作。那么是时候看看，运行环境初始化，都干了些什么。 main1234567891011121314151617181920212223242526272829// python.c.18intmain(int argc, char **argv)&#123; ... res = Py_Main(argc, argv_copy); ... return res&#125;;// Modules/main.c.348intPy_Main(int argc, wchar_t **argv)&#123; ... Py_Initialize(); ... if (command) &#123; sts = run_command(command, &amp;cf); PyMem_RawFree(command); &#125; else if (module) &#123; sts = (RunModule(module, 1) != 0); &#125; else &#123; ... /* 处理 fp、filename */ sts = run_file(fp, filename, &amp;cf); &#125; ... return sts /* 0 正常退出，1 异常退出，2 参数列表不正确 */&#125; 可以看到，跟普通的 C 程序一样，通过入口 main 进入到 Py_Main，在调用Py_Initialize进行初始化，然后根据参数列表进行分发。 Py_Initialize12345678void Py_Initialize() Initialize the Python interpreter. In an application embedding Python, this should be called before using any other Python/C API functions This initializes the table of loaded modules (sys.modules), and creates the fundamental modules builtins, __main__ and sys. It also initializes the module search path (sys.path). It does not set sys.argv; use PySys_SetArgvEx() for that. 在 Python 初始化以前，只能调用少量的 C API。调用 Py_Initialize() 将完成对环境的初始化。其中很重要的是创建 models builtins, __main__ and sys 等内置 modules。PyInitialize最终调用_Py_InitializeEx_Private。 _PyRandom_Init123456789101112131415161718192021// Py_Initialize -&gt; Py_InitializeEx(1) -&gt; _Py_InitializeEx_Private(1, 1)void_Py_InitializeEx_Private(int install_sigs, int install_importlib)&#123; PyInterpreterState *interp; PyThreadState *tstate; PyObject *bimod, *sysmod, *pstderr; char *p; extern void _Py_ReadyTypes(void); if (initialized) return; initialized = 1; _Py_Finalizing = NULL; /* Hash randomization is enabled. Generate a per-process secret, using PYTHONHASHSEED if provided. */ _PyRandom_Init(); 嘿，朋友，你知道 hash(1) != hash(1) 吗？ InterpreterState &amp; ThreadState12345678910111213141516171819202122/* 模拟进程状态 PyInterpreterState 见 pystate.h.26 interp-&gt;next = interp_head; interp-&gt;tstate_head = NULL; interp-&gt;eval_frame = _PyEval_EvalFrameDefault; interp_head = interp;*/interp = PyInterpreterState_New();/* 模拟线程状态 tstate-&gt;interp = interp; tstate-&gt;prev = NULL; tstate-&gt;next = interp-&gt;tstate_head; if (tstate-&gt;next) tstate-&gt;next-&gt;prev = tstate; interp-&gt;tstate_head = tstate;*/tstate = PyThreadState_New(interp);/* 宏：SET_TSTATE() 设置全局变量 _PyThreadState_Current */(void) PyThreadState_Swap(tstate); 此处，来张图最好理解，图片来自《Python 源码剖析》P318。 ReayType &amp; Init1234567891011121314151617181920212223/* 调用 PyType_Ready，对 Py*_Type 进行初始化 */_Py_ReadyTypes();if (!_PyFrame_Init()) Py_FatalError("Py_Initialize: can't init frames");/* 嘿，还记得 small_ints 小整数对象池吗？ */if (!_PyLong_Init()) Py_FatalError("Py_Initialize: can't init longs");if (!PyByteArray_Init()) Py_FatalError("Py_Initialize: can't init bytearray");/* 判断机器是否使用 IEEE 浮点数格式 */if (!_PyFloat_Init()) Py_FatalError("Py_Initialize: can't init float");/* Init Unicode implementation; relies on the codec registry */if (_PyUnicode_Init() &lt; 0) Py_FatalError("Py_Initialize: can't initialize unicode");if (_PyStructSequence_Init() &lt; 0) Py_FatalError("Py_Initialize: can't initialize structseq");/* initialize builtin exceptions */_PyExc_Init(bimod); builtins123456789101112131415161718192021222324252627 interp-&gt;modules = PyDict_New(); bimod = _PyBuiltin_Init(); _PyImport_FixupBuiltin(bimod, "builtins"); interp-&gt;builtins = PyModule_GetDict(bimod);PyObject *_PyBuiltin_Init(void)&#123; mod = PyModule_Create(&amp;builtinsmodule); dict = PyModule_GetDict(mod); // d = ((PyModuleObject *)m) -&gt; md_dict; #define SETBUILTIN(NAME, OBJECT) \ if (PyDict_SetItemString(dict, NAME, (PyObject *)OBJECT) &lt; 0) \ return NULL; SETBUILTIN("None", Py_None); SETBUILTIN("type", &amp;PyType_Type); SETBUILTIN("object", &amp;PyBaseObject_Type); ... return mod;&#125;static struct PyModuleDef builtinsmodule = &#123; PyModuleDef_HEAD_INIT, "builtins", builtin_doc, ...&#125;; 如上，创建我们已经熟悉的builtins，并且在其__dict__中放入我们熟悉的type/object等。然后再将解释器interp-&gt;builtins直接指向该__dict__。 同时在_PyImport_FixupBuiltin中，调用_PyImport_FixupExtensionObject，完成extensions的初始化。 sysmod12345678910111213141516 sysmod = _PySys_Init(); interp-&gt;sysdict = PyModule_GetDict(sysmod); _PyImport_FixupBuiltin(sysmod, "sys"); PySys_SetPath(Py_GetPath()); PyDict_SetItemString(interp-&gt;sysdict, "modules", interp-&gt;modules);PyObject *_PySys_Init(void)&#123; m = PyModule_Create(&amp;sysmodule); sysdict = PyModule_GetDict(m); SET_SYS_FROM_STRING("hash_info", get_hash_info()); ... return m;&#125; 对 sys module 进行同样的操作。此时的内存布局如下图，同样来自《Python 源码剖析》P327。 stderr12345678/* Set up a preliminary stderr printer until we have enough infrastructure for the io module in place. */pstderr = PyFile_NewStdPrinter(fileno(stderr));if (pstderr == NULL) Py_FatalError("Py_Initialize: can't set preliminary stderr");_PySys_SetObjectId(&amp;PyId_stderr, pstderr);PySys_SetObject("__stderr__", pstderr);Py_DECREF(pstderr); 恩，这就是sys.__stderr__的由来。 再次 Init12345678910111213141516171819202122232425262728293031323334353637383940 /* interp-&gt;builtins_copy = PyDict_Copy(interp-&gt;builtins); */ _PyImport_Init(); /* 设置 sys.meta_path sys.path_importer_cache sys.path_hooks */ _PyImportHooks_Init(); /* Initialize _warnings. */ _PyWarnings_Init(); if (!install_importlib) return; if (_PyTime_Init() &lt; 0) Py_FatalError("Py_Initialize: can't initialize time"); import_init(interp, sysmod); /* initialize the faulthandler module */ if (_PyFaulthandler_Init()) Py_FatalError("Py_Initialize: can't initialize faulthandler"); if (initfsencoding(interp) &lt; 0) Py_FatalError("Py_Initialize: unable to load the file system codec"); if (install_sigs) initsigs(); /* Signal handling stuff, including initintr() */ if (_PyTraceMalloc_Init() &lt; 0) Py_FatalError("Py_Initialize: can't initialize tracemalloc"); /* Initialize warnings. */ if (PySys_HasWarnOptions()) &#123; PyObject *warnings_module = PyImport_ImportModule("warnings"); if (warnings_module == NULL) &#123; fprintf(stderr, "'import warnings' failed; traceback:\n"); PyErr_Print(); &#125; Py_XDECREF(warnings_module); &#125;&#125; main123456789101112131415161718192021222324252627282930313233 initmain(interp); /* Module __main__ */ if (initstdio() &lt; 0) // 设置 sys.__stdin__、__stdout__、__stderr__ Py_FatalError( "Py_Initialize: can't initialize sys standard streams");static voidinitmain(PyInterpreterState *interp)&#123; PyObject *m, *d, *loader, *ann_dict; m = PyImport_AddModule("__main__"); d = PyModule_GetDict(m); ann_dict = PyDict_New(); PyDict_SetItemString(d, "__annotations__", ann_dict); PyObject *bimod = PyImport_ImportModule("builtins"); PyDict_SetItemString(d, "__builtins__", bimod); PyObject *loader = PyObject_GetAttrString(interp-&gt;importlib, "BuiltinImporter"); PyDict_SetItemString(d, "__loader__", loader);&#125;PyObject *PyImport_AddModuleObject(PyObject *name)&#123; // 获取到 PyThreadState_GET()-&gt;interp-&gt;modules PyObject *modules = PyImport_GetModuleDict(); // 创建一个新的 PyModuleObject，m-&gt;md_name = str: __main__ m = PyModule_NewObject(name); // interp-&gt;modules[str: __main__] = model object: __main__ PyDict_SetItem(modules, name, m); return m;&#125; 创建了一个名字为__main__的module，并且在其__dict__中放入了一些属性。 initsite1234567891011 if (!Py_NoSiteFlag) initsite(); /* Module site */static voidinitsite(void)&#123; PyObject *m; m = PyImport_ImportModule("site"); ...&#125;// PyImport_ImportModule -&gt; PyImport_Import 在前面 sysmod 中，有一个步骤是PySys_SetPath(Py_GetPath());，它完成了 Python 模块加载路径的设置。但完成第三方库搜索路径设置，还是在PyImport_Import中。 12345678910111213141516171819PyObject *PyImport_Import(PyObject *module_name)&#123; /* Initialize constant string objects */ import_str = PyUnicode_InternFromString("__import__"); builtins_str = PyUnicode_InternFromString("__builtins__"); silly_list = PyList_New(0); /* Get the builtins from current globals */ builtins = PyImport_ImportModuleLevel("builtins", NULL, NULL, NULL, 0); globals = Py_BuildValue("&#123;OO&#125;", builtins_str, builtins); import = PyObject_GetItem(builtins, import_str); r = PyObject_CallFunction(import, "OOOOi", module_name, globals, globals, silly_list, 0, NULL); return r;&#125; 在此处导入了模块 site.py 。好高兴，终于看见一个 py 文件了~~ 1234567891011// site.py"""Append module search paths for third-party packages to sys.path.* This module is automatically imported during initialization. *On Unix (including Mac OSX), it starts with sys.prefix and sys.exec_prefix(if different) and appends lib/python&lt;version&gt;/site-packages.On other platforms (such as Windows), it tries each of theprefixes directly, as well as with lib/site-packages appended.""" 从注释中能发现，根据不同平台，把不同的路径加入到 sys.path 中。具体内容可以参考源文件。 小结在_Py_InitializeEx_Private经过漫长的步骤后，终于完成了初始化工作，跳转到 main 继续运行。看图： run12345678run_command(command, &amp;cf); -&gt; PyRun_SimpleStringFlags -&gt; PyRun_StringFlags -&gt; run_mod -&gt; PyEval_EvalCode -&gt; PyEval_EvalCodeEx -&gt; 执行字节码run_file(fp, filename, &amp;cf); -&gt; PyRun_AnyFileExFlags -&gt; PyRun_InteractiveLoopFlags -&gt; PyRun_InteractiveOneObjectEx -&gt; 进入交互式环境 -&gt; run_modrun_file(fp, filename, &amp;cf); -&gt; PyRun_AnyFileExFlags -&gt; PyRun_SimpleFileExFlags -&gt; PyRun_FileExFlags -&gt; run_mod -&gt; PyEval_EvalCode -&gt; 执行字节码 Python 环境初始化完成后，根据参数的不同，进入不同的模式。从上面的调用链可以发现，最后必然都殊途同归，进入到字节码的执行环节，区别就在与字节码的获取方式不一样。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 自定义类]]></title>
    <url>%2F2018%2F07%2F28%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.11.Python%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[参考 PEP3115 Metaclasses in Python 前言在上一讲，我们谈到了内置类的初始化工作，其中最主要的逻辑落在 PyType_Ready 中。本讲，我们将主要查看用户自定义类及实例化，在 Python 中的实现过程。 自定义类123456789101112class A: name = 'a' def __init__(self): print("A:__init__") def f(self): print("A:f") def g(self, v): self.v = v print(self.v)a = A()a.f()a.g(10) 从编译的字节码可以发现，创建类、实例化，以及调用实例的方法，都是通过CALL_FUNCTION实现。在Python 函数机制中，我们已经分析过 CALL_FUNCTION 的实现：”通过栈中的 func 指针及参数，在加上当前的 global 命名空间，创建一个 Frame 对象。并在新的 Frame 中加载 Func.code 执行字节码指令，最终将返回值压入栈中。” 12345678910111213141516171819202122 1 0 LOAD_BUILD_CLASS 2 LOAD_CONST 0 (&lt;code object A &gt;) 4 LOAD_CONST 1 (&apos;A&apos;) 6 MAKE_FUNCTION 0 8 LOAD_CONST 1 (&apos;A&apos;) 10 CALL_FUNCTION 2 // 创建类 12 STORE_NAME 0 (A)10 14 LOAD_NAME 0 (A) 16 CALL_FUNCTION 0 18 STORE_NAME 1 (a)11 20 LOAD_NAME 1 (a) 22 LOAD_ATTR 2 (f) 24 CALL_FUNCTION 0 26 POP_TOP12 28 LOAD_NAME 1 (a) 30 LOAD_ATTR 3 (g) 32 LOAD_CONST 2 (10) 34 CALL_FUNCTION 1 36 POP_TOP 38 LOAD_CONST 3 (None) 40 RETURN_VALUE 那么我们先看下 demo.py 对应的CodeObject。 CodeObject：demo.py12345678910111213141516171819202122class A: 1 0 LOAD_BUILD_CLASS 2 LOAD_CONST 0 (&lt;code object A &gt;) 4 LOAD_CONST 1 ('A') 6 MAKE_FUNCTION 0 8 LOAD_CONST 1 ('A') 10 CALL_FUNCTION 2 12 STORE_NAME 0 (A)/*opcode:: LOAD_BUILD_CLASS Pushes :func:`builtins.__build_class__` onto the stack. It is later called by :opcode:`CALL_FUNCTION` to construct a class.*/TARGET(LOAD_BUILD_CLASS) &#123; PyObject *bc; /* 从 f-&gt;f_builtins 中获取 __build_class__ bc = __builtins__['__build_class__'] PUSH(bc); */&#125; 跟函数机制类似： 0，加载 __build_class__ 方法到栈顶 2、4、6，加载 &lt;code object A &gt; 函数名 A，创建一个 FuncObject 入栈 8、10，从栈中弹出 build_class、FuncObject、参数，创建一个新的 Frame 对象，加载字节码执行 12 将栈顶的结果转移到 local 命名空间中 CALL_FUNCTION123456789101112131415161718192021222324252627282930313233343536TARGET(CALL_FUNCTION) &#123; sp = stack_pointer; res = call_function(&amp;sp, oparg, NULL); // oparg == 2&#125;static PyObject *call_function(PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)&#123; PyObject *func = *((*pp_stack) - oparg - 1); Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames); Py_ssize_t nargs = oparg - nkwargs; if (PyCFunction_Check(func)) &#123; stack = (*pp_stack) - nargs - nkwargs; // - 2 - 0 x = _PyCFunction_FastCallKeywords(func, stack, nargs, kwnames); &#125; return x;&#125;PyObject *_PyCFunction_FastCallKeywords(PyObject *func, PyObject **stack, Py_ssize_t nargs, PyObject *kwnames)&#123; PyObject *kwdict, *result; Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames); if (nkwargs &gt; 0) &#123; /* zip 组合成字典，说明 kwnames 必须为 str 且唯一 */ kwdict = _PyStack_AsDict(stack + nargs, kwnames); &#125; else &#123; kwdict = NULL; &#125; result = _PyCFunction_FastCallDict(func, stack, nargs, kwdict); Py_XDECREF(kwdict); return result;&#125; 特别注意：10 CALL_FUNCTION 2，参数个数为2。执行前的栈帧结构如下：123__builtins__[&apos;__build_class__&apos;]FuncObjectCONST:&quot;A&quot; 因此，最终调用时的参数为：1234567result = _PyCFunction_FastCallDict(func, stack, nargs, kwdict);/* func = __builtins__[&apos;__build_class__&apos;] stack = &amp;FuncObject nargs = 2 kwdict = NULL*/ _PyCFunction_FastCallDict1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// methodobject.c.153PyObject *_PyCFunction_FastCallDict(PyObject *func_obj, PyObject **args, Py_ssize_t nargs, PyObject *kwargs)&#123; PyCFunctionObject *func = (PyCFunctionObject*)func_obj; PyObject *result; int flags = PyCFunction_GET_FLAGS(func) &amp; ~(METH_CLASS | METH_STATIC | METH_COEXIST); switch (flags) &#123; case METH_NOARGS: ... break; case METH_O: ... break; case METH_VARARGS: case METH_VARARGS | METH_KEYWORDS: ... break; case METH_FASTCALL: ... break; default： return NULL; &#125; return result;&#125;// bltinmodule.c.2635static PyMethodDef builtin_methods[] = &#123; &#123;"__build_class__", (PyCFunction)builtin___build_class__, METH_VARARGS | METH_KEYWORDS, build_class_doc&#125;,&#125;// methodobject.h.91typedef struct &#123; PyObject_HEAD PyMethodDef *m_ml; /* Description of the C function to call */ PyObject *m_self; /* Passed as 'self' arg to the C func, can be NULL */ PyObject *m_module; /* The __module__ attribute, can be anything */ PyObject *m_weakreflist; /* List of weak references */&#125; PyCFunctionObject;struct PyMethodDef &#123; const char *ml_name; /* The name of the built-in function/method */ PyCFunction ml_meth; /* The C function that implements it */ int ml_flags; /* Combination of METH_xxx flags, which mostly describe the args expected by the C func */ const char *ml_doc; /* The __daoc__ attribute, or NULL */&#125; PyMethodDef; 回想上一节谈到的 Python 类机制，在 PyType_Ready 中会经历一步 add_methods，把一个 C 函数封装成 Python 对象，放入字典中。此处，也不例外。根据 flags，程序将执行下面的分支。 12345678910111213141516PyCFunction meth = func -&gt; m_ml -&gt; ml_meth;PyObject *self = func -&gt; m_self; // == NULLcase METH_VARARGS | METH_KEYWORDS:&#123; PyObject *tuple; tuple = _PyStack_AsTuple(args, nargs); result = (*(PyCFunctionWithKeywords)meth) (self, tuple, kwargs); Py_DECREF(tuple); break;&#125;/* meth = builtin___build_class__ self = NULL tuple = (FuncObject,"A") kwargs = NULL*/ 此处，将直接执行 C 函数builtin___build_class__(NULL, (FuncObject, &quot;A&quot;), NULL)。 build_classPEP3115在查看源码前，我们先来看下PEP3115。该提案改变了 Python3 中 metaclass 的定义方式。按照 Guido 所说，class 语句将接受关键字参数，并且为元类增加 __prepare__ 方法逻辑。在用元类创建类之前，会先尝试调用元类的__prepare__方法，返回一个字典，作为局部变量字典。 1234567891011121314151617class C(A, B, metaclass=M, other=42, *more_bases, *more_kwds): ...# would translate into this:C = __build_class__(&lt;func&gt;, 'C', A, B, metaclass=M, other=42, *more_bases, *more_kwds)# Then __build_class__ could be roughly like this (but implemented in C):def __build_class__(func, name, *bases, metaclass=None, **kwds): if metaclass is None: metaclass = extract_metaclass(bases) # may raise an exception prepare = getattr(metaclass, "__prepare__", None) if prepare: locals = prepare(name, bases, **kwds) else: locals = &#123;&#125; func(locals) return metaclass(name, bases, locals, **kwds) builtin___build_class__12345678910111213141516171819202122232425262728293031323334353637// bltinmodule.c.55static PyObject *builtin___build_class__(PyObject *self, PyObject *args, PyObject *kwds)&#123; assert args is tuple assert nargs = len(args) &gt;= 2 asert func = args[0] is callable asert name = args[1] is string bases = args[2:] if (kwds == NULL): meta = NULL mkw = NULL else: mkw = kwds.copy() meta = mkw.pop('metaclass', NULL) if meta is NULL: if not bases: meta = PyType_Typ else: meta = bases[0].__calss__ if isinstance(meta, type): meta = 更深层的 meta ns = meta.__prepare__() or &#123;&#125; // namespace 的简写 /* 将 class block 存储到 ns 中 */ cell = PyEval_EvalCodeEx(func.__code__ func.__global__, ns, NULL, 0, NULL, 0, NULL, 0, NULL, func.closure); // 创建类 PyObject *cls = NULL; if cell != NULL: PyObject *margs[3] = &#123;name, bases, ns&#125;; // 相当于执行 meta(name_str, bases_tuple, namespace_dict) cls = _PyObject_FastCallDict(meta, margs, 3, mkw); return cls&#125; 注意，上面不伦不类的伪代码是笔者根据源码改写的，具体内容请查看bltinmodule.c。可以发现在此处真正完成了类的创建。 特别注意，此处传入的 CodeObject 是从栈中取出的 FuncObject.code，即对应代码中的&lt;code object A&gt;。 PyEval_EvalCodeEx 将调用 _PyEval_EvalCodeWithName。后者，我们在 Python函数机制 中已经谈到，最终都是创建栈帧对象，在新的上下文环境执行被调函数字节码指令。那么接下来就是在新的 Frame 中，执行 class A 的字节码指令，等待返回，执行创建类的代码。 CodeObject：Class A123456789101112131415161718192021222324252627// &lt;code object A&gt;co_consts = (&apos;A&apos;, &apos;a&apos;, &lt;code object __init__ &gt;, &apos;A.__init__&apos;, &lt;code object f&gt;, &apos;A.f&apos;, &lt;code object g&gt;, &apos;A.g&apos;, None)co_names = (&apos;__name__&apos;, &apos;__module__&apos;, &apos;__qualname__&apos;, &apos;name&apos;, &apos;__init__&apos;, &apos;f&apos;, &apos;g&apos;) 1 0 LOAD_NAME 0 (__name__) 2 STORE_NAME 1 (__module__) 4 LOAD_CONST 0 (&apos;A&apos;) 6 STORE_NAME 2 (__qualname__) 2 8 LOAD_CONST 1 (&apos;a&apos;) 10 STORE_NAME 3 (name) 3 12 LOAD_CONST 2 (&lt;code object __init__&gt;) 14 LOAD_CONST 3 (&apos;A.__init__&apos;) 16 MAKE_FUNCTION 0 18 STORE_NAME 4 (__init__) 5 20 LOAD_CONST 4 (&lt;code object f&gt;) 22 LOAD_CONST 5 (&apos;A.f&apos;) 24 MAKE_FUNCTION 0 26 STORE_NAME 5 (f) 7 28 LOAD_CONST 6 (&lt;code object g&gt;) 30 LOAD_CONST 7 (&apos;A.g&apos;) 32 MAKE_FUNCTION 0 34 STORE_NAME 6 (g) 36 LOAD_CONST 8 (None) 38 RETURN_VALUE 如上，在新的 Frame 中，执行 CodeObject class A，整体上都在加载变量，创建 Function，存储到此时的 locals 命名空间中。要注意到，此时的 locals，是在__build_class__中，创建并传入的ns。意思就是，这些属性、方法，都存放在了 ns 中。最后，返回 None，回到__build_class__继续执行，跳转到 builtin___build_class__。 _PyObject_FastCallDict12345678910111213141516171819202122232425PyObject *margs[3] = &#123;name, bases, ns&#125;;cls = _PyObject_FastCallDict(meta, margs, 3, mkw);PyObject *_PyObject_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs)&#123; ternaryfunc call; PyObject *result = NULL; PyObject *tuple = &amp;_PyStack_AsTuple(args, nargs); call = func-&gt;ob_type-&gt;tp_call; if (call == NULL) &#123; PyErr_Format(PyExc_TypeError, "'%.200s' object is not callable", func-&gt;ob_type-&gt;tp_name); goto exit; &#125; result = (*call)(func, tuple, kwargs); return result;&#125;PyTypeObject PyType_Type = &#123; (ternaryfunc)type_call, /* tp_call */ type_new, /* tp_new */ type_init, /* tp_init */&#125; 简写后的代码如上，此处的 func，就是上文传入的 metaclass，默认为 PyType_Type。那么就将调用 type_call()，创建类。 这里就要提一句，为什么传入一个对象，却可以作为 func 使用？在 Python 中，函数是可以被调用的。而函数是对象，变量也是对象。那么为什么函数可以被调用，而变量却不能？ 事实上，源代码已经告诉了我们答案：object-&gt;ob_type-&gt;tp_call，只要 tp_call 存在且是函数。该对象就是可以被调用的。 12345678910&gt;&gt;&gt; class Ca:... def __call__(self):... print("call: ca")...&gt;&gt;&gt; Ca.__class__.__call__&lt;slot wrapper '__call__' of 'type' objects&gt;&gt;&gt;&gt; callable(Ca())True&gt;&gt;&gt; Ca().__class__.__call__&lt;function Ca.__call__ at 0x000001C8B28BEA60&gt; 执行 classObject()，就是执行 PyType_Type.tp_call()。执行 instance()，就是执行instance.__class__.__call__。 type_call()1234567891011121314151617181920212223242526static PyObject *type_call(PyTypeObject *type, PyObject *args, PyObject *kwds)&#123; PyObject *obj; obj = type-&gt;tp_new(type, args, kwds); obj = _Py_CheckFunctionResult((PyObject*)type, obj, NULL); /* Ugly exception: when the call was type(something), don't call tp_init on the result. */ if (type == &amp;PyType_Type &amp;&amp; PyTuple_Check(args) &amp;&amp; PyTuple_GET_SIZE(args) == 1 &amp;&amp; (kwds == NULL || (PyDict_Check(kwds) &amp;&amp; PyDict_Size(kwds) == 0))) return obj; /* If the returned object is not an instance of type, it won't be initialized. */ if (!PyType_IsSubtype(Py_TYPE(obj), type)) return obj; type = Py_TYPE(obj); if (type-&gt;tp_init != NULL) &#123; type-&gt;tp_init(obj, args, kwds); &#125; return obj;&#125; 调用 type-&gt;type_new()，得到一个 classObject。判断，是否执行的是 type(classObject)，再判断 classObject 是否继承自 type，否则进入我们熟悉的环节__init__。 type_new()12345678910111213141516&gt;&gt;&gt; class A(list):... name = 'n'... def f(self):... print(self)...&gt;&gt;&gt; B = type('B', (list,), &#123;'name': 'n', "f": lambda self: print(self)&#125;)&gt;&gt;&gt; type(B) is typeTrue&gt;&gt;&gt; A.name'n'&gt;&gt;&gt; B.name'n'&gt;&gt;&gt; type('C',())Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: type() takes 1 or 3 arguments 在查看 type_new 之前，先了解下 Python 中类的创建。从上面可以发现，type() 接收1个参数时，返回类型对象，3个参数时创建类。好了，了解之后就开始进入 type_new 环节。 123456789// typeobject.c.2285-2731static PyObject *type_new(PyTypeObject *metatype, PyObject *args, PyObject *kwds)&#123;/* metatype = type args = (类名 name, 基类 bases, 命名空间 ns) kwds = 附加参数 or &#123;&#125;*/&#125; type_new是一个非常复杂的函数，有超过400行。它在 Python 中扮演着非常重要的角色，正是由它创建了 Python 的各种 class。 type(x)123456789101112if (metatype == &amp;PyType_Type) &#123; const Py_ssize_t nargs = PyTuple_GET_SIZE(args); const Py_ssize_t nkwds = kwds == NULL ? 0 : PyDict_Size(kwds); /* Special case: type(x) should return x-&gt;ob_type */ /* We only want type itself to accept the one-argument form (#27157) Note: We don't call PyType_CheckExact as that also allows subclasses */ if (nargs == 1 &amp;&amp; nkwds == 0) &#123; PyObject *x = PyTuple_GET_ITEM(args, 0); Py_INCREF(Py_TYPE(x)); return (PyObject *) Py_TYPE(x); &#125; 实际在调用时，type 本身也是作为形参 metatype 传入的。判断参数个数，若参数只有1个，那么就实在执行type(classObject)，直接返回type(args[0])。 确定 metatype123456789101112131415161718192021/* Determine the proper metatype to deal with this: */winner = _PyType_CalculateMetaclass(metatype, bases);if (winner == NULL) &#123; return NULL;&#125;if (winner != metatype) &#123; if (winner-&gt;tp_new != type_new) /* Pass it to the winner */ return winner-&gt;tp_new(winner, args, kwds); metatype = winner;&#125;/* Adjust for empty tuple bases */nbases = PyTuple_GET_SIZE(bases);if (nbases == 0) &#123; /* 这就是 为什么 Python3 中自动继承 object */ bases = PyTuple_Pack(1, &amp;PyBaseObject_Type); if (bases == NULL) goto error; nbases = 1;&#125; 找出最佳的 metaclass，并处理 base=() 的情况。 slot1234/* Check for a __slots__ sequence variable in dict, and count it */slots = _PyDict_GetItemId(di#$ct, &amp;PyId___slots__);if (slots == NULL) &#123; ... &#125;else &#123; ... &#125; __slot__属性，允许我们显式的指定成员属性，经常用于存在大量实例的情况下减小内存占用。在这种情况下，将不会存在__dict__属性。具体参考：python.org Allocate1234567891011121314151617181920212223242526272829303132333435363738394041 /* Allocate the type object, 不使用 __slot__时 nslots=0 */ type = (PyTypeObject *)metatype-&gt;tp_alloc(metatype, nslots); /* Keep name and slots alive in the extended type object */ et = (PyHeapTypeObject *)type; et-&gt;ht_name = name; et-&gt;ht_slots = slots; /* Initialize tp_flags */ type-&gt;tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HEAPTYPE | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HAVE_FINALIZE; if (base-&gt;tp_flags &amp; Py_TPFLAGS_HAVE_GC) type-&gt;tp_flags |= Py_TPFLAGS_HAVE_GC; /* Initialize essential fields */ type-&gt;tp_as_async = &amp;et-&gt;as_async; type-&gt;tp_as_number = &amp;et-&gt;as_number; type-&gt;tp_as_sequence = &amp;et-&gt;as_sequence; type-&gt;tp_as_mapping = &amp;et-&gt;as_mapping; type-&gt;tp_as_buffer = &amp;et-&gt;as_buffer; type-&gt;tp_name = PyUnicode_AsUTF8AndSize(name, &amp;name_size); /* Set tp_base and tp_bases */ type-&gt;tp_bases = bases; type-&gt;tp_base = base; /* Initialize tp_dict from passed-in dict */ type-&gt;tp_dict = dict; /* Set __module__ in the dict */ /* Set ht_qualname to dict['__qualname__'] if available, else to __name__. The __qualname__ accessor will look for ht_qualname. */ /* Set tp_doc to a copy of dict['__doc__'], if the latter is there and is a string. The __doc__ accessor will first look for tp_doc; if that fails, it will still look into __dict__. */ /* Special-case __new__: if it's a plain function, make it a static function *//* Special-case __init_subclass__: if it's a plain function, make it a classmethod *//* Add descriptors for custom slots from __slots__, or for __dict__ *//* Special case some slots */ 如上，在这部分调用 tp_alloc 在堆上分配内存。然后进行了一些属性和方法的初始化工作。 这里要注意一点，若查看 PyType_Type 源码会发现 tp_alloc 为0，这可怎么搞？还记得 Python类机制中谈到，PyType_Ready 会将所有的 type.base 默认设置为 object。因此，PyType_Type 将继承到 PyBaseObject_Type-&gt;PyType_GenericAlloc 方法。 Gc&amp;Ready123456789101112/* Enable GC unless this class is not adding new instance variables and the base class did not use GC. *//* Always override allocation strategy to use regular heap *//* store type in class' cell if one is supplied *//* Initialize the rest */if (PyType_Ready(type) &lt; 0) goto error;/* Put the proper slots in place */fixup_slot_dispatchers(type);return (PyObject *)type; 最终，调用 PyType_Ready 对用户创建的类进行初始化，完成后返回 type_call此时，判断满足条件PyType_IsSubtype(Py_TYPE(obj), type)，直接返回 classObject，完成创建类的工作。 特别注意： PyType_Ready(class A) 会为 A 继承一些属性/方法，其中就包括 tp_new/tp_init。 fixup_slot_dispatchers会替换存在于 slotdefs中，且用户自定义的魔术方法。 实例化自定义类1234a = A() 10 14 LOAD_NAME 0 (A) 16 CALL_FUNCTION 0 18 STORE_NAME 1 (a) 可见，创建实例对象，依此调用CALL_FUNCTION-&gt;call_function-&gt;_PyObject_FastCallKeywords-&gt;_PyObject_FastCallDict最终找到func-&gt;ob_type-&gt;tp_call，执行tp_call()。 这又回到了创建自定义类的套路，问题在于，此时的 tp_new/tp_init 还是之前的 PyType_Type-&gt;tp_new吗？ 回顾 PyType_Ready，Python3 默认添加基类 object，若用户没有自定义，那么 tp_new 自然是PyBaseObject_Type-&gt;tp_new 即 object_new 。 object_new12345678910static PyObject *object_new(PyTypeObject *type, PyObject *args, PyObject *kwds)&#123; /* 处理含参数，但 type-&gt;tp_init == object_init，报错 */ /* 处理抽象类 */ if (type-&gt;tp_flags &amp; Py_TPFLAGS_IS_ABSTRACT) &#123; ... &#125; return type-&gt;tp_alloc(type, 0);&#125; 是不是非常清晰、明了，比 type-&gt;type_new 的400行代码，看着舒服多了~完成后同样返回到 type_call。此时，不满足条件PyType_IsSubtype(Py_TYPE(obj), type)，继续执行tp_init(obj, args, kwds)，完成实例的初始化工作。 访问实例属性12345a.f() 11 20 LOAD_NAME 1 (a) 22 LOAD_ATTR 2 (f) 24 CALL_FUNCTION 0 26 POP_TOP 很明显，其中LOAD_ATTR将发挥重要作用。 LOAD_ATTR12345678910111213opcode:: LOAD_ATTR (namei) Replaces TOS with ``getattr(TOS, co_names[namei])``.TARGET(LOAD_ATTR) &#123; PyObject *name = GETITEM(names, oparg); PyObject *owner = TOP(); PyObject *res = PyObject_GetAttr(owner, name); Py_DECREF(owner); SET_TOP(res); if (res == NULL) goto error; DISPATCH();&#125; 恩，看注释就很好理解。那么在来看PyObject_GetAttr。在查看源码前，先了解下 Python 中的描述符协议。 描述符协议12345678910111213141516171819202122232425262728293031323334353637&gt;&gt;&gt; class Field:... """ 实现描述符协议的类，描述符类 """... def __init__(self, name):... self.name = name... def __set__(self, instance, value):... """... self 为描述符实例... instance 为托管类的实例... 为 托管实例的托管属性进行赋值时，调用。...... 描述符协议，是对托管实例，进行操作。... """... print("use __set__")... instance.__dict__[self.name] = value... def __get__(self, instance, owner):... """... self 为描述类实例... instance 为托管类实例... owner 为托管类... """... print("use __get__")... return instance.__dict__[self.name]...&gt;&gt;&gt; class Model:... """ 把描述符实例，声明为类属性的类，托管类 """... width = Field('width') # 描述符实例 Field()... height = Field("height") # 描述符属性 height，都是类属性... def __init__(self, width, height):... """ 由描述符协议进行托管的，托管属性 """... self.width = width... self.height = height...&gt;&gt;&gt; m = Model(10, 32)use __set__use __set__&gt;&gt;&gt; m.__dict__&#123;'width': 10, 'height': 32&#125; 写过框架或者熟悉ORM的人，应该对其不陌生。描述符，在ORM中经常被用于数据验证。实际上，描述符在 Python 内部被大量使用。属性访问得到的对象，如果包含描述符方法，会调用该方法并返回。 描述符定义为，对象包含以下任意方法，__get__(), __set__(), and __delete__()的对象。对实例来说，获取属性 x ，会lookup chain starting with a.__dict__[&#39;x&#39;], then type(a).__dict__[&#39;x&#39;], 并且继续在 bases 链中寻找，但不包括元类。 但是，如果查找的值是一个定义描述符方法的对象，那么Python可以重写默认行为并调用描述符方法。在优先级链中发生这种情况取决于定义了哪些描述符方法以及如何调用它们。 描述符优先级描述符调用的优先级取决于定义了哪些描述符方法： 如果它没有定义 get()，那么访问该属性将返回描述符对象本身，除非对象的实例字典中有一个值。 如果描述符定义了 set()或del() 那么它就是一个数据描述符 如果它既不定义set()也不定义del()，那么它就是一个非数据描述符 通常，数据描述符定义get()和set()，而非数据描述符只有get()方法。 总体上就是：数据描述符 &gt; 实例覆盖&gt; 非数据描述符 Python 方法(包括staticmethod()和classmethod()))实现为非数据描述符。因此，实例可以重新定义和覆盖方法。这允许实例获得与其他实例不同的行为。属性方法 property() 函数实现为数据描述符。因此，实例不能覆盖属性的行为。 因此，会有以下结果123456789101112131415161718192021222324252627282930&gt;&gt;&gt; class A:... @staticmethod... def s():... print("非数据描述符")... @classmethod... def c(cls):... print("非数据描述符")... @property... def p(self):... return "数据描述符"...&gt;&gt;&gt; a = A()&gt;&gt;&gt; a.s()非数据描述符&gt;&gt;&gt; a.c = 1&gt;&gt;&gt; a.c1&gt;&gt;&gt; a.__dict__&#123;'c': 1&#125;&gt;&gt;&gt; a.p'数据描述符'&gt;&gt;&gt; a.p = 2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: can't set attribute&gt;&gt;&gt; a.__dict__['p'] = 2&gt;&gt;&gt; a.__dict__&#123;'c': 1, 'p': 2&#125;&gt;&gt;&gt; a.p'数据描述符' 好了，如果还能保持清醒，那么就继续看PyObject_GetAttr的源码吧！ PyObject_GetAttr1234567891011121314151617181920// objectc.c.884PyObject *PyObject_GetAttr(PyObject *v, PyObject *name)&#123; PyTypeObject *tp = Py_TYPE(v); assert PyUnicode_Check(name) if (tp-&gt;tp_getattro != NULL) return (*tp-&gt;tp_getattro)(v, name); if (tp-&gt;tp_getattr != NULL) &#123; char *name_str = PyUnicode_AsUTF8(name); if (name_str == NULL) return NULL; return (*tp-&gt;tp_getattr)(v, name_str); &#125; PyErr_Format(PyExc_AttributeError, "'%.50s' object has no attribute '%U'", tp-&gt;tp_name, name); return NULL;&#125; 如上，tp_getattr 在内部已经被弃用，首选通过 tp_getattro，即PyBaseObject_Type-&gt;PyObject_GenericGetAttr，获取属性。 PyObject_GenericGetAttr12345678910111213141516PyObject *PyObject_GenericGetAttr(PyObject *obj, PyObject *name)&#123; return _PyObject_GenericGetAttrWithDict(obj, name, NULL);&#125;/* Generic attribute getter function that is meant to be put into a type object’s tp_getattro slot. It looks for a descriptor in the dictionary of classes in the object’s MRO as well as an attribute in the object’s __dict__ (if present). As outlined in Implementing Descriptors, data descriptors take preference over instance attributes, while non-data descriptors don’t. Otherwise, an AttributeError is raised.*/ 从注释中，可以获取到，通用属性搜索在 typeObject-&gt;tp_getattro 槽中。会在 MRO 及__dict__中寻找描述符。数据描述符优先于实例属性，未找到会报错。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374PyObject *_PyObject_GenericGetAttrWithDict(PyObject *obj, PyObject *name, PyObject *dict)&#123; PyTypeObject *tp = Py_TYPE(obj); PyObject *descr = NULL; PyObject *res = NULL; descrgetfunc f; Py_ssize_t dictoffset; PyObject **dictptr; if (tp-&gt;tp_dict == NULL) &#123; if (PyType_Ready(tp) &lt; 0) goto done; &#125; /* Look for a name through the MRO */ descr = _PyType_Lookup(tp, name); /* 尝试在 instance.__class__.__mro__ 链中寻找描述符 */ f = NULL; if (descr != NULL) &#123; Py_INCREF(descr); f = descr-&gt;ob_type-&gt;tp_descr_get; if (f != NULL &amp;&amp; PyDescr_IsData(descr)) &#123; /* 数据描述符，调用 __get__(self, instance, owner) */ res = f(descr, obj, (PyObject *)obj-&gt;ob_type); goto done; &#125; &#125; /* 获取 __dict__ */ if (dict == NULL) &#123; /* Inline _PyObject_GetDictPtr */ dictoffset = tp-&gt;tp_dictoffset; if (dictoffset != 0) &#123; if (dictoffset &lt; 0) &#123; // 变长对象 dictoffset 负处理 &#125; dictptr = (PyObject **) ((char *)obj + dictoffset); dict = *dictptr; &#125; &#125; /* 尝试在 instance.__dict__ 中寻找 */ if (dict != NULL) &#123; Py_INCREF(dict); res = PyDict_GetItem(dict, name); if (res != NULL) &#123; Py_INCREF(res); Py_DECREF(dict); goto done; &#125; Py_DECREF(dict); &#125; /* 处理找到描述符，但不是数据描述符 */ if (f != NULL) &#123; res = f(descr, obj, (PyObject *)Py_TYPE(obj)); goto done; &#125; /* 处理，找到描述符，但无 __get__ 方法，返回描述符 */ if (descr != NULL) &#123; res = descr; descr = NULL; goto done; &#125; /* 什么都没找到，最终报错 */ PyErr_Format(PyExc_AttributeError, "'%.50s' object has no attribute '%U'", tp-&gt;tp_name, name); done: Py_XDECREF(descr); Py_DECREF(name); return res;&#125; 如上，具体逻辑跟描述符优先级中的内容一模一样，沿着优先级一步一步尝试获取。 小结至此，我们通过LOAD_BUILD_CLASS + CALL_FUNCTION指令，进入到 C 函数 builtin___build_class__(NULL, (FuncObject, &quot;A&quot;), NULL) ，在其中通过PyEval_EvalCodeEx将 FuncObject 执行后存储到 ns 中，然后进入到meta(name_str, bases_tuple, namespace_dict)。最终我们进入PyType_Type-&gt;tp_new，完成类的内存分配、初始化，创建类并返回。 通过LOAD_NAME + CALL_FUNCTION，进入 C 函数PyBaseObject_Type-&gt;tp_new，完成实例的创建，通过classObject.__init__完成实例的初始化。 通过LOAD_NAME + LOAD_ATTR，进入PyObject_GetAttr，沿着属性访问优先级链描述符 + mro + __dict__，依此尝试获取属性。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>类机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 类机制]]></title>
    <url>%2F2018%2F07%2F28%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.10.Python%20%E7%B1%BB%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言在PyObject/PyObjectType，我们已经看到过，PyObject、PyTypeObject、PyType_Type、PyBaseObject_Type。 下面通过几个例子来具体描述关系： 实例，通过isinstance()方法，检查其 ob_type 是否一致。 子类，通过issubclass()方法，检查其 bases 是否存在继承关系。 123456789&gt;&gt;&gt; isinstance(object, type)True # object.__class__ == &lt;class 'type'&gt;&gt;&gt;&gt; issubclass(object, type)False # 注意：object.__base__ == None&gt;&gt;&gt; isinstance(type, object)True # 注意：type.__class__ == &lt;class 'type'&gt;&gt;&gt;&gt; issubclass(type, object)True # type.__base__ == &lt;class 'object'&gt; 这里需要特别注意，虽然 type.ob_type 并不指向 object，但isinstance(type, object)的结果仍然是True！ 事实上，isinstacne(anything, object) 都是 True。issubclass(AnyClass, object)也都是True。 1234567891011121314151617class A: passclass B(A): passprint(isinstance(B, A)) # False, B的 ob_type 不指向 Aprint(isinstance(B, object)) # True, 永真式print(isinstance(B, type)) # True, B的 ob_type 指向 PyType_Typeprint(isinstance(B(), B)) # True, 实例的 ob_type 指向类，没毛病print(isinstance(B(), A)) # True, 实例的类的继承关系print(isinstance(B(), object)) # True, 新式类都继承自 objectprint(isinstance(B(), type)) # False, 这里不要搞错了print(issubclass(B, A)) # True, B继承 Aprint(issubclass(B, object)) # True, 永真式print(issubclass(B, type)) # False, object 并不继承自 typeprint(issubclass(B(), B)) # TypeError: 实例无法判断继承关系 总结一下： 任何对象，都有一个ob_type，可通过__class__属性得到 任何实例对象的 ob_type，都是 class 对象 任何 class 对象的 ob_type 都是 metaclass 对象 任何 class 对象，都继承自 ，包括 默认的 metaclass 对象是 对应 PyType_Type 对应 PyBaseObject_Type PyType_Ready处理基类和type1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// typeobject.c.4913int PyType_Ready(PyTypeObject *type)&#123; PyObject *dict, *bases; PyTypeObject *base; Py_ssize_t i, n; /* 初始化完成的判断依据 */ if (type-&gt;tp_flags &amp; Py_TPFLAGS_READY) &#123; assert(type-&gt;tp_dict != NULL); return 0; &#125; type-&gt;tp_flags |= Py_TPFLAGS_READYING; /* Reading */ /* 除了Object自身, 其余 tp_base 都设置成 Object class对象 基类信息 PyBaseObject_Type NULL 不存在 PyType_Type NULL 不存在，设置为 object PyLong_Type NULL 不存在，设置为 object PyBool_Type &amp;PyLong_Type 存在，不修改 */ base = type-&gt;tp_base; if (base == NULL &amp;&amp; type != &amp;PyBaseObject_Type) &#123; base = type-&gt;tp_base = &amp;PyBaseObject_Type; Py_INCREF(base); &#125; if (base != NULL &amp;&amp; base-&gt;tp_dict == NULL) &#123; if (PyType_Ready(base) &lt; 0) // 尝试优先初始化基类，最终第一个处理 Object goto error; &#125; /* 设置其 type 为基类的 type 自定义 class A: -&gt; A.base = object -&gt; A.type = object.type = PyType_Type */ if (Py_TYPE(type) == NULL &amp;&amp; base != NULL) Py_TYPE(type) = Py_TYPE(base); /* 初始化 tp_bases 属性 */ bases = type-&gt;tp_bases; if (bases == NULL) &#123; if (base == NULL) /* object.__bases__ = () */ bases = PyTuple_New(0); else /* type.__bases__ = (object,)*/ bases = PyTuple_Pack(1, base); type-&gt;tp_bases = bases; &#125; ...&#125; 从上面的源码中，能清楚的看到基类object、元类type的关系。哇，从此以后再也不会烦恼type和obejct的关系了。 递归到底层，优先执行PyType_Ready(&amp;PyBaseObject_Type)。 处理 tp_dict1234567891011121314151617181920212223242526272829int PyType_Ready(PyTypeObject *type)&#123; ... /* Initialize tp_dict */ dict = type-&gt;tp_dict; if (dict == NULL) &#123; dict = PyDict_New(); if (dict == NULL) goto error; type-&gt;tp_dict = dict; &#125; /* Add type-specific descriptors to tp_dict */ if (add_operators(type) &lt; 0) goto error; if (type-&gt;tp_methods != NULL) &#123; if (add_methods(type, type-&gt;tp_methods) &lt; 0) goto error; &#125; if (type-&gt;tp_members != NULL) &#123; if (add_members(type, type-&gt;tp_members) &lt; 0) goto error; &#125; if (type-&gt;tp_getset != NULL) &#123; if (add_getset(type, type-&gt;tp_getset) &lt; 0) goto error; &#125; ...&#125; 如上，在这一阶段，将各种方法放入type-&gt;tp_dict中。 add_operators1234567891011121314151617181920212223242526272829/* This function is called by PyType_Ready() to populate the type's dictionary with method descriptors for function slots. For each function slot (like tp_repr) that's defined in the type, one or more corresponding descriptors are added in the type's tp_dict dictionary under the appropriate name (like __repr__). Some function slots cause more than one descriptor to be added (for example, the nb_add slot adds both __add__ and __radd__ descriptors) and some function slots compete for the same descriptor (for example both sq_item and mp_subscript generate a __getitem__ descriptor). In the latter case, the first slotdef entry encountered wins. Since slotdef entries are sorted by the offset of the slot in the PyHeapTypeObject, this gives us some control over disambiguating between competing slots: the members of PyHeapTypeObject are listed from most general to least general, so the most general slot is preferred. In particular, because as_mapping comes before as_sequence, for a type that defines both mp_subscript and sq_item, mp_subscript wins. This only adds new descriptors and doesn't overwrite entries in tp_dict that were previously defined. The descriptors contain a reference to the C function they must call, so that it's safe if they are copied into a subtype's __dict__ and the subtype has a different C function in its slot -- calling the method defined by the descriptor will call the C function that was used to create it, rather than the C function present in the slot when it is called. (This is important because a subtype may have a C function in the slot that calls the method from the dictionary, and we want to avoid infinite recursion here.) */ 老套路，开局一段注释。从注释中，我们能提取到一些信息： add_operators 的作用是，将方法 slot 的封装后填充到 type-&gt;to_dict 定义在 type 中的每个方法，都有一个名字与其对应 名字与方法之间的关系不是一一对应 对于同样名字不同方法，选择 offset 较小者 add_operators 只会添加新的方法描述，而不会覆盖已有的 slot 中含有一个可调用的 C 函数 12345678910111213141516171819// typeobject.c.7179static int add_operators(PyTypeObject *type)&#123; PyObject *dict = type-&gt;tp_dict; slotdef *p; PyObject *descr; void **ptr; init_slotdefs(); for (p = slotdefs; p-&gt;name; p++) &#123; ptr = slotptr(type, p-&gt;offset); ... &#125; if (type-&gt;tp_new != NULL) &#123; if (add_tp_new_wrapper(type) &lt; 0) return -1; &#125; return 0;&#125; emmm，注释那么长，代码这么短。注释中谈到的slot果然出现了，并且还是初始化slotdef。既然如此，我们就先看看 slotdef 为何方神圣。 slotdef12345678910111213// typeobject.c.6572typedef struct wrapperbase slotdef;// descrobject.h.26struct wrapperbase &#123; char *name; /* 操作名称 __add__ */ int offset; /* 函数在 PyHeapTypeObject 中的偏移量 */ void *function; /* 函数指针 */ wrapperfunc wrapper; char *doc; int flags; PyObject *name_strobj;&#125;; 在 Python 内部，solt 可以视为表示 PyTypeObject 中定义的操作，一个操作对应一个 slot。从结构体可以看出，不仅含有函数的指针，还有对应的名字以及一个偏移量，这些整体，作为一个描述符 slot。那么，这个offset是什么鬼？ offsetof1234567891011121314151617// typeobject.c.6541#define TPSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \ &#123;NAME, offsetof(PyTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \ PyDoc_STR(DOC)&#125;#define ETSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \ &#123;NAME, offsetof(PyHeapTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \ PyDoc_STR(DOC)&#125;// C标准库 stddef.hsize_t offsetof(type, member-designator);/*参数 type -- class 类型 member-designator -- class 类型的成员指示器。返回值 表示 type 中成员的偏移量。*/ 使用标准库 stddef.h中的offsetof方法，获取结构体中成员的偏移量。TPSLOT与ETSLOT的唯一区别是，指定的结构体不一样。很好，PyHeapTypeObject又是什么东西？ PyHeapTypeObject1234567891011121314151617181920typedef struct _heaptypeobject &#123; PyTypeObject ht_type; PyAsyncMethods as_async; PyNumberMethods as_number; PyMappingMethods as_mapping; PySequenceMethods as_sequence; PyBufferProcs as_buffer; PyObject *ht_name, *ht_slots, *ht_qualname; struct _dictkeysobject *ht_cached_keys;&#125; PyHeapTypeObject;typedef struct _typeobject &#123; ... reprfunc tp_repr; /* Method suites for standard classes */ PyNumberMethods *tp_as_number; PySequenceMethods *tp_as_sequence; /* 注意：顺序不一致 */ PyMappingMethods *tp_as_mapping; ...&#125; PyTypeObject; 观察发现，PyHeapTypeObject 的第一个元素就是 PyTypeObject。意味着，如果一个方法在 PyTypeObject 中，那么通过TPSLOT计算出的偏移量，其实跟该方法在PyHeapTypeObject中的偏移值相等。那么问题来了，这个偏移量到底有什么用？ slotdefs12345678910111213141516171819202122232425262728293031323334353637383940// object.htypedef struct &#123; lenfunc sq_length; binaryfunc sq_concat; ssizeargfunc sq_repeat; ssizeargfunc sq_item; ...&#125; PySequenceMethods;// typeobject.ctypedef struct wrapperbase slotdef;#define ETSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \ &#123;NAME, offsetof(PyHeapTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \ PyDoc_STR(DOC)&#125;#define SQSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \ ETSLOT(NAME, as_sequence.SLOT, FUNCTION, WRAPPER, DOC)static slotdef slotdefs[] = &#123; // 相同名字，不同操作 MPSLOT("__getitem__", mp_subscript, slot_mp_subscript, wrap_binaryfunc, "__getitem__($self, key, /)\n--\n\nReturn self[key]."), SQSLOT("__getitem__", sq_item, slot_sq_item, wrap_sq_item, "__getitem__($self, key, /)\n--\n\nReturn self[key]."), /* wrapperbase = &#123; name = "__getitem__", offset = offsetof(PyHeapTypeObject, as_sequence.slot_sq_item), function = slot_sq_item, wrapperfunc = wrap_sq_item, doc = "__getitem__($self, key, /)\n--\n\nReturn self[key].", flags = None, name_strobj = None &#125; */ // 不同名字，相同操作 BINSLOT("__add__", nb_add, slot_nb_add, "+"), RBINSLOT("__radd__", nb_add, slot_nb_add, "+"), ... &#123;NULL&#125;&#125;; 如上，Python 定义了一个slotdef数组。注意，其中NAME和FUNCTION并不是一一对应的。根据宏的不同，选择不同的函数簇，那么计算出的偏移量肯定也是不同的。在填充tp_dict的过程中，出现相同名字例如__getitem__时，会选择offset较小的那个。所以，offset 实际上是为了对存在相同方法名的，各个函数簇之间的操作优先级进行排序。 是了，跟 add_operators 中的注释内容一模一样。好了，让我们回到最初的起点 add_operators。 add_operators123456789101112131415161718// typeobject.c.7179static int add_operators(PyTypeObject *type)&#123; slotdef *p; // 初始化 init_slotdefs(); // 循环处理 descriptor for (p = slotdefs; p-&gt;name; p++) &#123; ptr = slotptr(type, p-&gt;offset); ... &#125; // 处理 new if (type-&gt;tp_new != NULL) &#123; if (add_tp_new_wrapper(type) &lt; 0) return -1; &#125; return 0;&#125; 如上，三步走。 init_slotdefs123456789101112131415// typeobject.c.6945static int slotdefs_initialized = 0;static void init_slotdefs(void)&#123; slotdef *p; if (slotdefs_initialized) return; for (p = slotdefs; p-&gt;name; p++) &#123; p-&gt;name_strobj = PyUnicode_InternFromString(p-&gt;name); if (!p-&gt;name_strobj || !PyUnicode_CHECK_INTERNED(p-&gt;name_strobj)) Py_FatalError("Out of memory interning slotdef names"); &#125; slotdefs_initialized = 1;&#125; 代码很简单，注意其中的INTERNED。想起来什么没有？根据NAME字符串__str__生成一个UnicodeObject，同时放入 interned 字典中。忘记的不妨看看Unicode 共享机制 循环处理 descriptor12345678910111213141516171819202122232425262728293031PyObject *dict = type-&gt;tp_dict;slotdef *p;PyObject *descr;void **ptr;for (p = slotdefs; p-&gt;name; p++) &#123; // 忽略未指定 warpper 的 func if (p-&gt;wrapper == NULL) continue; // 获取实际指针 ptr = slotptr(type, p-&gt;offset); if (!ptr || !*ptr) continue; // 此处，忽略已经存在的，对应上文的注释 if (PyDict_GetItem(dict, p-&gt;name_strobj)) continue; if (*ptr == (void *)PyObject_HashNotImplemented) &#123; // 不可hash对象 if (PyDict_SetItem(dict, p-&gt;name_strobj, Py_None) &lt; 0) return -1; &#125; else &#123; // 创建 descriptor descr = PyDescr_NewWrapper(type, p, *ptr); // 将 descriptor 作为 Value 放入字典 if (PyDict_SetItem(dict, p-&gt;name_strobj, descr) &lt; 0) &#123; Py_DECREF(descr); return -1; &#125; Py_DECREF(descr); &#125;&#125; 如上，在循环的过程中，会先通过 slotptr获取到实际的 slotdef 指针。然后为每个 slotdef 创建一个 descr，最后实际放入字典的是 descr 而不是 slot，这是为什么？ 1234struct wrapperbase &#123; void *function; /* 函数指针 */ wrapperfunc wrapper;&#125; slotdef; 回想一下关于 slotdef 的定义，似乎这就是一个单纯的C结构体。所以，必须对其进行包装，生成一个 PyObejct，才能放入字典中。 PyWrapperDescrObject12345678910111213141516171819202122232425262728293031323334353637// descobject.htypedef struct &#123; PyObject_HEAD PyTypeObject *d_type; PyObject *d_name; PyObject *d_qualname;&#125; PyDescrObject;typedef struct &#123; PyDescrObject d_common; struct wrapperbase *d_base; void *d_wrapped; /* This can be any function pointer */&#125; PyWrapperDescrObject;PyObject *PyDescr_NewWrapper(PyTypeObject *type, struct wrapperbase *base, void *wrapped)&#123; PyWrapperDescrObject *descr; descr = (PyWrapperDescrObject *)descr_new(&amp;PyWrapperDescr_Type, type, base-&gt;name); descr-&gt;d_base = base; /* 存放 slotdef */ descr-&gt;d_wrapped = wrapped; /* 存放 实际的函数指针 */ return (PyObject *)descr;&#125;static PyDescrObject *descr_new(PyTypeObject *descrtype, PyTypeObject *type, const char *name)&#123; PyDescrObject *descr; // 指定了 type 为 PyWrapperDescr_Type descr = (PyDescrObject *)PyType_GenericAlloc(descrtype, 0); Py_XINCREF(type); descr-&gt;d_type = type; descr-&gt;d_name = PyUnicode_InternFromString(name); descr-&gt;d_qualname = NULL; return descr;&#125; 如上，代码很简单。PyWrapperDescrObject 的 type 为 PyWrapperDescr_Type，因此调用 tp_dict[“xx“]，将会调用PyWrapperDescr_Type.__call__。 slot_tp_repr123456static slotdef slotdefs[] = &#123; TPSLOT("__repr__", tp_repr, slot_tp_repr, wrap_unaryfunc, TPSLOT("__str__", tp_str, slot_tp_str, wrap_unaryfunc, "__str__($self, /)\n--\n\nReturn str(self)."), ...&#125; 在上面的slotdefs介绍中，其实还存在另外一种模式。想想 Python 中自定义__str__方法，按照循环处理中的逻辑，已经存在的方法，不会被替换。那么用户自定义的方法如何实现的？ 123456789101112static PyObject * slot_tp_str(PyObject *self)&#123; PyObject *func, *res; _Py_IDENTIFIER(__str__); func = lookup_method(self, &amp;PyId___str__); if (func == NULL) return NULL; res = PyEval_CallObject(func, NULL); Py_DECREF(func); return res;&#125; 如上，在最终调用__str__方法时，表面调用的是slot_tp_str，内部却通过lookup_method，找到用户自定义的__str__，执行。具体内容留在 Python 自定义类 讲述。 PyType_Ready-2123456789101112131415161718192021222324252627282930313233343536373839/* Add type-specific descriptors to tp_dict */if (add_operators(type) &lt; 0) goto error;/* 添加其他函数簇:add_* *//* 创建 MRO：mro_internal *//* 继承属性、方法 ： 从 base 继承 flags 从 mro 继承 slotdef 方法 从 base 继承 tp_as_number 等函数簇*//* 遍历 tp_mro，验证所有 class 都应是静态分配的 *//* Sanity check for tp_free： 如果可以被GC，那么 tp_free 必然不为NULL，且是可被调用*//* if the type dictionary doesn't contain a __doc__ set it from the tp_doc slot. *//* __hash__ 是不继承的 if tp_has is NULL and '__hash__' not in tp_dict: tp_dict['__hash__'] = None 设置 type 为不可 hash*//* 遍历 bases，为 base 添加子类： add_subclass((PyTypeObject *)b, type)*//* All done -- set the ready flag type-&gt;tp_flags &amp; ~Py_TPFLAGS_READYING type-&gt;tp_flags | Py_TPFLAGS_READY*/return 0; add_*最终，在 add_operators 完成后的布局如下： 其中，PyList_Type.tp_as_mapping等都是在编译时确定，而 tp_dict 是Python 运行时初始化建立的。 123456789101112if (type-&gt;tp_methods != NULL) &#123; if (add_methods(type, type-&gt;tp_methods) &lt; 0) goto error;&#125;if (type-&gt;tp_members != NULL) &#123; if (add_members(type, type-&gt;tp_members) &lt; 0) goto error;&#125;if (type-&gt;tp_getset != NULL) &#123; if (add_getset(type, type-&gt;tp_getset) &lt; 0) goto error;&#125; PyType_Ready 在通过 add_operators 添加了 PyTypeObject 中定义的方法后，再将定义的函数簇添加到 tp_dict 中。 12345678910111213141516171819202122232425262728293031323334353637383940414243struct PyMethodDef &#123; const char *ml_name; /* The name of the built-in function/method */ PyCFunction ml_meth; /* The C function that implements it */ int ml_flags; /* Combination of METH_xxx flags, which mostly describe the args expected by the C func */ const char *ml_doc; /* The __doc__ attribute, or NULL */&#125; PyMethodDef;// typeobject.c.4581static intadd_methods(PyTypeObject *type, PyMethodDef *meth)&#123; PyObject *dict = type-&gt;tp_dict; for (; meth-&gt;ml_name != NULL; meth++) &#123; PyObject *descr; if (meth-&gt;ml_flags &amp; METH_CLASS) &#123; descr = PyDescr_NewClassMethod(type, meth); &#125; else if (meth-&gt;ml_flags &amp; METH_STATIC) &#123; PyObject *cfunc = PyCFunction_NewEx(meth, (PyObject*)type, NULL); descr = PyStaticMethod_New(cfunc); Py_DECREF(cfunc); &#125; else &#123; descr = PyDescr_NewMethod(type, meth); &#125; err = PyDict_SetItemString(dict, meth-&gt;ml_name, descr); &#125; return 0;&#125;PyObject *PyDescr_NewMethod(PyTypeObject *type, PyMethodDef *method)&#123; descr = (PyMethodDescrObject *)descr_new(&amp;PyMethodDescr_Type, type, method-&gt;ml_name);&#125;&#125;PyObject *PyDescr_NewClassMethod(PyTypeObject *type, PyMethodDef *method)&#123; descr = (PyMethodDescrObject *)descr_new(&amp;PyClassMethodDescr_Type, type, method-&gt;ml_name);&#125; 如上，在 add_method 的过程中，判断方法类型，在生成对应的 DescrObject，但最终都当做 PyMethodDescrObject 使用。同理，tp_members,add_getset放入tp_dict 的都是对应的DescrObject。 mro_internal12345678910111213141516171819202122232425/* Calculate method resolution order */if (mro_internal(type, NULL) &lt; 0) goto error;/* 计算并赋值 type-&gt;tp_mro - 正常返回1 - 自定义了 mro()，而导致 tp_mro 发生更改时，返回 0 - 错误返回 -1*/static intmro_internal(PyTypeObject *type, PyObject **p_old_mro)&#123; PyObject *new_mro, *old_mro; new_mro = mro_invoke(type); type-&gt;tp_mro = new_mro;&#125;/* 在 mro_invoke() 中： if type!=PyType_Type: 查找 自定义的 mro_meth mro_reslt = mero_meth() new_mro = PySequence_Tuple(mro_result); return new_mro*/ 在mro_internal中实现了 MRO 的创建，可以看到，MRO 是一个元组对象。其中的元素都是 class对象，方 Inherit1234567891011121314151617181920/* inherit_special: 视情况拷贝，tp_clear、tp_traverse、tp_itemsize等 根据base，继承 flag, 更改 tp_flags*/if (type-&gt;tp_base != NULL) inherit_special(type, type-&gt;tp_base);/* Initialize tp_dict properly */bases = type-&gt;tp_mro;n = PyTuple_GET_SIZE(bases);for (i = 1; i &lt; n; i++) &#123; PyObject *b = PyTuple_GET_ITEM(bases, i); if (PyType_Check(b)) inherit_slots(type, (PyTypeObject *)b);&#125;base = type-&gt;tp_base;if (base != NULL) &#123; if (type-&gt;tp_as_async == NULL) type-&gt;tp_as_async = base-&gt;tp_as_async; 如上，从 base 继承一些属性，并从 mro 中，继承 方法。 总结PyType_Ready 对 type 对象进行初始化操作： 处理基类：除了Object自身, 其余 tp_base 都设置成 Object 处理 type：if type.type is NULL: type.type = base.type 处理 bases：object.bases = (); otherClass.bases = (object,) 填充 tp_dict：遍历 slotdefs，放入 DescrObject 创建 mro：调用 mro_internal 从base、mro、继承 flags 方法等 为基类添加注册子类：add_subclass]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>类机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 函数机制]]></title>
    <url>%2F2018%2F07%2F21%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.9.Python%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[参考 Function Objects dis.rst: Disassembler for Python bytecode 前言在前面我们已经知道 Python 通过PyInterpreterState 对象模拟进程的状态信息，通过 PyThreadState 对象模拟线程的状态信息，通过PyFrameObject 模拟函数调用时的栈帧信息。FrameObject 通过 f_back 指针，形成函数调用的链式结构。那么要实现函数间的调用，就必然存在多个 Frame。 PyFunctionObject12345678910111213141516// funcobject.h.21typedef struct &#123; PyObject_HEAD PyObject *func_code; /* A code object, the __code__ attribute */ PyObject *func_globals; /* A dictionary (命名空间) */ PyObject *func_defaults; /* NULL or a tuple，默认参数*/ PyObject *func_kwdefaults; /* NULL or a dict，默认参数 */ PyObject *func_closure; /* NULL or a tuple，用于闭包*/ PyObject *func_doc; /* __doc__ attribute, can be anything */ PyObject *func_name; /* __name__ attribute, a string object */ PyObject *func_dict; /* __dict__ attribute, a dict or NULL */ PyObject *func_weakreflist; /* List of weak references */ PyObject *func_module; /* __module__ attribute, can be anything */ PyObject *func_annotations; /* Annotations, a dict or NULL */ PyObject *func_qualname; /* The qualified name */&#125; PyFunctionObject; 如上，PyFunctionObject 中存放着对应的 CodeObject，除此之外还包含着运行需要的其他信息。这些其他信息，例如命名空间，只有在运行过程中才能获取到。可见 FuncObject 必然是在运行过程中创建的，而 CodeObject 却是在编译时创建的。 函数创建123456789101112def f(): passco_names: ('f',)co_consts: (&lt;code object f , file "demo.py", line 1&gt;, 'f', None) 1 0 LOAD_CONST 0 (&lt;code object f , file "demo.py", line 1&gt;) 2 LOAD_CONST 1 ('f') 4 MAKE_FUNCTION 0 /* 稍稍留意，此处为0 */ 6 STORE_NAME 0 (f) 8 LOAD_CONST 2 (None) 10 RETURN_VALUE 在前面我们已经知道，CodeObject 是一种嵌套结构，正如上面的 。命名空间 builtin 中的 ‘function’ 对应着 PyFunction_Type。既然已经知道 FuncObject 是动态创建的，那么MAKE_FUNCTION就很值得怀疑。 MAKE_FUNCTION 无参数12345678910111213141516/*opcode:: MAKE_FUNCTION (argc) Pushes a new function object on the stack. From bottom to top, the consumed stack must consist of values if the argument carries a specified flag value*/TARGET(MAKE_FUNCTION) &#123; PyObject *qualname = POP(); PyObject *codeobj = POP(); PyFunctionObject *func = (PyFunctionObject *) PyFunction_NewWithQualName(codeobj, f-&gt;f_globals, qualname); ... // 根据 oparg, 处理默认值：func_defaults，func_closure等 PUSH((PyObject *)func); DISPATCH();&#125; 果然，从栈中取出名字+CodeObject，然后创建一个新的 FuncObject，封装属性，压入栈中。 PyFunction_NewWithQualName1234567891011121314// funcobject.c.9PyObject *PyFunction_NewWithQualName(PyObject *code, PyObject *globals, PyObject *qualname)&#123; PyFunctionObject *op; PyObject *doc, *consts, *module; op = PyObject_GC_New(PyFunctionObject, &amp;PyFunction_Type); ... // 封装属性 op-&gt;func_code = code; op-&gt;func_globals = globals; _PyObject_GC_TRACK(op); return (PyObject *)op;&#125; 如上，新的 FuncObject 属性封装分别在两个地方进行。完事后下一条指令STORE_NAME将栈顶的FuncObject 移入命名空间 local 中。 函数执行CALL_FUNCTION1234567891011// print('1')co_consts: ('1', None)co_names: ('print',) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('1') 4 CALL_FUNCTION 1 6 POP_TOP 8 LOAD_CONST 1 (None) 10 RETURN_VALUE 执行函数时，从 local 中加载对象，执行指令CALL_FUNCTION。 12345678910111213141516171819202122232425/*opcode:: CALL_FUNCTION (argc) Calls a function. *argc* indicates the number of positional arguments. The positional arguments are on the stack, with the right-most argument on top. Below the arguments, the function object to call is on the stack. Pops all function arguments, and the function itself off the stack, and pushes the return value. versionchanged:: 3.6 This opcode is used only for calls with positional arguments.*/TARGET(CALL_FUNCTION) &#123; PyObject **sp, *res; PCALL(PCALL_ALL); sp = stack_pointer; // 获取到当前 f-&gt;f_stacktop res = call_function(&amp;sp, oparg, NULL); // 调用函数，同时传入函数参数个数 stack_pointer = sp; // 设置 栈顶 PUSH(res); if (res == NULL) &#123; goto error; &#125; DISPATCH();&#125; 在执行CALL_FUNCTION指令时，获得当前运行时栈栈顶指针，进入call_function。 call_function12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// ceval.c.4806static PyObject *call_function(PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)&#123; // 根据栈顶和函数参数个数，计算获取 func PyObject **pfunc = (*pp_stack) - oparg - 1; PyObject *func = *pfunc; PyObject *x, *w; Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames); Py_ssize_t nargs = oparg - nkwargs; PyObject **stack; if (PyCFunction_Check(func)) &#123; PyThreadState *tstate = PyThreadState_GET(); stack = (*pp_stack) - nargs - nkwargs; x = _PyCFunction_FastCallKeywords(func, stack, nargs, kwnames); &#125; else &#123; // (func)-&gt;ob_type == &amp;PyMethod_Type if (PyMethod_Check(func) &amp;&amp; PyMethod_GET_SELF(func) != NULL) &#123; // ((PyMethodObject *)func) -&gt; im_self PyObject *self = PyMethod_GET_SELF(func); PCALL(PCALL_METHOD); PCALL(PCALL_BOUND_METHOD); Py_INCREF(self); // ((PyMethodObject *)func) -&gt; im_func func = PyMethod_GET_FUNCTION(func); Py_INCREF(func); Py_SETREF(*pfunc, self); // self == &amp;func nargs++; &#125; else &#123; Py_INCREF(func); &#125; stack = (*pp_stack) - nargs - nkwargs; if (PyFunction_Check(func)) &#123; x = fast_function(func, stack, nargs, kwnames); &#125; else &#123; x = _PyObject_FastCallKeywords(func, stack, nargs, kwnames); &#125; Py_DECREF(func); &#125; ... return x;&#125; 如上，代码不长，先是Check_type()，若对应PyMethod_Type，还得调用PyMethod_GET_FUNCTION，获取到最终的 func，并且把self 作为位置参数传递进去。最后，判断Func_Type，进行分发。 在前面PyObject_GC_New(PyFunctionObject, &amp;PyFunction_Type)中，传入的是PyFunction_Type，将进入到fast_function()。 fast_function123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// ceval.c.4916static PyObject *fast_function(PyObject *func, PyObject **stack, Py_ssize_t nargs, PyObject *kwnames)&#123; PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func); PyObject *globals = PyFunction_GET_GLOBALS(func); // func -&gt; func_globals PyObject *argdefs = PyFunction_GET_DEFAULTS(func); // func -&gt; func_defaults PyObject *kwdefs, *closure, *name, *qualname; PyObject **d; Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames); Py_ssize_t nd; assert(PyFunction_Check(func)); assert(nargs &gt;= 0); assert(kwnames == NULL || PyTuple_CheckExact(kwnames)); assert((nargs == 0 &amp;&amp; nkwargs == 0) || stack != NULL); PCALL(PCALL_FUNCTION); PCALL(PCALL_FAST_FUNCTION); /* 处理无需 关键字参数的函数 */ if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp; co-&gt;co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) &#123; /* 无默认参数，且参数个数刚好满足 func 需要 */ if (argdefs == NULL &amp;&amp; co-&gt;co_argcount == nargs) &#123; return _PyFunction_FastCall(co, stack, nargs, globals); &#125; /* 无参数传递，但 func 每个参数都有默认参数 */ else if (nargs == 0 &amp;&amp; argdefs != NULL &amp;&amp; co-&gt;co_argcount == Py_SIZE(argdefs)) &#123; stack = &amp;PyTuple_GET_ITEM(argdefs, 0); return _PyFunction_FastCall(co, stack, Py_SIZE(argdefs), globals); &#125; &#125; /* 含有关键字参数 见：_PyEval_EvalCodeWithName */ ...&#125;typedef struct &#123; PyObject_HEAD int co_argcount; /* 位置参数 *args 个数 */ int co_kwonlyargcount; /* #keyword only arguments */ int co_nlocals; /* 局部变量个数，包含位置参数 */ PyObject *co_code; /* 字节码序列，PyStringObject 形式 */ PyObject *co_consts; /* list (所有常量) */ PyObject *co_names; /* list of strings (所有符号) */ PyObject *co_varnames; /* tuple of strings (局部变量名) */ PyObject *co_freevars; /* tuple of strings (闭包所需变量名) */ PyObject *co_cellvars; /* tuple of strings ...&#125; PyCodeObject; 如上，CodeObject中含有 block 所需的关键字参数，当不含关键字参数时，调用_PyFunction_FastCall。否则，执行_PyEval_EvalCodeWithName。 无参数：PyFunction_FastCall123456789101112131415161718192021222324252627// ceval.c.4879static PyObject*_PyFunction_FastCall(PyCodeObject *co, PyObject **args, Py_ssize_t nargs, PyObject *globals)&#123; PyFrameObject *f; PyThreadState *tstate = PyThreadState_GET(); PyObject **fastlocals; Py_ssize_t i; PyObject *result; PCALL(PCALL_FASTER_FUNCTION); f = PyFrame_New(tstate, co, globals, NULL); fastlocals = f-&gt;f_localsplus; for (i = 0; i &lt; nargs; i++) &#123; Py_INCREF(*args); fastlocals[i] = *args++; &#125; result = PyEval_EvalFrameEx(f,0); ++tstate-&gt;recursion_depth; Py_DECREF(f); --tstate-&gt;recursion_depth; return result;&#125; 如上，创建一个FrameObject，执行CodeObject中的字节码。函数执行完成后，将结果返回到 result中，完成了类似C语言的函数调用过程。关于 PyEval_EvalFrameEx 的执行逻辑，在 PyCodeObject/PyFrameObject 中已经叙述过。 这里很明显能够观察到，在新的栈帧对象中，执行的是传入的CodeObject中的字节码序列，上下文环境是通过命名空间globals实现。那么函数要调用其他的函数，该怎么实现？很容易想到在fast_function中的含有关键字参数的执行逻辑。 有参数：PyEval_EvalCodeWithName123456789101112131415161718192021kwdefs = PyFunction_GET_KW_DEFAULTS(func); // func -&gt; func_kwdefaultsclosure = PyFunction_GET_CLOSURE(func); // func -&gt; func_closurename = ((PyFunctionObject *)func) -&gt; func_name;qualname = ((PyFunctionObject *)func) -&gt; func_qualname;if (argdefs != NULL) &#123; /* 有参数传递时，需判断个数，以便获取默认参数 */ d = &amp;PyTuple_GET_ITEM(argdefs, 0); nd = Py_SIZE(argdefs);&#125;else &#123; d = NULL; nd = 0;&#125;return _PyEval_EvalCodeWithName((PyObject*)co, globals, (PyObject *)NULL, stack, nargs, nkwargs ? &amp;PyTuple_GET_ITEM(kwnames, 0) : NULL, stack + nargs, nkwargs, 1, d, (int)nd, kwdefs, closure, name, qualname); 123456789101112131415161718192021222324252627// ceval.c.3888_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals, PyObject **args, Py_ssize_t argcount, PyObject **kwnames, PyObject **kwargs, Py_ssize_t kwcount, int kwstep, PyObject **defs, Py_ssize_t defcount, PyObject *kwdefs, PyObject *closure, PyObject *name, PyObject *qualname)&#123; ... /* Create the frame */ f = PyFrame_New(tstate, co, globals, locals); /* Create a dictionary for keyword parameters (**kwags) */ /* Copy positional arguments into local variables */ /* Pack other positional arguments into the *args argument */ /* Handle keyword arguments passed as two strided arrays */ /* Check the number of positional arguments */ /* Add missing positional arguments (copy default values from defs) */ /* Add missing keyword arguments (copy default values from kwdefs) */ /* Allocate and initialize storage for cell vars, and copy free vars into frame. */ /* Copy closure variables to free variables */ /* Handle generator/coroutine/asynchronous generator */ retval = PyEval_EvalFrameEx(f,0);&#125; 如上，不管有参数无参数，最终都是创建栈帧对象，在新的上下文环境执行被调函数字节码指令。唯一的区别仅在于，对被调函数可能存在的参数进行处理，其中涉及到可变参数，默认参数，闭包参数等。详细内容可以阅读源码。 这里要提一句，判断函数是否含有可变参数，是通过 CodeObject-&gt;co_flags 字段实现。12345#define CO_VARARGS 0x0004 /* CodeObject 存在可变位置参数 *args */#define CO_VARKEYWORDS 0x0008 /* CodeObject 存在可变关键字参数 **kwargs *//* Create a dictionary for keyword parameters (**kwags) */if (co-&gt;co_flags &amp; CO_VARKEYWORDS) &#123; ... &#125; 函数参数如果是 C，会有值传递和地址传递这个说法。 在Python中，调用时传递的都是 对象 有的对象 1 ‘abc’ (1,3) 是不可变的 有的对象[1,3] {1,3} 是可变的 如果被调用函数需要修改对象内容：1.不可变的，自然只能新创建一个对象。2.是可变的，自然直接在对象内容删更改 而调用函数原持有的对象引用，还是指向之前的对象。 1234567891011121314151617181920def fun(a, b=3): passfun(1) 3 10 LOAD_NAME 0 (fun) 12 LOAD_CONST 3 (1) 14 CALL_FUNCTION 1fun(1, 2) 3 10 LOAD_NAME 0 (fun) 12 LOAD_CONST 3 (1) 14 LOAD_CONST 4 (2) 16 CALL_FUNCTION 2fun(1, b=2) 3 10 LOAD_NAME 0 (fun) 12 LOAD_CONST 3 (1) 14 LOAD_CONST 4 (2) 16 LOAD_CONST 5 ((&apos;b&apos;,)) 18 CALL_FUNCTION_KW 2 由上可见，函数的参数是位置参数还是关键字参数，是跟参数的传递方式有关，而与定义无关。函数的参数通过指令LOAD_*压入栈中，那么问题来了，上面的例子中b=3是如何生效的？ MAKE_FUNCTION 带参数1234567def fun(a, b=3): pass 1 0 LOAD_CONST 6 ((3,)) 2 LOAD_CONST 1 (&lt;code object fun, file &quot;demo.py&quot;, line 1&gt;) 4 LOAD_CONST 2 (&apos;fun&apos;) 6 MAKE_FUNCTION 1 /* 注意此处 */ 此处，指令序列MAKE_FUNCTION比我们在函数创建中用到的，多了一个参数 1。所以，是时候来看下在MAKE_FUNCTION中，我们注释的那一段内容了。 1234567891011121314151617181920212223242526272829/*-&gt; 栈底方向 * ``0x01`` a tuple of default argument objects in positional order * ``0x02`` a dictionary of keyword-only parameters' default values * ``0x04`` an annotation dictionary * ``0x08`` a tuple containing cells for free variables, making a closure-&gt; 栈顶方向*/TARGET(MAKE_FUNCTION) &#123; ... // 根据 oparg, 处理默认值：func_defaults，func_closure等 if (oparg &amp; 0x08) &#123; assert(PyTuple_CheckExact(TOP())); func -&gt;func_closure = POP(); /* 闭包 */ &#125; if (oparg &amp; 0x04) &#123; assert(PyDict_CheckExact(TOP())); func-&gt;func_annotations = POP(); /* 函数注解 */ &#125; if (oparg &amp; 0x02) &#123; assert(PyDict_CheckExact(TOP())); func-&gt;func_kwdefaults = POP(); /* keyword-only 参数默认值 */ &#125; if (oparg &amp; 0x01) &#123; assert(PyTuple_CheckExact(TOP())); func-&gt;func_defaults = POP(); /* 位置参数默认值 */ &#125; ...&#125; 真相很明显了，默认参数、函数注解、闭包属性，都各自从栈顶POP，放入 FuncObj 属性中。下面就来看一个实际的例子。 MAKE_FUNCTION 131234567891011121314151617181920// demo.pydef f(): clu = &apos;clu&apos; def c(a:int = 1): print(clu)co = compile(open(&apos;demo.py&apos;).read(),&apos;demo.py&apos;,&apos;exec&apos;); import dis; f = co.co_consts[0]; dis.dis(f) 2 0 LOAD_CONST 1 (&apos;clu&apos;) 2 STORE_DEREF 0 (clu) 3 4 LOAD_CONST 6 ((1,)) 6 LOAD_GLOBAL 0 (int) 8 LOAD_CONST 3 ((&apos;a&apos;,)) 10 BUILD_CONST_KEY_MAP 1 12 LOAD_CLOSURE 0 (clu) 14 BUILD_TUPLE 1 16 LOAD_CONST 4 (&lt;code object c , file &quot;demo.py&quot;, line 3&gt;) 18 LOAD_CONST 5 (&apos;f.&lt;locals&gt;.c&apos;) 20 MAKE_FUNCTION 13 /* 注意此处，13 = 8+4+1*/ 22 STORE_FAST 0 (c) 如上，在def c中，同时用到了3种。那么问题来了剩下的func_kwdefaults如何实现？留给大家思考。哈~欢迎留言~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyFunctionObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 异常控制]]></title>
    <url>%2F2018%2F07%2F21%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.8.Python%20%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言本章将通过字节码指令，探究 Python 中try-except等异常控制语句的实现及原理。阅读本章前需了解PyCodeObject/PyFrameObject。开局一张陈儒先生著作《Python 源码剖析》中的附图： 1/0123456789101/0co_consts: (1, 0, None) 1 0 LOAD_CONST 0 (1) 2 LOAD_CONST 1 (0) 4 BINARY_TRUE_DIVIDE 6 POP_TOP 8 LOAD_CONST 2 (None) 10 RETURN_VALUE 其他的先不谈，先来看上面的字节码。4+6 就是一个/运算。很明显，重点落在BINARY_TRUE_DIVIDE中。 BINARY_TRUE_DIVIDE12345678910111213141516171819#define BINARY_TRUE_DIVIDE 27TARGET(BINARY_TRUE_DIVIDE) &#123; /* TOS = TOS1 / TOS */ PyObject *divisor = POP(); PyObject *dividend = TOP(); PyObject *quotient = PyNumber_TrueDivide(dividend, divisor); Py_DECREF(dividend); Py_DECREF(divisor); SET_TOP(quotient); if (quotient == NULL) goto error; DISPATCH();&#125;PyNumber_TrueDivide -&gt; binary_op(v, w, NB_SLOT(nb_true_divide), "/")-&gt; binary_op1(v, w, op_slot)-&gt; v-&gt;ob_type-&gt;tp_as_number[op_slot](v, w)-&gt; long_true_divide(v, w) 1/0最终进入到longobject.c中去执行，源码中有很长一段关于除法运算的注释，有兴趣可以看看。我们这里只关注异常处理的部分。 long_true_divide1234567891011// longobject.c.long_true_divideif (Py_ABS(Py_SIZE(b)) == 0) &#123; PyErr_SetString(PyExc_ZeroDivisionError, "division by zero"); goto error;&#125;overflow: PyErr_SetString(PyExc_OverflowError, "integer division result too large for a float");error: return NULL; 在前面的部分中，其实我们已经看见了 Python 关于故障报错的处理方式，ZeroDivisionError同样是通过这种方式实现。那么，问题来了，这个PyExc_ZeroDivisionError又是个什么东西？ PyErrorObject123456789101112131415161718192021222324// pyport.hdefine PyAPI_DATA(RTYPE) extern RTYPE// pyerrors.hPyAPI_DATA(PyObject *) PyExc_ZeroDivisionError;typedef struct &#123; PyException_HEAD&#125; PyBaseExceptionObject;typedef struct &#123; PyException_HEAD PyObject *msg; PyObject *filename; PyObject *lineno; PyObject *offset; PyObject *text; PyObject *print_file_and_line;&#125; PySyntaxErrorObject;PyAPI_FUNC(void) PyErr_SetString( PyObject *exception, const char *string /* decoded from utf-8 */); 果然，一切皆为对象。long_true_divide 似乎就干了两件事，SetString&amp;Return NULL。BINARY_TRUE_DIVIDE先把结果入栈SET_TOP()，判断结果为空，goto error。 goto error123456789101112131415error: why = WHY_EXCEPTION; // !!! /* Log traceback info. */ PyTraceBack_Here(f);fast_block_end: /* Unwind stacks if a (pseudo) exception occurred */ while (why != WHY_NOT &amp;&amp; f-&gt;f_iblock &gt; 0) &#123; ... &#125; /* unwind stack */ /* End the loop if we still have an error (or return) */ if (why != WHY_NOT) break;&#125; /* main loop */ emmm，代码很长。从上面的轮廓可以看见，在 error 中 TraceBack。在 fast_block_end 中，尝试在栈链上逐级捕捉错误。否则，最终退出循环，结束程序。 PyTraceBack_Here12345678910111213// traceback.c.133int PyTraceBack_Here(PyFrameObject *frame)&#123; PyObject *exc, *val, *tb, *newtb; /* 先保存，后清空 */ PyErr_Fetch(&amp;exc, &amp;val, &amp;tb); // 构建新的 traceback，形成链表 newtb = (PyObject *)newtracebackobject((PyTracebackObject *)tb,frame); // 将新的异常对象存储到线程状态对象中 PyErr_Restore(exc, val, newtb); Py_XDECREF(tb); return 0;&#125; 如上，代码很简单，将 Frame 的错误信息保存起来，构建一个新的 tb，插入到原有的链中。 PyErr_Fetch123456789101112131415// errors.c.339voidPyErr_Fetch(PyObject **p_type, PyObject **p_value, PyObject **p_traceback)&#123; // 保存线程异常对象，并清空 PyThreadState *tstate = PyThreadState_GET(); *p_type = tstate-&gt;curexc_type; *p_value = tstate-&gt;curexc_value; *p_traceback = tstate-&gt;curexc_traceback; tstate-&gt;curexc_type = NULL; tstate-&gt;curexc_value = NULL; tstate-&gt;curexc_traceback = NULL;&#125; newtracebackobject123456789101112131415161718// traceback.c.111static PyTracebackObject *newtracebackobject(PyTracebackObject *next, PyFrameObject *frame)&#123; PyTracebackObject *tb; ... tb = PyObject_GC_New(PyTracebackObject, &amp;PyTraceBack_Type); if (tb != NULL) &#123; Py_XINCREF(next); tb-&gt;tb_next = next; // 关键步骤，链表插入 Py_XINCREF(frame); tb-&gt;tb_frame = frame; tb-&gt;tb_lasti = frame-&gt;f_lasti; tb-&gt;tb_lineno = PyFrame_GetLineNumber(frame); PyObject_GC_Track(tb); &#125; return tb;&#125; try-except1234567891011121314151617181920212223242526272829303132333435363738394041424344try: 1 / 0except ZeroDivisionError: passco_consts: (1, 0, None)co_names: ('ZeroDivisionError',) 1 0 SETUP_EXCEPT 12 (to 14)/* 在FOR控制流中已经提到，等效于 SETUP_LOOP，构建一个 TryBlock PyFrame_BlockSetup( PyFrameObject * = f, int type = opcode = SETUP_EXCEPT, int handler = INSTR_OFFSET() + oparg = 14, int level = STACK_LEVEL() = stack_pointer - f-&gt;f_valuestack ) b = &amp;f-&gt;f_blockstack[f-&gt;f_iblock++]; 对b 进行赋值;*/ 2 2 LOAD_CONST 0 (1) 4 LOAD_CONST 1 (0) 6 BINARY_TRUE_DIVIDE/* PyErr_SetString(PyExc_ZeroDivisionError); SET_TOP(NULL); goto error; PyTraceBack_Here(); goto fast_block_end;*/ 8 POP_TOP 10 POP_BLOCK 12 JUMP_FORWARD 20 (to 34) // JUMPBY(20) 3 &gt;&gt; 14 DUP_TOP 16 LOAD_NAME 0 (ZeroDivisionError) 18 COMPARE_OP 10 (exception match) 20 POP_JUMP_IF_FALSE 32 22 POP_TOP 24 POP_TOP 26 POP_TOP 4 28 POP_EXCEPT 30 JUMP_FORWARD 2 (to 34) &gt;&gt; 32 END_FINALLY &gt;&gt; 34 LOAD_CONST 2 (None) 36 RETURN_VALUE 前面关于goto error的问题，我们先放一放，先看一段字节码指令。一段try-except的代码，编译结果高达30+行，即使是try 1/1结果也是30+行。 前面我们已经知道1/0 对应 6+8。如果顺序执行，字节码12，就直接跳转到字节码34，结束程序，这显然是不可能的。那么必然，在BINARY_TRUE_DIVIDE中会发生些什么。想起来没有？对，goto erorr！接下来就到了fast_block_end。 fast_block_end123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990why = WHY_EXCEPTION;while (why != WHY_NOT &amp;&amp; f-&gt;f_iblock &gt; 0) &#123; /* Peek at the current block */ PyTryBlock *b = &amp;f-&gt;f_blockstack[f-&gt;f_iblock - 1]; /* Now we have to pop the block. */ f-&gt;f_iblock--; if (b-&gt;b_type == EXCEPT_HANDLER) &#123; // == 257 UNWIND_EXCEPT_HANDLER(b); continue; &#125; UNWIND_BLOCK(b); if (b-&gt;b_type == SETUP_LOOP &amp;&amp; why == WHY_BREAK) &#123; why = WHY_NOT; JUMPTO(b-&gt;b_handler); break; &#125; if (why == WHY_EXCEPTION &amp;&amp; (b-&gt;b_type == SETUP_EXCEPT || b-&gt;b_type == SETUP_FINALLY)) &#123; // 判断是否在 try-except 块中 PyObject *exc, *val, *tb; int handler = b-&gt;b_handler; /* 在FOR控制流 SETUP_LOOP 中有提到 从数组中获取一个新的 TryBlock，并放入信息 PyFrame_BlockSetup( PyFrameObject * = f, int type = EXCEPT_HANDLER, int handler = -1, int level = STACK_LEVEL() = stack_pointer - f-&gt;f_valuestack ) 构建一个新的 block 用于处理异常 */ PyFrame_BlockSetup(f, EXCEPT_HANDLER, -1, STACK_LEVEL()); /* 在 PyTraceBack_Here 中，已经构建了一个新的 tb 此处，将异常信息压栈 */ PUSH(tstate-&gt;exc_traceback); PUSH(tstate-&gt;exc_value); if (tstate-&gt;exc_type != NULL) &#123; PUSH(tstate-&gt;exc_type); &#125; else &#123; Py_INCREF(Py_None); PUSH(Py_None); &#125; /* 先保存，后清空 线程异常对象 */ PyErr_Fetch(&amp;exc, &amp;val, &amp;tb); /* 详见 errors.c。 递归调用 PyErr_NormalizeExceptionEx() */ PyErr_NormalizeException(&amp;exc, &amp;val, &amp;tb); if (tb != NULL) PyException_SetTraceback(val, tb); else PyException_SetTraceback(val, Py_None); Py_INCREF(exc); tstate-&gt;exc_type = exc; Py_INCREF(val); tstate-&gt;exc_value = val; tstate-&gt;exc_traceback = tb; if (tb == NULL) tb = Py_None; Py_INCREF(tb); /* 压入运行时栈 */ PUSH(tb); PUSH(val); PUSH(exc); /* 结束异常发现阶段，跳转到 handler，进行异常处理 */ why = WHY_NOT; JUMPTO(handler); break; &#125; if (b-&gt;b_type == SETUP_FINALLY) &#123; if (why &amp; (WHY_RETURN | WHY_CONTINUE)) PUSH(retval); PUSH(PyLong_FromLong((long)why)); why = WHY_NOT; JUMPTO(b-&gt;b_handler); break; &#125;&#125; /* unwind stack */ 程序抛出故障，将沿着 tb 链，逐级寻找一个 try-except最终找到一个except，将跳转到 handler，否则直接退出程序，显示栈中压入的错误信息。而这个hander，是跟字节码SETUP_EXCEPT/SETUP_FINALLY`对应的。 12345678910111213141 0 SETUP_EXCEPT 12 (to 14)...3 &gt;&gt; 14 DUP_TOP 16 LOAD_NAME 0 (ZeroDivisionError) 18 COMPARE_OP 10 (exception match) 20 POP_JUMP_IF_FALSE 32 22 POP_TOP 24 POP_TOP 26 POP_TOP4 28 POP_EXCEPT 30 JUMP_FORWARD 2 (to 34) &gt;&gt; 32 END_FINALLY &gt;&gt; 34 LOAD_CONST 2 (None) 36 RETURN_VALUE 在随后的字节码指令中，进行异常比较。若异常匹配，将POP三连，扔掉栈中的异常信息 跳转到正常代码。当异常不匹配时，直接跳转到END_FINALLY。 END_FINALLY123456789101112131415161718192021222324opcode:: END_FINALLY Terminates a :keyword:`finally` clause. The interpreter recalls whether the exception has to be re-raised, or whether the function returns, and continues with the outer-next block.PREDICTED(END_FINALLY);TARGET(END_FINALLY) &#123; PyObject *status = POP(); if (PyLong_Check(status)) &#123; ... // 处理 with 上下文 &#125; else if (PyExceptionClass_Check(status)) &#123; PyObject *exc = POP(); PyObject *tb = POP(); PyErr_Restore(status, exc, tb); why = WHY_EXCEPTION; goto fast_block_end; &#125; else if (status != Py_None) &#123; ... &#125; Py_DECREF(status); DISPATCH();&#125; 异常不匹配，意味着异常并未被成功捕捉，需要再次进行抛出。END_FINALLY就是干这个的。如上，在判断语句中，能够清除的发现，将异常对象从栈中取出，重新放回线程状态对象中。再次设置 why 的状态，Python 虚拟机重新进入异常发生状态。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>try-except</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 控制字节码执行]]></title>
    <url>%2F2018%2F07%2F21%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.7.Python%20%E6%8E%A7%E5%88%B6%E5%AD%97%E8%8A%82%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前言本章将通过几个字节码指令，探究 Python 中if及for语句的实现及原理，阅读本章前需了解PyCodeObject/PyFrameObject。 IF控制流（JUMP_*）123456789101112131415161718192021222324252627282930313233343536373839a = 0if a &gt; 0: b = 3elif a &lt; 0: b = -3else: b = 0c = 1co_consts: (0, 3, 1, None, -3)co_names: (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;) 1 0 LOAD_CONST 0 (0) 2 STORE_NAME 0 (a) 3 4 LOAD_NAME 0 (a) 6 LOAD_CONST 0 (0) 8 COMPARE_OP 4 (&gt;) // 执行比较操作 10 POP_JUMP_IF_FALSE 18 // if POP()== Py_False: JUMPTO(18) 4 12 LOAD_CONST 1 (3) 14 STORE_NAME 1 (b) 16 JUMP_FORWARD 18 (to 36) // JUMPBY(18) 5 &gt;&gt; 18 LOAD_NAME 0 (a) 20 LOAD_CONST 0 (0) 22 COMPARE_OP 0 (&lt;) 24 POP_JUMP_IF_FALSE 32// if POP()== Py_False: JUMPTO(32) 6 26 LOAD_CONST 4 (-3) 28 STORE_NAME 1 (b) 30 JUMP_FORWARD 4 (to 36) 8 &gt;&gt; 32 LOAD_CONST 0 (0) 34 STORE_NAME 1 (b) 9 &gt;&gt; 36 LOAD_CONST 2 (1) 38 STORE_NAME 2 (c) 40 LOAD_CONST 3 (None) 42 RETURN_VALUEtypedef uint16_t _Py_CODEUNIT; // 2字节#define JUMPTO(x) (next_instr = first_instr + (x) / sizeof(_Py_CODEUNIT))#define JUMPBY(x) (next_instr += (x) / sizeof(_Py_CODEUNIT)) 可以看出，比较操作，会调用 COMPARE_OP，然后根据结果进行跳转。而大于符号&gt;，在数组 opcode.h/enum cmp_op{}中，索引为4。 我们知道 first_instr，始终指向字节码开始位置。因此，JUMPTO(18)，最终的结果是，改变下一条 code 指针next_instr的值，实际上就是跳转到索引为 18 的字节码处。JUMPBY(18)相当于在下一条的基础上，跳转偏移量为18。 这里要说一下还是说一下，为什么要(x) / sizeof(_Py_CODEUNIT)。在前面我们也已经提到，STORE_NAME本身是一个数字，而这个数字是_Py_CODEUNIT形式。所以，每增加一条指令，指针就要移动相应的位置。 还需要说明的是，这里的JUMP*皆是 Python 用户层面的跳转，影响的是用户代码逻辑。而goto fast_block_end，是在 Python虚拟机层面的跳转，影响的是虚拟机的状态。 COMPARE_OP12345678910111213141516171819202122232425262728293031323334353637// opcode.henum cmp_op &#123;PyCmp_LT=Py_LT, PyCmp_LE=Py_LE, PyCmp_EQ=Py_EQ, PyCmp_NE=Py_NE, PyCmp_GT=Py_GT, PyCmp_GE=Py_GE, PyCmp_IN, PyCmp_NOT_IN, PyCmp_IS, PyCmp_IS_NOT, PyCmp_EXC_MATCH, PyCmp_BAD&#125;;TARGET(COMPARE_OP) &#123; PyObject *right = POP(); PyObject *left = TOP(); PyObject *res = cmp_outcome(oparg, left, right); Py_DECREF(left); Py_DECREF(right); SET_TOP(res); if (res == NULL) goto error; PREDICT(POP_JUMP_IF_FALSE); PREDICT(POP_JUMP_IF_TRUE); DISPATCH();&#125;static PyObject *cmp_outcome(int op, PyObject *v, PyObject *w)&#123; int res = 0; switch (op) &#123; case PyCmp_IS: res = (v == w); // 注意，此处是 PyObject 之间的比较 break; case PyCmp_IS_NOT: res = (v != w); // 而不是 C对象 break; case PyCmp_IN: ... &#125; v = res ? Py_True : Py_False; Py_INCREF(v); return v;&#125; 从定义中可以看见，in/is 操作也是走 COMPARE_OP 流程。并且返回的是 PyObject。 FOR控制流1234567891011121314151617181920212223242526272829# demo.pya = [1, 2, 3, 4]for i in a: print(i)co_consts: (1, 2, 3, 4, None)co_names: (&apos;a&apos;, &apos;i&apos;, &apos;print&apos;) 1 0 LOAD_CONST 0 (1) 2 LOAD_CONST 1 (2) 4 LOAD_CONST 2 (3) 6 LOAD_CONST 3 (4) 8 BUILD_LIST 4 10 STORE_NAME 0 (a) 2 12 SETUP_LOOP 20 (to 34) 14 LOAD_NAME 0 (a) 16 GET_ITER &gt;&gt; 18 FOR_ITER 12 (to 32) 20 STORE_NAME 1 (i) 3 22 LOAD_NAME 2 (print) 24 LOAD_NAME 1 (i) 26 CALL_FUNCTION 1 28 POP_TOP 30 JUMP_ABSOLUTE 18 &gt;&gt; 32 POP_BLOCK &gt;&gt; 34 LOAD_CONST 4 (None) 36 RETURN_VALUE SETUP_LOOP123456789101112opcode:: SETUP_LOOP (delta) Pushes a block for a loop onto the block stack. The block spans from the current instruction with a size of *delta* bytes.TARGET(SETUP_LOOP) // 三种方式，都走该函数TARGET(SETUP_EXCEPT) // loop/except/finallyTARGET(SETUP_FINALLY) &#123; PyFrame_BlockSetup(f, opcode, INSTR_OFFSET() + oparg, STACK_LEVEL()); DISPATCH();&#125; 下面是很重要的循环控制，关于 FrameObject 的操作，自然在frameobject.c。 PyFrame_BlockSetup123456789101112131415161718192021222324252627voidPyFrame_BlockSetup(PyFrameObject *f, int type, int handler, int level)&#123; PyTryBlock *b; // index in f_blockstack，在 PyFrame_New 中，初始化为 0 if (f-&gt;f_iblock &gt;= CO_MAXBLOCKS) Py_FatalError("XXX block stack overflow"); /* 在 PyFrameObject 结构体中，被定义为 PyTryBlock f_blockstack[CO_MAXBLOCKS] 获取 PyTryBlock，指针 ++ */ b = &amp;f-&gt;f_blockstack[f-&gt;f_iblock++]; /* 定义 code block 块类型 ，直接跟 opcode 一致。 SETUP_* -&gt; loop/except/finally */ b-&gt;b_type = type; // block 类型 b-&gt;b_level = level; // 保存栈位置 b-&gt;b_handler = handler;&#125;#define CO_MAXBLOCKS 20 /* Max static block nesting within a function */typedef struct &#123; int b_type; /* what kind of block this is */ int b_handler; /* where to jump to find handler */ int b_level; /* value stack level to pop to */&#125; PyTryBlock; 这里的 f 自然是，系统运行时的当前 FrameObject。在数组中获取一个新的 block，并存放相关信息。 GET_ITER123456789101112131415 16 GET_ITER &gt;&gt; 18 FOR_ITER 12 (to 32)TARGET(GET_ITER) &#123; /* before: [obj]; after [getiter(obj)] */ PyObject *iterable = TOP(); // 出栈 PyObject *iter = PyObject_GetIter(iterable); Py_DECREF(iterable); SET_TOP(iter); // 入栈 if (iter == NULL) goto error; PREDICT(FOR_ITER); PREDICT(CALL_FUNCTION); DISPATCH();&#125; 如上，先从栈顶获取到对象，处理后再推入栈中。TOS = iter(TOS)。 PyObject_GetIter123456789101112131415161718192021222324252627// object.htypedef PyObject *(*getiterfunc) (PyObject *);// abstract.c.3127PyObject * PyObject_GetIter(PyObject *o)&#123; PyTypeObject *t = o-&gt;ob_type; getiterfunc f = NULL; f = t-&gt;tp_iter; // == list_iter if (f == NULL) &#123; if (PySequence_Check(o)) return PySeqIter_New(o); return type_error("'%.200s' object is not iterable", o); &#125; else &#123; PyObject *res = (*f)(o); if (res != NULL &amp;&amp; !PyIter_Check(res)) &#123; PyErr_Format(PyExc_TypeError, "iter() returned non-iterator " "of type '%.100s'", res-&gt;ob_type-&gt;tp_name); Py_DECREF(res); res = NULL; &#125; return res; &#125;&#125; 这里传入的 object *o，是上一步获取到的 PyListObject，通过获取 ob_type，调用其类型对象定义的tp_iter方法，即 list_iter。 list_iter1234567891011121314151617181920212223static PyObject * list_iter(PyObject *seq)&#123; listiterobject *it; if (!PyList_Check(seq)) &#123; PyErr_BadInternalCall(); return NULL; &#125; it = PyObject_GC_New(listiterobject, &amp;PyListIter_Type); if (it == NULL) return NULL; it-&gt;it_index = 0; Py_INCREF(seq); it-&gt;it_seq = (PyListObject *)seq; // 赋值 _PyObject_GC_TRACK(it); return (PyObject *)it;&#125;typedef struct &#123; PyObject_HEAD Py_ssize_t it_index; PyListObject *it_seq; /* Set to NULL when iterator is exhausted */&#125; listiterobject; 如上，调用 iter 方法，返回的是一个新的对象，即我们常说的迭代器。 FOR_ITER12345678910111213141516171819202122232425262728 &gt;&gt; 18 FOR_ITER 12 (to 32) ... // 执行 print(i) 30 JUMP_ABSOLUTE 18opcode:: FOR_ITER (delta) TOS is an :term:`iterator`. Call its :meth:`~iterator.__next__` method. If this yields a new value, push it on the stack (leaving the iterator below it). If the iterator indicates it is exhausted TOS is popped, and the byte code counter is incremented by *delta*.PREDICTED(FOR_ITER);TARGET(FOR_ITER) &#123; /* before: [iter]; after: [iter, iter()] *or* [] */ PyObject *iter = TOP(); PyObject *next = (*iter-&gt;ob_type-&gt;tp_iternext)(iter); if (next != NULL) &#123; PUSH(next); PREDICT(STORE_FAST); PREDICT(UNPACK_SEQUENCE); DISPATCH(); &#125; STACKADJ(-1); Py_DECREF(iter); JUMPBY(oparg); PREDICT(POP_BLOCK); DISPATCH();&#125; 通过 GET_ITER，将一个栈顶的对象转换成迭代器。再调用 PyTypeObject 的tp_iternext方法，获取 next 值，入栈。最终处理 next==NULL 情况。 当迭代未结束时，仅仅将 next() 值压入了栈中，栈顶依然保持为迭代器。 当迭代结束时，才弹出栈顶迭代器，下一条字节码计数增加，执行相对跳转。 JUMP_ABSOLUTE12345678910 &gt;&gt; 18 FOR_ITER 12 (to 32) 30 JUMP_ABSOLUTE 18#define JUMPTO(x) (next_instr = first_instr + (x) / sizeof(_Py_CODEUNIT))PREDICTED(JUMP_ABSOLUTE);TARGET(JUMP_ABSOLUTE) &#123; JUMPTO(oparg); DISPATCH();&#125; JUMP_ABSOLUTE 18 执行绝对跳转，跳转到字节码计数为18的指令处，继续迭代。 POP_BLOCK（结束循环）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 &gt;&gt; 18 FOR_ITER 12 (to 32) &gt;&gt; 32 POP_BLOCKopcode:: POP_BLOCK Removes one block from the block stack. Per frame, there is a stack of blocks, denoting nested loops, try statements, and such.TARGET(FOR_ITER) &#123; /* before: [iter]; after: [iter, iter()] *or* [] */ PyObject *iter = TOP(); PyObject *next = (*iter-&gt;ob_type-&gt;tp_iternext)(iter); if (next != NULL) &#123; ... &#125; if (PyErr_Occurred()) &#123; if (!PyErr_ExceptionMatches(PyExc_StopIteration)) goto error; else if (tstate-&gt;c_tracefunc != NULL) call_exc_trace(tstate-&gt;c_tracefunc, tstate-&gt;c_traceobj, tstate, f); PyErr_Clear(); &#125; /* iterator ended normally */ STACKADJ(-1); // stack_pointer += n Py_DECREF(iter); JUMPBY(oparg); // (next_instr += (x) / sizeof(_Py_CODEUNIT)) PREDICT(POP_BLOCK); DISPATCH();&#125;PREDICTED(POP_BLOCK);TARGET(POP_BLOCK) &#123; PyTryBlock *b = PyFrame_BlockPop(f); UNWIND_BLOCK(b); DISPATCH();&#125;// frameobject.c.788PyTryBlock * PyFrame_BlockPop(PyFrameObject *f)&#123; PyTryBlock *b; if (f-&gt;f_iblock &lt;= 0) Py_FatalError("XXX block stack underflow"); // 指针 --，返回的是 SETUP_LOOP（PyFrame_BlockSetup) 中获取 TryBlock b = &amp;f-&gt;f_blockstack[--f-&gt;f_iblock]; return b;&#125;#define UNWIND_BLOCK(b) \ while (STACK_LEVEL() &gt; (b)-&gt;b_level) &#123; \ PyObject *v = POP(); \ Py_XDECREF(v); \ &#125; FOR_ITER在调用时，附带有参数 12，下一条为20，JUMPBY 跳转到32，执行POP_BLOCK。从 block 堆栈中删除一个 block，恢复 f_iblock 到循环之前。每个 Frame 都会有一个 block 堆栈，表示嵌套循环、try语句等。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyCodeObject</tag>
        <tag>EvalFrame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】Python 一般字节码执行]]></title>
    <url>%2F2018%2F07%2F21%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.6.Python%20%E4%B8%80%E8%88%AC%E5%AD%97%E8%8A%82%E7%A0%81%2F</url>
    <content type="text"><![CDATA[参考 dis.rst: Disassembler for Python bytecode 前情提要123456789101112_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)&#123; // ceval.c.1144 for (;;) &#123; // ceval.c.1267 switch (opcode) &#123; TARGET(LOAD_FAST) &#123; ... &#125; TARGET(LOAD_CONST) &#123; ... &#125; ... &#125; &#125;&#125; 在前面我们提到，解释器会在 _PyEval_EvalFrameDefault进入for(;;)死循环，不断加载字节码指令，并执行。本章将通过几个常用的字节码指令，来了解 Python 字节码指令执行的逻辑。阅读本章前需了解PyCodeObject/PyFrameObject。 123456789101112# demo.pya = 1&gt;&gt;&gt;co = compile(open('demo.py').read(),'demo.py','exec'); import dis; dis.dis(co) 1 0 LOAD_CONST 0 (1) 2 STORE_NAME 0 (a) 2 4 BUILD_MAP 0 6 STORE_NAME 1 (b) 8 LOAD_CONST 1 (None) 10 RETURN_VALUE 字节码序列： 第一列：字节码对应源码中的行号 第二列：当前字节码指令在 co_code 中的偏移位置 第三列：当前字节码指令 第四列：oparg，指令参数 最后一列：当前字节码指令的参数实际内容 LOAD_CONST123456789101112/* 1 0 LOAD_CONST 0 (1)opcode:: LOAD_CONST (consti) Pushes ``co_consts[consti]`` onto the stack.*/TARGET(LOAD_CONST) &#123; PyObject *value = GETITEM(consts, oparg); // 加载序号为 oparg 的元素 Py_INCREF(value); // 增加引用 PUSH(value); // 入栈 FAST_DISPATCH(); // 继续循环&#125; consts = f-&gt;f_code-&gt;co_consts，即 CodeObject 中的所有常量，一张常量表。LOAD_CONST 完成后，栈顶增加元素 1，栈顶指针下移。 STORE_NAME12345678910111213141516171819202122232425262728/* 2 STORE_NAME 0 (a)opcode:: STORE_NAME (namei) Implements ``name = TOS``. *namei* is the index of *name* in the attribute :attr:`co_names` of the code object.*/TARGET(STORE_NAME) &#123; PyObject *name = GETITEM(names, oparg); // names = f-&gt;co-&gt;co_names; PyObject *v = POP(); // 从运行时栈中获取值 PyObject *ns = f-&gt;f_locals; int err; if (ns == NULL) &#123; PyErr_Format(PyExc_SystemError, "no locals found when storing %R", name); Py_DECREF(v); goto error; &#125; // 将 符号name-值v 的映射关系存储到 locals 中 if (PyDict_CheckExact(ns)) err = PyDict_SetItem(ns, name, v); else err = PyObject_SetItem(ns, name, v); Py_DECREF(v); if (err != 0) goto error; DISPATCH();&#125; 注意到，上一步刚进行了压栈操作，第二步就进行了出栈。然后从 co_names中获取第0个元素，作为字典的k-v，映射到 locals 中。此时，栈空，f_locals 指针依然指向开始位置。 BUILD_MAP/BUILD_LIST123456789101112131415opcode:: BUILD_MAP (count) Pushes a new dictionary object onto the stack. Pops ``2 * count`` items so that the dictionary holds *count* entries: ``&#123;..., TOS3: TOS2, TOS1: TOS&#125;``. .. versionchanged:: 3.5 The dictionary is created from stack items instead of creating an empty dictionary pre-sized to hold *count* items.opcode:: BUILD_TUPLE (count) Creates a tuple consuming *count* items from the stack, and pushes the resulting tuple onto the stack.opcode:: BUILD_LIST (count) Works as :opcode:`BUILD_TUPLE`, but creates a list. 123456789101112131415161718192021222324252627282930313233343536373839404142434445#define PEEK(n) (stack_pointer[-(n)])TARGET(BUILD_MAP) &#123; Py_ssize_t i; PyObject *map = _PyDict_NewPresized((Py_ssize_t)oparg); if (map == NULL) goto error; for (i = oparg; i &gt; 0; i--) &#123; int err; PyObject *key = PEEK(2*i); // 偶数 PyObject *value = PEEK(2*i - 1); // 奇数 err = PyDict_SetItem(map, key, value); if (err != 0) &#123; Py_DECREF(map); goto error; &#125; &#125; while (oparg--) &#123; // 这里挺有趣，每次都 POP 两个 Py_DECREF(POP()); Py_DECREF(POP()); /* 从上面的偶数，奇数，也不难猜出。 字典 k-v 都是通过 LOAD_CONST，压入了栈中 比较奇特的是：d = &#123;"X": "Z", 'a': 'b'&#125;，结果是 key 在一起 &gt;&gt;&gt; co.co_consts == ('Z', 'b', ('X', 'a'), None) 字节码对应 BUILD_CONST_KEY_MAP */ &#125; PUSH(map); DISPATCH();&#125;TARGET(BUILD_LIST) &#123; PyObject *list = PyList_New(oparg); if (list == NULL) goto error; while (--oparg &gt;= 0) &#123; // 同样，列表中的值，也是在栈中，依此读取 PyObject *item = POP(); PyList_SET_ITEM(list, oparg, item); &#125; PUSH(list); DISPATCH();&#125; RETURN_VALUE12345678 8 LOAD_CONST 1 (None) 10 RETURN_VALUETARGET(RETURN_VALUE) &#123; retval = POP(); why = WHY_RETURN; // 0x0008, /* 'return' statement */ goto fast_block_end;&#125; 最后，临走前将返回值 None 压入栈中，然后在 POP 出来，break 掉死循环。 BINARY_ADD1234a = 1 + 3co_consts: (1, 3, None, 4)co_names: (&apos;a&apos;,) 这种，在编译时直接就计算了结果。 123456789101112131415a = 1b = 2c = 3d = a + b * (c + c)BINARY_ADD：TOS = TOS1 + TOS 4 12 LOAD_NAME 0 (a) 14 LOAD_NAME 1 (b) 16 LOAD_NAME 2 (c) 18 LOAD_NAME 2 (c) 20 BINARY_ADD 22 BINARY_MULTIPLY 24 BINARY_ADD 26 STORE_NAME 3 (d) 这种，就是正常的，先调用LOAD_NAME在调用BINARY_ADD。而且，比较重要的是，只能每次两个两个相加，并且自左向右结合，优先级在编译时考虑。 LOAD_NAME1234567891011121314151617181920212223// names = f-&gt;co-&gt;co_names，可见是从 符号表中加载TARGET(LOAD_NAME) &#123; PyObject *name = GETITEM(names, oparg); PyObject *locals = f-&gt;f_locals; PyObject *v; v = PyObject_GetItem(locals, name); if (v == NULL) &#123; v = PyDict_GetItem(f-&gt;f_globals, name); Py_XINCREF(v); if (v == NULL) &#123; v = PyDict_GetItem(f-&gt;f_builtins, name); if (v == NULL) &#123; goto error; &#125; Py_INCREF(v); &#125; &#125; PUSH(v); DISPATCH();&#125; 精简代码如上，很好理解，从 locals -&gt; globals -&gt; builtins，找到了，就压栈，找不到就报错。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyCodeObject</tag>
        <tag>EvalFrame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyCodeObject/PyFrameObject]]></title>
    <url>%2F2018%2F07%2F21%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.5.Python%20Code%20Frame%2F</url>
    <content type="text"><![CDATA[参考 PEP3147 PYC Repository Directories 前言事实上，Python虽然是解释型语言，但也需要经过 源文件 -&gt; 编译 -&gt; 可执行文件 -&gt; 执行整个过程。12345javac Example.java -&gt; Example.classjava Example.class -&gt; 输出python Example.py -&gt; 创建或加载 PyCodeObject -&gt; 输出保存PyCodeObject到 -&gt; Example.pyc 如上，编译器在编译产生 code 后由虚拟机执行。Python 与 Java 不同之处在于 Python 的虚拟机是一种抽象层次更高的虚拟机。 在 编译结束后，Python 会将 code 对象所包含的的信息存储在 pyc 文件内，下次运行直接加载 pyc 里的 code 对象到内存。 Python 解释器(interpreter)，同时拥有编译器和虚拟机的身份。具体流程参见PyCodeObject 包含 Python 虚拟机所需要的信息，而 pyc 就是其在硬盘实体化后的载体。 PyCodeObjectPyCodeObject，同样是 Python 对象，也继承 PyObject_HEAD。对于 Python 源代码中的任一 Code Block 都会创建一个 CodeObject 与之对应。一个新的命名空间，是一个 Code Block。类、函数、module都对应一个新的命名空间。 12345678910111213141516171819202122232425262728293031typedef struct &#123; PyObject_HEAD int co_argcount; /* 位置参数 *args 个数 */ int co_kwonlyargcount; /* #keyword only arguments */ int co_nlocals; /* 局部变量个数，包含位置参数 */ int co_stacksize; /* 需要的栈空间 */ int co_flags; /* 对block进行划分，详见 inspect.rst */ int co_firstlineno; /* 对应 .py 的起始行 */ PyObject *co_code; /* 字节码序列，PyStringObject 形式 */ PyObject *co_consts; /* list (所有常量) */ PyObject *co_names; /* list of strings (所有符号) */ PyObject *co_varnames; /* tuple of strings (局部变量名) */ PyObject *co_freevars; /* tuple of strings 使用了外层作用域中的变量名 */ PyObject *co_cellvars; /* tuple of strings 嵌套函数中使用了的变量名 */ /* 除了 co_name，余下都不用于 hash 或 比较。 为了回溯和debug，保留行号和名字。 否则，会不断的 覆盖已有的同名 func/lambda */ unsigned char *co_cell2arg; /* Maps cell vars which are arguments. */ PyObject *co_filename; /* unicode (.py 文件名) */ PyObject *co_name; /* unicode (函数名/类名/模块名) */ PyObject *co_lnotab; /* string (encoding addr&lt;-&gt;lineno mapping 字节码指令与 .py 行号的对应关系) */ void *co_zombieframe; /* for optimization only (see frameobject.c) */ PyObject *co_weakreflist; /* to support weakrefs to code objects */ /* Scratch space for extra data relating to the code object. */ void *co_extra;&#125; PyCodeObject; 需要注意的是，co_lnotab 记录行号，在实际中是记录增量值。 生成1234567891011121314151617&gt;&gt;&gt; src = open('demo.py').read()&gt;&gt;&gt; co = compile(src,'demo.py','exec')&gt;&gt;&gt; co&lt;code object &lt;module&gt; at 0x000002942853DD20, file "demo.py", line 1&gt;&gt;&gt;&gt; type(co)&lt;class 'code'&gt;&gt;&gt;&gt; co.co_consts(&lt;code object A , file "demo.py", line 1&gt;, 'A', &lt;code object fun, file "demo.py", line 5&gt;, 'fun', None)&gt;&gt;&gt; cls_A = co.co_consts[0]&gt;&gt;&gt; type(cls_A)&lt;class 'code'&gt;&gt;&gt;&gt; co.co_names('A', 'fun', 'a')&gt;&gt;&gt; co.co_filename'demo.py'&gt;&gt;&gt; cls_A.co_filename'demo.py' 可见，PyObjectObject 通过 co_consts 字段，实现了嵌套。 字节码123456// opcode.h#define POP_TOP 1#define ROT_TWO 2 ...#define HAVE_ARGUMENT 90#define HAS_ARG(op) ((op) &gt;= HAVE_ARGUMENT) opcode.h中定义了所有的字节码指令，判断是否需要参数是根据HAVE_ARGUMENT宏来简单判断 1234567891011&gt;&gt;&gt; cls_A&lt;code object A , file "demo.py", line 1&gt;&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis(cls_A) 1 0 LOAD_NAME 0 (__name__) 2 STORE_NAME 1 (__module__) 4 LOAD_CONST 0 ('A') 6 STORE_NAME 2 (__qualname__) 2 8 LOAD_CONST 1 (None) 10 RETURN_VALUE dis 工具能很好的解析字节码： 第一列：字节码对应源码中的行号 第二列：当前字节码指令在 co_code 中的偏移位置 第三列：当前字节码指令 第四列：oparg，指令参数 最后一列：当前字节码指令的参数实际内容 栈帧 Python 解释器，本身拥有一套运行时的栈帧。但要执行源代码中的函数调用，却不是通过系统栈帧实现。在前文介绍 PyObject 时也发现，所有的 Object 都是存储在堆中。PyCodeObject 包含了运行时需要的信息，而其本身也存储在堆中。 因此，Python 在初始化后，会创建一个执行环境。发生函数调用时，会再次创建一个执行环境，并加载新的 PyCodeObject。这个执行环境，就是 PyFrameObject。关于函数调用的内容，会在 Pythn函数机制 中讲到。 12345678910111213141516171819202122/* Stack frames 快速的创建和释放，下面是一些加速手段： 1. Hold a single "zombie" frame on each code object. In zombie mode, 不持有 对象引用，但以下字段依然有效： * ob_type, ob_size, f_code, f_valuestack; * f_locals, f_trace, f_exc_type, f_exc_value, f_exc_traceback are NULL; * f_localsplus does not require re-allocation and the local variables in f_localsplus are NULL. 2. 共享池技术 free list，池中的 FrameObject，只有以下字段有效： ob_type == &amp;Frametype f_back next item on free list, or NULL f_stacksize size of value stack ob_size size of localsplus Note that the value and block stacks are preserved. 不同于整数对象池，此处的 frame object 是具有内存空间的。 PyFrame_MAXFREELIST(200) 限制了最大 free_list 数目*/ 共享池真是无处不在… PyFrameObject12345678910111213141516171819202122232425262728293031323334// frameobject.h.11typedef struct &#123; int b_type; /* what kind of block this is */ int b_handler; /* where to jump to find handler */ int b_level; /* value stack level to pop to */&#125; PyTryBlock;typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* PyCodeObject 对象 */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* 运行时栈 栈底 */ PyObject **f_stacktop; /* 运行时栈 栈顶 */ PyObject *f_trace; /* Trace function */ /* 用于 generator 交换错误信息 */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; /* Borrowed reference to a generator, or NULL */ PyObject *f_gen; int f_lasti; /* 上一条字节码指令在 f_code 中的偏移位置 */ int f_lineno; /* 当前字节码，对应源代码行号 通过 PyFrame_GetLineNumber() 调用*/ int f_iblock; /* index in f_blockstack */ char f_executing; /* whether the frame is still executing */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* block 堆栈 */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; f_back 表明 FrameObject 被组成链式结构，可以回溯，形成类似栈帧一样的结构。 PyFrame_New123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384PyFrameObject *PyFrame_New(PyThreadState *tstate, PyCodeObject *code, PyObject *globals, PyObject *locals)&#123; PyFrameObject *back = tstate-&gt;frame; PyFrameObject *f; PyObject *builtins; Py_ssize_t i; // 存在函数调用 if (back == NULL || back-&gt;f_globals != globals) &#123; // 获取 builtins （略） &#125; else &#123; /* share the globals、 builtins. Save a lookup and a call. */ builtins = back-&gt;f_builtins; assert(builtins != NULL); Py_INCREF(builtins); &#125; // 尝试利用 zombieframe if (code-&gt;co_zombieframe != NULL) &#123; f = code-&gt;co_zombieframe; code-&gt;co_zombieframe = NULL; _Py_NewReference((PyObject *)f); assert(f-&gt;f_code == code); &#125; else &#123; Py_ssize_t extras, ncells, nfrees; ncells = PyTuple_GET_SIZE(code-&gt;co_cellvars); // 闭包：嵌套函数，使用了的变量 nfrees = PyTuple_GET_SIZE(code-&gt;co_freevars); // 使用了的外部作用域变量。 // Frame 所需动态内存大小 extras = code-&gt;co_stacksize + \ // 运行，栈空间（系统级） code-&gt;co_nlocals + \ // 局部变量个数 ncells + \ nfrees; if (free_list == NULL) &#123; f = PyObject_GC_NewVar(PyFrameObject, &amp;PyFrame_Type, extras); &#125; else &#123; assert(numfree &gt; 0); // 熟悉的套路， 链表，而不是数组 --numfree; f = free_list; free_list = free_list-&gt;f_back; if (Py_SIZE(f) &lt; extras) &#123; // 触发 resize 调整大小 PyFrameObject *new_f = PyObject_GC_Resize(PyFrameObject, f, extras); f = new_f; &#125; _Py_NewReference((PyObject *)f); &#125; // 封装属性 f-&gt;f_code = code; // 此处，计算初始化时的栈顶 extras = code-&gt;co_nlocals + ncells + nfrees; f-&gt;f_valuestack = f-&gt;f_localsplus + extras; // 栈底 for (i=0; i&lt;extras; i++) f-&gt;f_localsplus[i] = NULL; f-&gt;f_locals = NULL; f-&gt;f_trace = NULL; f-&gt;f_exc_type = f-&gt;f_exc_value = f-&gt;f_exc_traceback = NULL; &#125; //封装属性 f-&gt;f_stacktop = f-&gt;f_valuestack; // 初始化的 Frame，栈顶==栈底 f-&gt;f_builtins = builtins; Py_XINCREF(back); f-&gt;f_back = back; Py_INCREF(code); Py_INCREF(globals); f-&gt;f_globals = globals; // 处理 f-&gt;f_locals (略) f-&gt;f_lasti = -1; f-&gt;f_lineno = code-&gt;co_firstlineno; f-&gt;f_iblock = 0; f-&gt;f_executing = 0; f-&gt;f_gen = NULL; _PyObject_GC_TRACK(f); return f;&#125; 创建 FrameObject 时，多创建了一部分作为运行时的栈空间。具体参考代码和下图： 获取FrameObject1234567891011121314151617# import sys; sys._getframe()import inspectdef f(): frame = inspect.currentframe() print(f"Current fun: &#123;frame.f_code.co_name&#125;") caller = frame.f_back print(f"Caller fun: &#123;caller.f_code.co_name&#125;") print(f"Caller's local: &#123;caller.f_locals&#125;") print(f"Caller's global: &#123;caller.f_globals.keys()&#125;")def c(): l = 1 m = 2 f()def show(): c() 结果显示，在被调用者中，完全可以通过 frame 链，获取到调用者的相关信息：123456show()Current fun: fCaller fun: cCaller fun: cCaller&apos;s local: &#123;&apos;m&apos;: 2, &apos;l&apos;: 1&#125;Caller&apos;s global: dict_keys([..., &apos;inspect&apos;, &apos;f&apos;, &apos;c&apos;, &apos;show&apos;]) 作用域Python 具有静态作用域，支持嵌套作用域，名字访问时按照LEGB规则访问属性。 Python 自身定义了一个 builtin 作用域，module 对应一个全局作用域 global，函数对应 local 作用域。这三个组成了LGB顺序查找模式。E 为 encloseing 的缩写，代表直接外围作用域，适用于函数闭包。 用名字访问时，用户代码的终点是 module，而 module 是在 import 编译完成时就已经确定了，所以永远不可能访问到其他 module 的相同名字，不会越界。 因为最内嵌套作用域的原因，决定 Python 行为的更多是代码出现的位置，而非执行的时间。 PyEval_EvalFrameEx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// ceval.c.750PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)&#123; PyThreadState *tstate = PyThreadState_GET(); return tstate-&gt;interp-&gt;eval_frame(f, throwflag);&#125;// pystate.c.70PyInterpreterState * PyInterpreterState_New(void)&#123; ... interp-&gt;eval_frame = _PyEval_EvalFrameDefault; ...&#125;// ceval.c.757PyObject *_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)&#123; int opcode; /* Current opcode */ int oparg; /* Current opcode argument, if any */ enum why_code why; /* Reason for block stack unwind */ PyThreadState *tstate = PyThreadState_GET(); ... tstate-&gt;frame = f; // 设置线程状态中的栈帧对象 co = f-&gt;f_code; names = co-&gt;co_names; consts = co-&gt;co_consts; fastlocals = f-&gt;f_localsplus; freevars = f-&gt;f_localsplus + co-&gt;co_nlocals; first_instr = (_Py_CODEUNIT *) PyBytes_AS_STRING(co-&gt;co_code); next_instr = first_instr; stack_pointer = f-&gt;f_stacktop; f-&gt;f_stacktop = NULL; /* remains NULL unless yield suspends frame */ ... // ceval.c.1144 for (;;) &#123; // ceval.c.1267 switch (opcode) &#123; TARGET(LOAD_FAST) &#123; ... &#125; TARGET(LOAD_CONST) &#123; ... &#125; ... &#125; &#125;&#125; PEP 523中引入了 _PyEval_EvalFrameDefault，具体的逻辑都在其中。在 for 循环中，不断遍历字节码序列，然后 switch 执行。遍历过程中： first_instr，始终指向字节码开始位置 next_inster，始终指向下一条待执行的位置（因参数影响，位置不固定） frame.f_lasti，始终指向已经执行的上一条的位置 通过判断 why/why_not 字段，决定循环的状态。12345678910/* Status code for main loop (reason for stack unwind) */enum why_code &#123; WHY_NOT = 0x0001, /* No error */ WHY_EXCEPTION = 0x0002, /* Exception occurred */ WHY_RETURN = 0x0008, /* 'return' statement */ WHY_BREAK = 0x0010, /* 'break' statement */ WHY_CONTINUE = 0x0020, /* 'continue' statement */ WHY_YIELD = 0x0040, /* 'yield' operator */ WHY_SILENCED = 0x0080 /* Exception silenced by 'with' */&#125;; Code 与 FrameCodeObject： 每个命令空间都对应一个，可以嵌套 存储着实际的变量值，变量名等等 FrameObject: 通过属性 f_code，跟 CodeObject 进行关联 维护这运行时的栈帧，f_lineno 等信息 先有鸡还是先有蛋？Python 环境初始化之后，通过run_file(fp, filename, &amp;cf)，进入到用户代码执行阶段。通过run_file调用链可以看出，最终运行的是_PyEval_EvalCodeWithName。123456789// ceval.cstatic PyObject *_PyEval_EvalCodeWithName() &#123; ... f = PyFrame_New(tstate, co, globals, locals); retval = PyEval_EvalFrameEx(f,0); ... return retval;&#125; 很明显，先有 CodeObject，再有 FrameObject。在EvalFrame中，又会取出 f_code，执行用户代码。 12345static PyObject*_PyFunction_FastCall() &#123; f = PyFrame_New(tstate, co, globals, NULL); result = PyEval_EvalFrameEx(f,0);&#125; 在用户代码中，出现过程调用时，同样会再次创建 Frame。谁让 Frame 是维护的 Python 栈帧环境呢~ 其实回想一下，CodeObject 是在编译阶段就已经创建，此时根本没有运行环境之说，肯定是先有鸡！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyCodeObject</tag>
        <tag>PyFrameObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyDictObject]]></title>
    <url>%2F2018%2F07%2F15%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.4.Python%E5%AD%97%E5%85%B8%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[参考 Dictionary Objects PEP412 Key-Sharing Dictionary 前言Python官网把 PyDictObject 归类与 Concrete Objects Layer，享受同样待遇的还有PySetObject。在前面 PythonUnicodeObject 中，我们已经见到了 PythonDict 的运用，即共享机制 interned。在 Python 世界里，字典被用于建立字节码的运行环境，用来存放变量名和变量值，意味着做任何操作几乎都要设计到 PythonDict， 因此，对搜索的效率要求及其苛刻。因而采用的 HashTable(散列表)，在最优情况下能达到O(1)。散列表的基本思想是，将键映射为一个整数，把整数作为索引访问内存。主要逻辑是：查询键值 ——散列函数 hash function —— 散列值 hash value —— 内存区域 —— 查询结果——散列冲突。Python 处理散列冲突的问题，采用的是 开放定址法。删除探测链上元素，采用的是伪删除。 因为字典的重要性，Python 甚至单独在Objects/dictnotes.txt中写入了关于字典的说明，下面仅挑选部分内容：123456789101112131415161718192021222324252627281. 主要应用 1. 传递关键字参数（1~3个元素） 2. 类方法查找： 1. 通常包含 8~16 个元素。 2. 通常只写入一次，但多次查找 3. 当使用基类时，会频繁在基类中查找 3. 实例属性查找、全局变量查找 1. 通常包含 4~10 个元素。 2. 写入和读取都非常频繁 4. Builtins（内置命令） 1. 频繁的读取，几乎不写入 2. About 150 interned strings (as of Py3.3). 3. 其中一切访问频率远大于其他2. 数据存储 由3部分组成： 1. dictobject 自身 2. A dict-keys object (keys &amp; hashes) 3. A values array仅涉及单个键的字典操作可以是O（1），除非涉及到调整大小。现在的版本与之前的差别： 1. key value 可以分开存储 2. 分离表中 key-val 新增组合 (key, NULL)，代表被删除 3. key-val表中，不能嵌套小表 4. 一般字典比以前略大 5. 单个类的所有对象，共享key表，节约大量内存 PyDict_Type12345678910111213141516// dictobject.c.3282PyTypeObject PyDict_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "dict", sizeof(PyDictObject), (destructor)dict_dealloc, /* tp_dealloc */ &amp;dict_as_sequence, /* tp_as_sequence */ &amp;dict_as_mapping, /* tp_as_mapping */ PyObject_HashNotImplemented, /* tp_hash */ (getiterfunc)dict_iter, /* tp_iter */ mapp_methods, /* tp_methods */ dict_init, /* tp_init */ PyType_GenericAlloc, /* tp_alloc */ dict_new, /* tp_new */ PyObject_GC_Del, /* tp_free */&#125;; PyDictObject1234567891011121314151617181920212223// dictobject.h.18typedef struct _dictkeysobject PyDictKeysObject;typedef struct &#123; PyObject_HEAD /* Number of items in the dictionary */ Py_ssize_t ma_used; /* Dictionary version: globally unique, value change each time the dictionary is modified */ uint64_t ma_version_tag; PyDictKeysObject *ma_keys; /* If ma_values is NULL, the table is "combined": keys and values are stored in ma_keys. If ma_values is not NULL, the table is splitted: keys are stored in ma_keys and values are stored in ma_values */ PyObject **ma_values;&#125; PyDictObject; 如上，不同于之前的 PyListObject/PyUnicodeObject，他们被归类于 Sequence Object。而PyDictObject 归类于 Concrete Objects。因此，直接定义为 PyObject_HEAD。其他字段含义，见注释。 既然是分离设计，那么必然存在两个储存表的地方，一个是 ma_keys，一个是ma_values。具体内容见下文注释。1234567891011The DictObject can be in one of two forms.A combined table: ma_values == NULL, dk_refcnt == 1. Values are stored in the me_value field of the PyDictKeysObject.A split table: ma_values != NULL, dk_refcnt &gt;= 1 Values are stored in the ma_values array. Only string (unicode) keys are allowed. All dicts sharing same key must have same insertion order. PyDictKeysObject1234567891011121314// dict-common.h/23struct _dictkeysobject &#123; Py_ssize_t dk_refcnt; Py_ssize_t dk_size; dict_lookup_func dk_lookup; Py_ssize_t dk_usable; Py_ssize_t dk_nentries; union &#123; int8_t as_1[8]; int16_t as_2[4]; int32_t as_4[2]; int64_t as_8[1]; &#125; dk_indices;&#125;; PyDictKeysObject 实现了字典的 hash table，布局如下: layout1234567891011121314151617181920212223+---------------+| dk_refcnt || dk_size | /* Size of the hash table.| | It must be a power of 2. */| dk_lookup | /* Function to lookup in the hash table. */| dk_usable | /* Number of usable entries in dk_entries. */| dk_nentries | /* Number of used entries in dk_entries. */+---------------+| dk_indices | // Actual hash table of dk_size entries.| |+---------------+| dk_entries | /* array of PyDictKeyEntry.| | len(dk_entries) == USABLE_FRACTION(dk_size) */+---------------+The size in bytes of an indice depends on dk_size:- 1 byte if dk_size &lt;= 0xff (char*)- 2 bytes if dk_size &lt;= 0xffff (int16_t*)- 4 bytes if dk_size &lt;= 0xffffffff (int32_t*)- 8 bytes otherwise (int64_t*)Dynamically sized, 8 is minimum. 需要注意的是，dk_indices 是一个共用体，会根据 dk_size 的值，决定存储 index 的类型。 PyDictKeyEntry1234567891011// dict-common.h.17#define DKIX_EMPTY (-1)#define DKIX_DUMMY (-2) /* Used internally */#define DKIX_ERROR (-3)// dict-common.h.4typedef struct &#123; Py_hash_t me_hash; /* Cached hash code of me_key. */ PyObject *me_key; PyObject *me_value; /* only meaningful for combined tables */&#125; PyDictKeyEntry; dk_entries中存储的是 PyDictKeyEntry对象，其中每个元素都可以称为一个 enrty。因为使用了负数作为 entry 的状态，因此dk_indices中存储的是有符号整数。可以通过 宏 DK_ENTRIES 访问 entry：1234567891011// dictobject.c.289#define DK_SIZE(dk) ((dk)-&gt;dk_size)#define DK_IXSIZE(dk) \ (DK_SIZE(dk) &lt;= 0xff ? \ 1 : DK_SIZE(dk) &lt;= 0xffff ? \ 2 : DK_SIZE(dk) &lt;= 0xffffffff ? \ 4 : sizeof(int64_t))#define DK_ENTRIES(dk) \ ((PyDictKeyEntry*)(&amp;(dk)-&gt;dk_indices.as_1[DK_SIZE(dk) * DK_IXSIZE(dk)])) dk_indicesdk_indices 即是真正的 hash table，对应一个 slot 数组，每个slot 有四种状态1234567891011121314151617181920// dictobject.c.641. Unused. index == DKIX_EMPTY This is each slot's initial state. Does not hold an active (key, value) pair now and never did. Unused can transition to Active upon key insertion.2. Active. index &gt;= 0, me_key != NULL and me_value != NULL Holds an active (key, value) pair. This is the only case in which me_value != NULL. Active can transition to Dummy or Pending upon key deletion~~~~ (for combined and split tables respectively).3. Dummy. index == DKIX_DUMMY (combined only) Previously held an active (key, value) pair, but that was deleted and an active pair has not yet overwritten the slot. Dummy can transition to Active upon key insertion. Dummy slots cannot be made Unused again.4. Pending. index &gt;= 0, key != NULL, and value == NULL (split only) Not yet inserted in split-table. 简单来说就是 Unused，初始状态，该 slot 没有被使用，index = -1 Active，正在使用，index &gt; 0 Dummy，曾经使用过，但现在被删除了，index = -2 。(仅限 combined-table) Pending，还未插入。(仅限 split-table)正因为 Dummy 态不能转换为 Unused，所以保证了探测链的连续性，对应前文说的 伪删除。 创建12345678910#define PyDict_MINSIZE 8// dictobject.c.620PyObject * PyDict_New(void)&#123; PyDictKeysObject *keys = new_keys_object(PyDict_MINSIZE); if (keys == NULL) return NULL; return new_dict(keys, NULL);&#125; PyDict_MINSIZE 是任何新 Dict 的起始大小，默认为8，满足运行过程中大量的函数参数传递过程。 new_keys_object12345678910111213141516171819202122232425262728293031323334353637383940414243// dictobject.c.374#define USABLE_FRACTION(n) (((n) &lt;&lt; 1)/3)static PyDictKeysObject *new_keys_object(Py_ssize_t size)&#123; PyDictKeysObject *dk; Py_ssize_t es, usable; // dk_size &gt;= 8 and must be a power of 2. assert(size &gt;= PyDict_MINSIZE); assert(IS_POWER_OF_2(size)); // len(dk_entries) == USABLE_FRACTION(dk_size)，最小为5 usable = USABLE_FRACTION(size); ... // es = 1/2/3/4; 根据 size 大小，确定存储位数 // 尝试共享 if (size == PyDict_MINSIZE &amp;&amp; numfreekeys &gt; 0) &#123; dk = keys_free_list[--numfreekeys]; &#125; else &#123; dk = PyObject_MALLOC(sizeof(PyDictKeysObject) - Py_MEMBER_SIZE(PyDictKeysObject, dk_indices) + es * size + sizeof(PyDictKeyEntry) * usable); if (dk == NULL) &#123; PyErr_NoMemory(); return NULL; &#125; &#125; DK_DEBUG_INCREF dk-&gt;dk_refcnt = 1; dk-&gt;dk_size = size; dk-&gt;dk_usable = usable; dk-&gt;dk_lookup = lookdict_unicode_nodummy; dk-&gt;dk_nentries = 0; // 初始化 dk_indices == -1 memset(&amp;dk-&gt;dk_indices.as_1[0], 0xff, es * size); // 初始化 dk_entries == 0 memset(DK_ENTRIES(dk), 0, sizeof(PyDictKeyEntry) * usable); return dk;&#125; 从代码中也清晰的看见，对象缓冲池 keys_free_list 的身影。其中需要注意的是： 1usable = USABLE_FRACTION(size); // (((n) &lt;&lt; 1)/3) size 默认为 PyDict_MINSIZE 即8。通过计算可以得出默认存放5个对象。 new_dict1234567891011121314151617181920212223242526// dictobject.c.573static PyObject *new_dict(PyDictKeysObject *keys, PyObject **values)&#123; PyDictObject *mp; // 尝试共享 if (numfree) &#123; mp = free_list[--numfree]; _Py_NewReference((PyObject *)mp); &#125; else &#123; mp = PyObject_GC_New(PyDictObject, &amp;PyDict_Type); if (mp == NULL) &#123; DK_DECREF(keys); free_values(values); return NULL; &#125; &#125; mp-&gt;ma_keys = keys; mp-&gt;ma_values = values; mp-&gt;ma_used = 0; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); return (PyObject *)mp;&#125; 代码不长，很好懂。再次发现了对象池 free_list。 共享机制前面 创建 PyDictObject 和 PyDictKeysObject 时，都利用了对象缓冲池。12345#define PyDict_MAXFREELIST 80static PyDictObject *free_list[PyDict_MAXFREELIST];static int numfree = 0;static PyDictKeysObject *keys_free_list[PyDict_MAXFREELIST];static int numfreekeys = 0; 宏定义如上，与 PyListObject 类似，甚至连名字都类似。那么必然的，销毁对象时，会把对象放入缓冲池。 dict_dealloc1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static PyObject *empty_values[1] = &#123; NULL &#125;;// dictobject.c.2003static void dict_dealloc(PyDictObject *mp)&#123; PyObject **values = mp-&gt;ma_values; PyDictKeysObject *keys = mp-&gt;ma_keys; Py_ssize_t i, n; /* bpo-31095: UnTrack is needed before calling any callbacks */ PyObject_GC_UnTrack(mp); Py_TRASHCAN_SAFE_BEGIN(mp) if (values != NULL) &#123; if (values != empty_values) &#123; for (i = 0, n = mp-&gt;ma_keys-&gt;dk_nentries; i &lt; n; i++) &#123; Py_XDECREF(values[i]); &#125; free_values(values); &#125; DK_DECREF(keys); &#125; else if (keys != NULL) &#123; assert(keys-&gt;dk_refcnt == 1); DK_DECREF(keys); &#125; // 尝试共享 if (numfree &lt; PyDict_MAXFREELIST &amp;&amp; Py_TYPE(mp) == &amp;PyDict_Type) free_list[numfree++] = mp; else Py_TYPE(mp)-&gt;tp_free((PyObject *)mp); Py_TRASHCAN_SAFE_END(mp)&#125;// dictobject.c.554static void free_keys_object(PyDictKeysObject *keys)&#123; PyDictKeyEntry *entries = DK_ENTRIES(keys); Py_ssize_t i, n; for (i = 0, n = keys-&gt;dk_nentries; i &lt; n; i++) &#123; Py_XDECREF(entries[i].me_key); Py_XDECREF(entries[i].me_value); &#125; // 尝试共享 if (keys-&gt;dk_size == PyDict_MINSIZE &amp;&amp; numfreekeys &lt; PyDict_MAXFREELIST) &#123; keys_free_list[numfreekeys++] = keys; return; &#125; PyObject_FREE(keys);&#125; CRUDMapping方法簇12345678910static PyMappingMethods dict_as_mapping = &#123; (lenfunc)dict_length, /*mp_length*/ (binaryfunc)dict_subscript, /*mp_subscript*/ (objobjargproc)dict_ass_sub, /*mp_ass_subscript*/&#125;;static Py_ssize_t dict_length(PyDictObject *mp)&#123; return mp-&gt;ma_used;&#125; PyDict_Type 中定义的 tp_as_mapping == &amp;dict_as_mapping。从代码中可以看见len(dict)时间复杂度为O(1)。执行 dict[item] 即调用 dict_subscript()。 GetItem12345678910111213141516171819202122232425262728293031323334353637383940414243// dictobject.c.2172static PyObject * dict_subscript(PyDictObject *mp, PyObject *key)&#123; PyObject *v; Py_ssize_t ix; Py_hash_t hash; PyObject **value_addr; // 1. 获取/计算 hash 值 if (!PyUnicode_CheckExact(key) || (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) &#123; hash = PyObject_Hash(key); if (hash == -1) return NULL; &#125; // 2. 查找 index ，返回 ix&gt;0 或 ix == -1 / -3 ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;value_addr, NULL); if (ix == DKIX_ERROR) // -3 return NULL; // 3. 根据 ix 结果值，执行 __miss__ 或 返回结果 if (ix == DKIX_EMPTY || *value_addr == NULL) &#123; if (!PyDict_CheckExact(mp)) &#123; /* Look up __missing__ method if we're a subclass. */ PyObject *missing, *res; _Py_IDENTIFIER(__missing__); missing = _PyObject_LookupSpecial((PyObject *)mp, &amp;PyId___missing__); if (missing != NULL) &#123; res = PyObject_CallFunctionObjArgs(missing, key, NULL); Py_DECREF(missing); return res; &#125; else if (PyErr_Occurred()) return NULL; &#125; _PyErr_SetKeyError(key); return NULL; &#125; v = *value_addr; Py_INCREF(v); return v;&#125; 源码如上，需要注意的的是，返回的是 对象引用。并且，时间复杂度为O(1)。 ix 获取方式 mp-&gt;ma_keys-&gt;dk_lookup，即调用 PyDictObject 自身的 dk_lookup，在前面的 PyDict_New 中，可以发现 dk-&gt;dk_lookup = lookdict_unicode_nodummy。实际上，dk_lookup 存在不止一种。 dk_lookup123456789101112131415161718192021222324252627// ictobject.c.224/* lookdict() is general-purpose, and may return DKIX_ERROR if (and only if) a comparison raises an exception. */static Py_ssize_t lookdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos);/* Specialized version for string-only keys */static Py_ssize_t lookdict_unicode(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos);/* Faster version of lookdict_unicode when it is known that no &lt;dummy&gt; keys * will be present. */static Py_ssize_tlookdict_unicode_nodummy(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos);/* Version of lookdict for split tables. * All split tables and only split tables use this lookup function. * Split tables only contain unicode keys and no dummy keys, * so algorithm is the same as lookdict_unicode_nodummy. */static Py_ssize_t lookdict_split(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos); 如上，dk_lookup 有4个非常相似的 查找函数。因为在 Python 中，大量使用 str 作为字典的 key，因此会有2个特定针对 str 对象的 优化版本。 lookdict123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113static Py_ssize_tlookdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos)&#123; size_t i, mask; Py_ssize_t ix, freeslot; int cmp; PyDictKeysObject *dk; PyDictKeyEntry *ep0, *ep; PyObject *startkey;top: dk = mp-&gt;ma_keys; mask = DK_MASK(dk); ep0 = DK_ENTRIES(dk); i = (size_t)hash &amp; mask; ix = dk_get_index(dk, i); if (ix == DKIX_EMPTY) &#123; if (hashpos != NULL) *hashpos = i; *value_addr = NULL; return DKIX_EMPTY; &#125; if (ix == DKIX_DUMMY) &#123; freeslot = i; &#125; else &#123; ep = &amp;ep0[ix]; assert(ep-&gt;me_key != NULL); if (ep-&gt;me_key == key) &#123; *value_addr = &amp;ep-&gt;me_value; if (hashpos != NULL) *hashpos = i; return ix; &#125; if (ep-&gt;me_hash == hash) &#123; startkey = ep-&gt;me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); Py_DECREF(startkey); if (cmp &lt; 0) &#123; *value_addr = NULL; return DKIX_ERROR; &#125; if (dk == mp-&gt;ma_keys &amp;&amp; ep-&gt;me_key == startkey) &#123; if (cmp &gt; 0) &#123; *value_addr = &amp;ep-&gt;me_value; if (hashpos != NULL) *hashpos = i; return ix; &#125; &#125; else &#123; /* The dict was mutated, restart */ goto top; &#125; &#125; freeslot = -1; &#125; for (size_t perturb = hash;;) &#123; perturb &gt;&gt;= PERTURB_SHIFT; i = ((i &lt;&lt; 2) + i + perturb + 1) &amp; mask; ix = dk_get_index(dk, i); if (ix == DKIX_EMPTY) &#123; if (hashpos != NULL) &#123; *hashpos = (freeslot == -1) ? (Py_ssize_t)i : freeslot; &#125; *value_addr = NULL; return ix; &#125; if (ix == DKIX_DUMMY) &#123; if (freeslot == -1) freeslot = i; continue; &#125; ep = &amp;ep0[ix]; assert(ep-&gt;me_key != NULL); if (ep-&gt;me_key == key) &#123; if (hashpos != NULL) &#123; *hashpos = i; &#125; *value_addr = &amp;ep-&gt;me_value; return ix; &#125; if (ep-&gt;me_hash == hash) &#123; startkey = ep-&gt;me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); Py_DECREF(startkey); if (cmp &lt; 0) &#123; *value_addr = NULL; return DKIX_ERROR; &#125; if (dk == mp-&gt;ma_keys &amp;&amp; ep-&gt;me_key == startkey) &#123; if (cmp &gt; 0) &#123; if (hashpos != NULL) &#123; *hashpos = i; &#125; *value_addr = &amp;ep-&gt;me_value; return ix; &#125; &#125; else &#123; /* The dict was mutated, restart */ goto top; &#125; &#125; &#125; assert(0); /* NOT REACHED */ return 0;&#125; 如上，通用的 lookdict 代码很长。大概可以分为 以下几部分 ix = ?12345678910111213#define DK_MASK(dk) (((dk)-&gt;dk_size)-1)static Py_ssize_tlookdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos)&#123; size_t i, mask; PyDictKeysObject *dk; dk = mp-&gt;ma_keys; mask = DK_MASK(dk); i = (size_t)hash &amp; mask; // hash%dk_size == hash &amp; (dk_size - 1)&#125; 前面已经知道： hash == PyObject_Hash(key) dk_size &gt;= 8 &amp;&amp; IS_POWER_OF_2 注意最后一行，将 hash 值映射到数组上 if ix == DKIX_EMPTY1234567891011121314static Py_ssize_tlookdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject ***value_addr, Py_ssize_t *hashpos)&#123; /* lookup indices. returns DKIX_EMPTY, DKIX_DUMMY, or ix &gt;=0 */ ix = dk_get_index(dk, i); if (ix == DKIX_EMPTY) &#123; if (hashpos != NULL) *hashpos = i; *value_addr = NULL; return DKIX_EMPTY; &#125;&#125; 如上，当 ix == DKIX_EMPTY 表明，slot 可用，直接返回。需要注意的是，返回之前，把 *value_addr 设为了 NULL，相当于清空了数据。 if ix != DKIX_EMPTY123456789101112131415161718192021222324252627282930313233343536373839404142PyDictKeyEntry *ep0, *ep;// DK_ENTRIES(keys)[index] if index &gt;= 0ep0 = DK_ENTRIES(dk);if (ix == DKIX_DUMMY) &#123; freeslot = i; // 伪删除，me_value==NULL&#125;else &#123; ep = &amp;ep0[ix]; assert(ep-&gt;me_key != NULL); if (ep-&gt;me_key == key) &#123; // 引用相同 *value_addr = &amp;ep-&gt;me_value; if (hashpos != NULL) *hashpos = i; return ix; &#125; if (ep-&gt;me_hash == hash) &#123; // hash 相同 startkey = ep-&gt;me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); /* cmp = startkey == key ? 1 : 0 or -1 (raise ERROR) */ Py_DECREF(startkey); if (cmp &lt; 0) &#123; *value_addr = NULL; return DKIX_ERROR; &#125; if (dk == mp-&gt;ma_keys &amp;&amp; ep-&gt;me_key == startkey) &#123; if (cmp &gt; 0) &#123; // 值相同 *value_addr = &amp;ep-&gt;me_value; if (hashpos != NULL) *hashpos = i; return ix; &#125; &#125; else &#123; /* The dict was mutated, restart */ goto top; &#125; &#125; freeslot = -1;&#125; 如上，当 ix == DKIX_DUMMY 时，将 freeslot 设置为该 slot。若后续搜索没有成功找到，那么将返回该 slot。 当 ix&gt;=0 &amp;&amp; ix != DKIX_DUMMY 时，获取 Entry 对象，对其值进行判断。前面已经知道，me_hash 是 hash(me_key) 的 缓存。 接着两个 if 判断，是为了优先考虑引用相同，接着再考虑引用不同而值相同。因为 Python 内部存在对象缓冲池，小整数，字符串等具有相同的对象引用，而对于1024等大整数，就必须判断 引用不一样而值一样。 PyObject_RichCompareBool 是传入操作数与操作符，返回数值。 若cmp==1，即 hash,value 都相等，正确返回。 若cmp==0，即 hash相等，值不等，即 hash 冲突。 解决 hash 冲突123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*执行循环的 前提条件：if ix == DKIX_DUMMY： freeslot = ielif ix&gt;=0 and hash冲突: freeslot = -1;*/#define PERTURB_SHIFT 5for (size_t perturb = hash;;) &#123; // 探测链算法 perturb &gt;&gt;= PERTURB_SHIFT; i = ((i &lt;&lt; 2) + i + perturb + 1) &amp; mask; ix = dk_get_index(dk, i); if (ix == DKIX_EMPTY) &#123; if (hashpos != NULL) &#123; *hashpos = (freeslot == -1) ? (Py_ssize_t)i : freeslot; /* 找到一个 UnusedEnpty，表明搜索失败 1. freeslot 不存在，返回现在的 2. freeslot 已经有一个，返回第一个 */ &#125; *value_addr = NULL; return ix; &#125; if (ix == DKIX_DUMMY) &#123; // 探测链 继续寻找 if (freeslot == -1) freeslot = i; continue; &#125; ep = &amp;ep0[ix]; assert(ep-&gt;me_key != NULL); if (ep-&gt;me_key == key) &#123; // 引用相同 if (hashpos != NULL) &#123; *hashpos = i; &#125; *value_addr = &amp;ep-&gt;me_value; return ix; &#125; if (ep-&gt;me_hash == hash) &#123; startkey = ep-&gt;me_key; Py_INCREF(startkey); cmp = PyObject_RichCompareBool(startkey, key, Py_EQ); Py_DECREF(startkey); if (cmp &lt; 0) &#123; *value_addr = NULL; return DKIX_ERROR; &#125; if (dk == mp-&gt;ma_keys &amp;&amp; ep-&gt;me_key == startkey) &#123; if (cmp &gt; 0) &#123; // 值相同 if (hashpos != NULL) &#123; *hashpos = i; &#125; *value_addr = &amp;ep-&gt;me_value; return ix; &#125; &#125; else &#123; /* The dict was mutated, restart */ goto top; &#125; &#125;&#125; 如上，整个过程是，当发生冲突时，再次计算获取一个 i 值，最终返回 NUll 或 目标值。 SetItemdict_ass_sub123456789101112131415161718192021222324252627282930313233343536// dictobject.c.2163static intdict_ass_sub(PyDictObject *mp, PyObject *v, PyObject *w)&#123; if (w == NULL) return PyDict_DelItem((PyObject *)mp, v); else return PyDict_SetItem((PyObject *)mp, v, w);&#125;// dictobject.c.1554intPyDict_SetItem(PyObject *op, PyObject *key, PyObject *value)&#123; PyDictObject *mp; Py_hash_t hash; // 类型检查 if (!PyDict_Check(op)) &#123; PyErr_BadInternalCall(); return -1; &#125; assert(key); assert(value); mp = (PyDictObject *)op; // 获取 hash 值 if (!PyUnicode_CheckExact(key) || (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) &#123; hash = PyObject_Hash(key); if (hash == -1) return -1; &#125; /* insertdict() handles any resizing that might be necessary */ return insertdict(mp, key, hash, value);&#125; 执行 dict[item] = value 时，调用 dict_ass_sub()。如上，与 List 类似，SetItem 和 DelItem 都是调用同一个方法。在 PyDict_SetItem 中，仅进行类型检查，计算 hash 值，实际插入调用 insertdict。 insertdict12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// dictobject.c.1110static intinsertdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject *value)&#123; PyObject *old_value; PyObject **value_addr; PyDictKeyEntry *ep, *ep0; Py_ssize_t hashpos, ix; Py_INCREF(key); Py_INCREF(value); // split-table 插入 key(not Unicode) if (mp-&gt;ma_values != NULL &amp;&amp; !PyUnicode_CheckExact(key)) &#123; if (insertion_resize(mp) &lt; 0) goto Fail; &#125; // 计算 ix 的值 ix = ? ix = mp-&gt;ma_keys-&gt;dk_lookup(mp, key, hash, &amp;value_addr, &amp;hashpos); if (ix == DKIX_ERROR) goto Fail; assert(PyUnicode_CheckExact(key) || mp-&gt;ma_keys-&gt;dk_lookup == lookdict); MAINTAIN_TRACKING(mp, key, value); // split-table 插入 key(different order) if (_PyDict_HasSplitTable(mp) &amp;&amp; ((ix &gt;= 0 &amp;&amp; *value_addr == NULL &amp;&amp; mp-&gt;ma_used != ix) || (ix == DKIX_EMPTY &amp;&amp; mp-&gt;ma_used != mp-&gt;ma_keys-&gt;dk_nentries))) &#123; if (insertion_resize(mp) &lt; 0) goto Fail; find_empty_slot(mp, key, hash, &amp;value_addr, &amp;hashpos); ix = DKIX_EMPTY; &#125; // Insert when ix == DKIX_EMPTY if (ix == DKIX_EMPTY) &#123; /* Insert into new slot. */ if (mp-&gt;ma_keys-&gt;dk_usable &lt;= 0) &#123; /* Need to resize. */ if (insertion_resize(mp) &lt; 0) goto Fail; find_empty_slot(mp, key, hash, &amp;value_addr, &amp;hashpos); &#125; ep0 = DK_ENTRIES(mp-&gt;ma_keys); ep = &amp;ep0[mp-&gt;ma_keys-&gt;dk_nentries]; dk_set_index(mp-&gt;ma_keys, hashpos, mp-&gt;ma_keys-&gt;dk_nentries); ep-&gt;me_key = key; ep-&gt;me_hash = hash; if (mp-&gt;ma_values) &#123; assert (mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] == NULL); mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] = value; &#125; else &#123; ep-&gt;me_value = value; &#125; mp-&gt;ma_used++; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); mp-&gt;ma_keys-&gt;dk_usable--; mp-&gt;ma_keys-&gt;dk_nentries++; assert(mp-&gt;ma_keys-&gt;dk_usable &gt;= 0); assert(_PyDict_CheckConsistency(mp)); return 0; &#125; assert(value_addr != NULL); // Insert when ix != DKIX_EMPTY old_value = *value_addr; if (old_value != NULL) &#123; *value_addr = value; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); assert(_PyDict_CheckConsistency(mp)); Py_DECREF(old_value); /* which **CAN** re-enter (see issue #22653) */ Py_DECREF(key); return 0; &#125; /* pending state */ assert(_PyDict_HasSplitTable(mp)); assert(ix == mp-&gt;ma_used); *value_addr = value; mp-&gt;ma_used++; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); assert(_PyDict_CheckConsistency(mp)); Py_DECREF(key); return 0;Fail: Py_DECREF(value); Py_DECREF(key); return -1;&#125; 如上，实际插入的对象的函数，代码也很长，需要分块处理。 split-table 插入 key(not Unicode)1234if (mp-&gt;ma_values != NULL &amp;&amp; !PyUnicode_CheckExact(key)) &#123; if (insertion_resize(mp) &lt; 0) goto Fail;&#125; 在 前面 PyDictObject 结构体定义中，有提到：1234A split table: ma_values != NULL, dk_refcnt &gt;= 1 Values are stored in the ma_values array. Only string (unicode) keys are allowed. 当，split table 插入的 key 不是 Unicode 时，调用 insertion_resize。 split-table 插入 key(different order)1234567891011/* When insertion order is different from shared key, we can't share * the key anymore. Convert this instance to combine table. */if (_PyDict_HasSplitTable(mp) &amp;&amp; ((ix &gt;= 0 &amp;&amp; *value_addr == NULL &amp;&amp; mp-&gt;ma_used != ix) || (ix == DKIX_EMPTY &amp;&amp; mp-&gt;ma_used != mp-&gt;ma_keys-&gt;dk_nentries))) &#123; if (insertion_resize(mp) &lt; 0) goto Fail; find_empty_slot(mp, key, hash, &amp;value_addr, &amp;hashpos); ix = DKIX_EMPTY;&#125; 在 前面 PyDictObject 结构体定义中，同时有提到：12A split table: All dicts sharing same key must have same insertion order. 如源码中注释所述，当插入 顺序不一致时，将调用 insertion_resize。 Insert when ix == DKIX_EMPTY123456789101112131415161718192021222324252627282930313233if (ix == DKIX_EMPTY) &#123; /* Insert into new slot. */ if (mp-&gt;ma_keys-&gt;dk_usable &lt;= 0) &#123; /* Need to resize. */ if (insertion_resize(mp) &lt; 0) goto Fail; find_empty_slot(mp, key, hash, &amp;value_addr, &amp;hashpos); &#125; // 初始化 ep0 = DK_ENTRIES(mp-&gt;ma_keys); ep = &amp;ep0[mp-&gt;ma_keys-&gt;dk_nentries]; dk_set_index(mp-&gt;ma_keys, hashpos, mp-&gt;ma_keys-&gt;dk_nentries); ep-&gt;me_key = key; ep-&gt;me_hash = hash; // 插入不同地方 if (mp-&gt;ma_values) &#123; assert (mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] == NULL); mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] = value; &#125; else &#123; ep-&gt;me_value = value; &#125; // 调整属性值 mp-&gt;ma_used++; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); mp-&gt;ma_keys-&gt;dk_usable--; mp-&gt;ma_keys-&gt;dk_nentries++; assert(mp-&gt;ma_keys-&gt;dk_usable &gt;= 0); assert(_PyDict_CheckConsistency(mp)); return 0;&#125; 如上，ix == DKIX_EMPTY 时，执行插入动作。 if 可用空间 dk_usable &lt;=0，调用 insertion_resize dk_set_index，初始化 me_key, me_hash 根据 ma_values，判断 table 类型，插入 不同的地方 调整 mp 自身属性 Insert when ix != DKIX_EMPTY123456789101112131415161718192021assert(value_addr != NULL);old_value = *value_addr;if (old_value != NULL) &#123; *value_addr = value; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); assert(_PyDict_CheckConsistency(mp)); Py_DECREF(old_value); /* which **CAN** re-enter (see issue #22653) */ Py_DECREF(key); return 0;&#125;/* pending state */assert(_PyDict_HasSplitTable(mp));assert(ix == mp-&gt;ma_used);*value_addr = value;mp-&gt;ma_used++;mp-&gt;ma_version_tag = DICT_NEXT_VERSION();assert(_PyDict_CheckConsistency(mp));Py_DECREF(key);return 0; 如上，ix != DKIX_EMPTY 即代表修改值。同时，根据 old_value 可以判断出 表的类型。 PyDict_DelItem前面已经提到 Del 和 Set 有相同的入口 dict_ass_sub。Del 最终实现是靠 PyDict_DelItem()1234567891011121314// dictobject.c/1621int PyDict_DelItem(PyObject *op, PyObject *key)&#123; Py_hash_t hash; assert(key); if (!PyUnicode_CheckExact(key) || (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) &#123; hash = PyObject_Hash(key); if (hash == -1) return -1; &#125; return _PyDict_DelItem_KnownHash(op, key, hash);&#125; 如上，先验证 hash，在调用 _PyDict_DelItem_KnownHash _PyDict_DelItem_KnownHash123456789101112131415161718192021222324252627282930313233int_PyDict_DelItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)&#123; Py_ssize_t hashpos, ix; PyDictObject *mp; PyObject **value_addr; if (!PyDict_Check(op)) &#123; PyErr_BadInternalCall(); return -1; &#125; assert(key); assert(hash != -1); mp = (PyDictObject *)op; ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;value_addr, &amp;hashpos); if (ix == DKIX_ERROR) return -1; if (ix == DKIX_EMPTY || *value_addr == NULL) &#123; _PyErr_SetKeyError(key); return -1; &#125; assert(dk_get_index(mp-&gt;ma_keys, hashpos) == ix); // Split table doesn't allow deletion. Combine it. if (_PyDict_HasSplitTable(mp)) &#123; if (dictresize(mp, DK_SIZE(mp-&gt;ma_keys))) &#123; return -1; &#125; ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;value_addr, &amp;hashpos); assert(ix &gt;= 0); &#125; return delitem_common(mp, hashpos, ix, value_addr);&#125; 如上，_PyDict_DelItem_KnownHash 代码很好理解，根据 key hash 找到相应的 enrty。需要注意的是其中的，Split-table 不允许删除操作，必然要转换为 combined table。 delitem_common1234567891011121314151617181920212223static intdelitem_common(PyDictObject *mp, Py_ssize_t hashpos, Py_ssize_t ix, PyObject **value_addr)&#123; PyObject *old_key, *old_value; PyDictKeyEntry *ep; old_value = *value_addr; assert(old_value != NULL); *value_addr = NULL; mp-&gt;ma_used--; mp-&gt;ma_version_tag = DICT_NEXT_VERSION(); ep = &amp;DK_ENTRIES(mp-&gt;ma_keys)[ix]; dk_set_index(mp-&gt;ma_keys, hashpos, DKIX_DUMMY); ENSURE_ALLOWS_DELETIONS(mp); old_key = ep-&gt;me_key; ep-&gt;me_key = NULL; Py_DECREF(old_key); Py_DECREF(old_value); assert(_PyDict_CheckConsistency(mp)); return 0;&#125; 如上，代码很简单。。就酱。。 insertion_resize123456// dictobject.c.1099static intinsertion_resize(PyDictObject *mp)&#123; return dictresize(mp, GROWTH_RATE(mp));&#125; 前面，已经提到，在 CRUD 时，有几种情况下会调用 insertion_resize dk_usable &lt;=0 split-table insert key which is not Unicode. split-table insertion order is different from shared key. GROWTH_RATE1#define GROWTH_RATE(d) (((d)-&gt;ma_used*2)+((d)-&gt;ma_keys-&gt;dk_size&gt;&gt;1)) 如上，在调用 dictresize 之前，会先计算一个 GROWTH_RATE。这个东西的作用可以参考链接已失效 123456789101112如果原有的数据量小于原有大小的1/4，那么它也会小于现有大小的1/4，但新的dict缩小了；如果原有的数据量大于原有大小的1/4，那么它也会大于现有大小的1/4，但新的dict扩大了。if used &lt; size/4: used*4 &lt; used*2 + size/4*2 = used*2 + size/2 = newsize used &lt; newsize/4 newsize = used*2 + size/2 &lt; size/4*2 + size/2 = sizeif used &gt; size/4: used*4 &gt; used*2 + size/4*2 = used*2 + size/2 = newsize used &gt; newsize/4 newsize = used*2 + size/2 &gt; size/4*2 + size/2 = size emmm…好吧，看看就好 dictresize123456789101112131415161718192021222324252627282930313233343536373839404142// dictobject.c.1250/* Restructure the table by allocating a new table and reinserting all items again. When entries have been deleted, the new table may actually be smaller than the old one. If a table is split (its keys and hashes are shared, its values are not), then the values are temporarily copied into the table, it is resized as a combined table, then the me_value slots in the old table are NULLed out. After resizing a table is always combined, but can be resplit by make_keys_shared().*/static intdictresize(PyDictObject *mp, Py_ssize_t minsize) ... // 很多很多 /* Allocate a new table. */ // 注：static PyDictKeysObject *new_keys_object(Py_ssize_t size) mp-&gt;ma_keys = new_keys_object(newsize); /* Main loop */ for (i = 0; i &lt; oldkeys-&gt;dk_nentries; i++) &#123; PyDictKeyEntry *ep = &amp;ep0[i]; if (ep-&gt;me_value != NULL) &#123; insertdict_clean(mp, ep-&gt;me_key, ep-&gt;me_hash, ep-&gt;me_value); &#125; &#125; ... // 很多很多&#125;/* Internal routine used by dictresize() to insert an item which is known to be absent from the dict. This routine also assumes that the dict contains no deleted entries. Besides the performance benefit, using insertdict() in dictresize() is dangerous (SF bug #1456209). Note that no refcounts are changed by this routine; if needed, the caller is responsible for incref'ing `key` and `value`. Neither mp-&gt;ma_used nor k-&gt;dk_usable are modified by this routine; the caller must set them correctly*/static voidinsertdict_clean(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject *value) emm…代码很长，看注释就够了。 dictresize 返回的都是 combined table，跟上文一致 combined split 两者是可以相互转换的 resize 后，表是可以被 扩容或缩小的 insertdict_clean 只干插入的活，不干其他的 只要涉及到 resize ，就涉及到 Malloc memcpy，耗时 耗力]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyDictObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyListObject]]></title>
    <url>%2F2018%2F07%2F15%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.3.Python%E5%88%97%E8%A1%A8%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[参考 List Objects 前言123Another generally useful object type is a list of object pointers.This is a mutable type: the list items can be changed, and items can beadded or removed. Out-of-range indices or non-list objects are ignored. 老套路，开局一段注释： 对象指针列表 可以增删改查 具有索引容错功能 PyListObject123456789101112131415161718// listobject.h.23typedef struct &#123; PyObject_VAR_HEAD PyObject **ob_item; Py_ssize_t allocated;&#125; PyListObject;/* ob_item contains space for 'allocated' elements. The number * currently in use is ob_size. * Invariants: * 0 &lt;= ob_size &lt;= allocated * len(list) == ob_size * ob_item == NULL implies ob_size == allocated == 0 * list.sort() temporarily sets allocated to -1 to detect mutations. * * Items must normally not be NULL, except during construction when * the list is not yet visible outside the function that builds it. */ 如上，其中的注释很有用，其他信息： **ob_item 明确是指针数组 allocated 标记了容器大小，决定了内存大小 ob_size 标记了元素个数 PyList_Type1234567891011// listobject.c.2624PyTypeObject PyList_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "list", sizeof(PyListObject), 0, (destructor)list_dealloc, /* tp_dealloc */ PyType_GenericAlloc, /* tp_alloc */ PyType_GenericNew, /* tp_new */ (initproc)list_init, /* tp_init */&#125;; 在之前的 PyLong_Type、PyUnicode_Type中，tp_new都是单独定义的函数。而在PyList_Type中，是通用的 PyType_Generic* 函数。下面，我们就来看下他们的逻辑。 PyType_GenericNew1234567891011121314151617181920212223242526272829303132333435363738394041424344// typeobject.c.958PyObject *PyType_GenericNew(PyTypeObject *type, PyObject *args, PyObject *kwds)&#123; return type-&gt;tp_alloc(type, 0);&#125;// typeobject.c.928PyObject * PyType_GenericAlloc(PyTypeObject *type, Py_ssize_t nitems)&#123; PyObject *obj; const size_t size = _PyObject_VAR_SIZE(type, nitems+1); /* note that we need to add one, for the sentinel */ if (PyType_IS_GC(type)) obj = _PyObject_GC_Malloc(size); else obj = (PyObject *)PyObject_MALLOC(size); if (obj == NULL)); return PyErr_NoMemory(); memset(obj, '\0', size); if (type-&gt;tp_flags &amp; Py_TPFLAGS_HEAPTYPE) Py_INCREF(type); if (type-&gt;tp_itemsize == 0) (void)PyObject_INIT(obj, type); else (void) PyObject_INIT_VAR((PyVarObject *)obj, type, nitems); if (PyType_IS_GC(type)) _PyObject_GC_TRACK(obj); return obj;&#125;// objimpl.h.141/* Macros trading binary compatibility for speed. See also pymem.h. Note that these macros expect non-NULL object pointers.*/#define PyObject_INIT(op, typeobj) \ ( Py_TYPE(op) = (typeobj), _Py_NewReference((PyObject *)(op)), (op) )#define PyObject_INIT_VAR(op, typeobj, size) \ ( Py_SIZE(op) = (size), PyObject_INIT((op), (typeobj)) ) 如上，具体细节不在深究，能够看出一个轮廓： 根据 type 计算 size 根据 size 调用 MALLOC 调用 INIT 完成初始化 PyList_New123456789PyObject* PyList_New(Py_ssize_t len) Return value: New reference. Return a new list of length len on success, or NULL on failure. Note: If len is greater than zero, the returned list object’s items are set to NULL. Thus you cannot use abstract API functions such as PySequence_SetItem() or expose the object to Python code before setting all items to a real object with PyList_SetItem(). 上面，是来自来自文档的API介绍，其中介绍了创建列表，设置元素的方法。 12345678910111213141516171819202122232425262728293031323334353637383940// listobject.c.104#define PyList_MAXFREELIST 80static PyListObject *free_list[PyList_MAXFREELIST];static int numfree = 0;// listobject.c.140PyObject * PyList_New(Py_ssize_t size)&#123; PyListObject *op; // asert size &gt;= 0 if (size &lt; 0) &#123; PyErr_BadInternalCall(); return NULL; &#125; // 尝试共享 list 对象指针 if (numfree) &#123; numfree--; op = free_list[numfree]; _Py_NewReference((PyObject *)op); &#125; else &#123; op = PyObject_GC_New(PyListObject, &amp;PyList_Type); if (op == NULL) return NULL; &#125; // 获取真实数据地址 if (size &lt;= 0) op-&gt;ob_item = NULL; else &#123; op-&gt;ob_item = (PyObject **) PyMem_Calloc(size, sizeof(PyObject *)); &#125; // 赋初值 Py_SIZE(op) = size; op-&gt;allocated = size; _PyObject_GC_TRACK(op); return (PyObject *) op;&#125; 如上，从中我们可以看到，一个数组 free_list，很容易联想到共享机制。通过 numfree 与 free_list 的配合，实现了列表的共享，却又不同于之前谈到的整数小对象池。此处共享的是对象的指针，但真实数据的地址是不共享的，这点也很容易明白。 共享机制如上，free_list 与 small_ints 类似，都是提供对象缓冲池，但又不完全一样。 小整数对象 small_ints 是一个数组 [-5, 256] 单字节对象 characters 是一个数组 latin-1 [0 - 255] UnicodeObject interned 是一个弱引用的对象字典 ListObject free_list 是一个数组，存放着80个销毁的对象 list_dealloc12345678910111213141516171819// Objects/listobject.c/313行static void list_dealloc(PyListObject *op)&#123; Py_ssize_t i; PyObject_GC_UnTrack(op); Py_TRASHCAN_SAFE_BEGIN(op) if (op-&gt;ob_item != NULL) &#123; i = Py_SIZE(op); while (--i &gt;= 0) &#123; Py_XDECREF(op-&gt;ob_item[i]); &#125; PyMem_FREE(op-&gt;ob_item); &#125; if (numfree &lt; PyList_MAXFREELIST &amp;&amp; PyList_CheckExact(op)) free_list[numfree++] = op; else Py_TYPE(op)-&gt;tp_free((PyObject *)op); Py_TRASHCAN_SAFE_END(op)&#125; 如上，PyList_Type 中定义了 tp_dealloc 为 list_dealloc，在代码中可以看见： 对元素进行循环处理：减引用 对 ob_item 指针进行释放 尝试加入缓冲池 free_list CRUD在 PyList_New 中，很明确的指出创建对象后要先调用 PyList_SetItem PyList_SetItem1234567891011121314151617int PyList_SetItem(PyObject *list, Py_ssize_t index, PyObject *item) Set the item at index index in list to item. Return 0 on success or -1 on failure. Note: This function “steals” a reference to item and discards a reference to an item already in the list at the affected position.void PyList_SET_ITEM(PyObject *list, Py_ssize_t i, PyObject *o) Macro form of PyList_SetItem() without error checking. This is normally only used to fill in new lists where there is no previous content. Note: This macro “steals” a reference to item, and, unlike PyList_SetItem(), does not discard a reference to any item that is being replaced; any reference in list at position i will be leaked. 文档中，指出设置元素的方式，并且指明引用计数的处理原则。 1234567891011121314151617181920212223242526272829303132333435#define PyList_SET_ITEM(op, i, v) (((PyListObject *)(op))-&gt;ob_item[i] = (v))// listobject.c.218int PyList_SetItem(PyObject *op, Py_ssize_t i, PyObject *newitem)&#123; PyObject **p; // op 类型检查 if (!PyList_Check(op)) &#123; Py_XDECREF(newitem); PyErr_BadInternalCall(); return -1; &#125; // 索引值容错 if (i &lt; 0 || i &gt;= Py_SIZE(op)) &#123; Py_XDECREF(newitem); PyErr_SetString(PyExc_IndexError, "list assignment index out of range"); return -1; &#125; // 对象指针引用 p = ((PyListObject *)op) -&gt; ob_item + i; Py_XSETREF(*p, newitem); return 0;&#125;// object.h.882#define Py_XSETREF(op, op2) \ do &#123; \ PyObject *_py_tmp = (PyObject *)(op); \ (op) = (op2); \ Py_XDECREF(_py_tmp); \ &#125; while (0) 如上，对元素进行赋值操作，单纯的进行了对象指针赋值操作，时间复杂度O(1)。 需要注意的是，如上文所述，在指针替换的过程中，只减少了原地址的引用，并未增加 newitem 的引用数。 PyList_GetItem123456789101112PyObject* PyList_GetItem(PyObject *list, Py_ssize_t index) Return value: Borrowed reference. Return the object at position index in the list pointed to by list. The position must be positive, indexing from the end of the list is not supported. If index is out of bounds, return NULL and set an IndexError exception.PyObject* PyList_GET_ITEM(PyObject *list, Py_ssize_t i) Return value: Borrowed reference. Macro form of PyList_GetItem() without error checking. 文档中也指出了获取元素的方式，其中一个是宏实现。 123456789101112131415161718#define PyList_GET_ITEM(op, i) (((PyListObject *)(op))-&gt;ob_item[i])// Objects/listobject.c/198行PyObject * PyList_GetItem(PyObject *op, Py_ssize_t i)&#123; // 类型检查(略) if (i &lt; 0 || i &gt;= Py_SIZE(op)) &#123; if (indexerr == NULL) &#123; indexerr = PyUnicode_FromString( "list index out of range"); if (indexerr == NULL) return NULL; &#125; PyErr_SetObject(PyExc_IndexError, indexerr); return NULL; &#125; return ((PyListObject *)op) -&gt; ob_item[i];&#125; 如上，函数PyList_GetItem会进行容错处理。最终按索引进行数组取值，时间复杂度O(1) PyList_Insert1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// listobject.c.272int PyList_Insert(PyObject *op, Py_ssize_t where, PyObject *newitem)&#123; // 类型检查(略) return ins1((PyListObject *)op, where, newitem);&#125;// listobject.c.239static int ins1(PyListObject *self, Py_ssize_t where, PyObject *v)&#123; Py_ssize_t i, n = Py_SIZE(self); PyObject **items; // 容错处理 if (v == NULL) &#123; PyErr_BadInternalCall(); return -1; &#125; if (n == PY_SSIZE_T_MAX) &#123; PyErr_SetString(PyExc_OverflowError, "cannot add more objects to list"); return -1; &#125; // !!! 可能调整位置 !!! if (list_resize(self, n+1) &lt; 0) return -1; // 索引正负号处理 if (where &lt; 0) &#123; where += n; if (where &lt; 0) where = 0; &#125; if (where &gt; n) where = n; // 移动元素 items = self-&gt;ob_item; for (i = n; --i &gt;= where; ) items[i+1] = items[i]; // 插入值 Py_INCREF(v); items[where] = v; return 0;&#125; 如上，对数组进行插值大概可以分为几部分，从中可以看出： 索引 where 支持负值，支持大于元素个数的值 调用 list_resize 可能会调整位置 插入值，会产生移动操作。时间复杂度O(n) list_resize1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// listobject.c.25static int list_resize(PyListObject *self, Py_ssize_t newsize)&#123; PyObject **items; size_t new_allocated; Py_ssize_t allocated = self-&gt;allocated; // 如果足够大，就减小 if (allocated &gt;= newsize &amp;&amp; newsize &gt;= (allocated &gt;&gt; 1)) &#123; assert(self-&gt;ob_item != NULL || newsize == 0); Py_SIZE(self) = newsize; return 0; &#125; // 计算新的需要 new_allocated = (newsize &gt;&gt; 3) + (newsize &lt; 9 ? 3 : 6); /* check for integer overflow */ if (new_allocated &gt; SIZE_MAX - newsize) &#123; PyErr_NoMemory(); return -1; &#125; else &#123; new_allocated += newsize; &#125; if (newsize == 0) new_allocated = 0; items = self-&gt;ob_item; // 调整大小 if (new_allocated &lt;= (SIZE_MAX / sizeof(PyObject *))) PyMem_RESIZE(items, PyObject *, new_allocated); else items = NULL; if (items == NULL) &#123; PyErr_NoMemory(); return -1; &#125; // 赋值 self-&gt;ob_item = items; Py_SIZE(self) = newsize; self-&gt;allocated = new_allocated; return 0;&#125;调用链：if (list_resize(self, n+1) &lt; 0) return -1; 如上，list_resize 接收一个 list对 象指针以及新的size值，成功返回0，失败返回-1。具体分析，见下文的伪代码 12345678910111213141516def list_resize(*self, newsize): allocated = self.allocated if newsize == 0: new_allocated = 0 elif allocated /2 &lt;= newsize &lt;= allocated： self.size = newsize return 0 else: new_allocated = newsize + newsize / 8 + (3 if newsize&lt;9 else 6) PyMem_RESIZE(items, PyObject *, new_allocated); self-&gt;ob_item = items; Py_SIZE(self) = newsize; self-&gt;allocated = new_allocated; return 0; PyMem_RESIZE，调用 PyMem_REALLOC，实现最终的重新分配内存空间。 PyList_Append12345678910111213141516171819202122// Objects/listobject.c/282行static intapp1(PyListObject *self, PyObject *v)&#123; Py_ssize_t n = PyList_GET_SIZE(self); if (list_resize(self, n+1) &lt; 0) return -1; Py_INCREF(v); PyList_SET_ITEM(self, n, v); return 0;&#125;intPyList_Append(PyObject *op, PyObject *newitem)&#123; if (PyList_Check(op) &amp;&amp; (newitem != NULL)) return app1((PyListObject *)op, newitem); PyErr_BadInternalCall(); return -1;&#125; 如上，append -&gt; app1 -&gt; list_resize -&gt; PyList_SET_ITEM若 list_resize 不触发 PyMem_RESIZE()，时间复杂度为 O(1) PyList_GetSlice(list_slice)123456789101112131415161718192021222324252627282930313233343536373839404142// listobject.c.458PyObject *PyList_GetSlice(PyObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)&#123; // 类型检查(略) return list_slice((PyListObject *)a, ilow, ihigh);&#125;// listobject.c.428static PyObject * list_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)&#123; PyListObject *np; PyObject **src, **dest; Py_ssize_t i, len; // 边界处理 if (ilow &lt; 0) ilow = 0; else if (ilow &gt; Py_SIZE(a)) ilow = Py_SIZE(a); if (ihigh &lt; ilow) ihigh = ilow; else if (ihigh &gt; Py_SIZE(a)) ihigh = Py_SIZE(a); len = ihigh - ilow; // 新对象 np = (PyListObject *) PyList_New(len); if (np == NULL) return NULL; src = a-&gt;ob_item + ilow; dest = np-&gt;ob_item; // 拷贝数据指针 for (i = 0; i &lt; len; i++) &#123; PyObject *v = src[i]; Py_INCREF(v); dest[i] = v; &#125; return (PyObject *)np;&#125; 如上，对List 切片取值。其中需要注意的是，在数据拷贝过程中，拷贝的是指针，实现的是 浅拷贝。 PyList_SetSlice(list_ass_slice)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123intPyList_SetSlice(PyObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)&#123; ... // 类型检查 return list_ass_slice((PyListObject *)a, ilow, ihigh, v);&#125;// listobject.c.569static intlist_ass_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)&#123; PyObject *recycle_on_stack[8]; /* can allocate more if needed */ PyObject **recycle = recycle_on_stack; PyObject **item; PyObject **vitem = NULL; PyObject *v_as_SF = NULL; /* PySequence_Fast(v) */ Py_ssize_t n; /* # of elements in replacement list */ Py_ssize_t norig; /* # of elements in list getting replaced */ Py_ssize_t d; /* Change in size */ Py_ssize_t k; size_t s; int result = -1; /* guilty until proved innocent */#define b ((PyListObject *)v) // v = NULL，不执行操作 if (v == NULL) n = 0; else &#123; if (a == b) &#123; /* Special case "a[i:j] = a" -- copy b first */ v = list_slice(b, 0, Py_SIZE(b)); if (v == NULL) return result; result = list_ass_slice(a, ilow, ihigh, v); Py_DECREF(v); return result; &#125; v_as_SF = PySequence_Fast(v, "can only assign an iterable"); n = PySequence_Fast_GET_SIZE(v_as_SF); vitem = PySequence_Fast_ITEMS(v_as_SF); &#125; // 边界处理（略） ilow = ? ihigh = ? norig = ihigh - ilow; assert(norig&gt;= 0); d = n - norig; // a[:] = [] 清空 if (Py_SIZE(a) + d == 0) &#123; Py_XDECREF(v_as_SF); return list_clear(a); &#125; // 创建临时数据 recycle item = a-&gt;ob_item; /* recycle the items that we are about to remove */ s = norig * sizeof(PyObject *); /* If norig == 0, item might be NULL, in which case we may not memcpy from it. */ if (s) &#123; if (s &gt; sizeof(recycle_on_stack)) &#123; recycle = (PyObject **)PyMem_MALLOC(s); &#125; memcpy(recycle, &amp;item[ilow], s); &#125; // 形如 a[1:10] = [1,2] if (d &lt; 0) &#123; /* Delete -d items */ Py_ssize_t tail; tail = (Py_SIZE(a) - ihigh) * sizeof(PyObject *); // 左移 a[ihigh:]，减少空位 memmove(&amp;item[ihigh+d], &amp;item[ihigh], tail); // 拷贝后，尝试 resieze if (list_resize(a, Py_SIZE(a) + d) &lt; 0) &#123; // 失败后恢复 recycle memmove(&amp;item[ihigh], &amp;item[ihigh+d], tail); memcpy(&amp;item[ilow], recycle, s); goto Error; &#125; item = a-&gt;ob_item; &#125; // 形如 a[0:2] =[1,2,3,4] else if (d &gt; 0) &#123; /* Insert d items */ k = Py_SIZE(a); if (list_resize(a, k+d) &lt; 0) goto Error; item = a-&gt;ob_item; // 右移 a[ihigh:]，腾出位置 memmove(&amp;item[ihigh+d], &amp;item[ihigh], (k - ihigh)*sizeof(PyObject *)); &#125; // 拷贝 v 的值指针到 a for (k = 0; k &lt; n; k++, ilow++) &#123; PyObject *w = vitem[k]; Py_XINCREF(w); // 注意，从 ilow 开始 item[ilow] = w; &#125; // 释放 recycle for (k = norig - 1; k &gt;= 0; --k) Py_XDECREF(recycle[k]); result = 0; Error: if (recycle != recycle_on_stack) PyMem_FREE(recycle); Py_XDECREF(v_as_SF); return result;#undef b&#125; 当执行 a[low:high] = v 时，调用 SetSlice 方法，具体执行逻辑见注释内容。 从源码中，能分析出一些执行结果，伪代码如下：123456789101112131415161718192021222324252627282930/* a[ilow:ihigh] = v if v != NULL. del a[ilow:ihigh] if v == NULL. */&gt;&gt;&gt; a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; del a[1:1]&gt;&gt;&gt; a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]v=NULLn=0ilow = 1ihigh = 1norig = ihigh - ilow = 0d = n - norig = 0不满足 if(d) 中的任何条件，结果就是不做任何操作&gt;&gt;&gt; a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; a[1:1] = [1]&gt;&gt;&gt; a[0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9]v!=NULLn=1ilow = 1ihigh = 1norig = ihigh - ilow = 0d = n - norig = 1满足 if(d&gt;0)，右移腾出位置，并插入a[ilow] = 1 listremove12345678910111213141516171819// listobject.c.2193static PyObject * listremove(PyListObject *self, PyObject *v)&#123; Py_ssize_t i; for (i = 0; i &lt; Py_SIZE(self); i++) &#123; int cmp = PyObject_RichCompareBool(self-&gt;ob_item[i], v, Py_EQ); if (cmp &gt; 0) &#123; if (list_ass_slice(self, i, i+1, (PyObject *)NULL) == 0) Py_RETURN_NONE; return NULL; &#125; else if (cmp &lt; 0) return NULL; &#125; PyErr_SetString(PyExc_ValueError, "list.remove(x): x not in list"); return NULL;&#125; 由上，可以看出，删除元素是通过 list_ass_slice 实现： 仅删除第一个遇见的元素，删除一个不在其中的元素，会报错 删除是通过遍历实现，时间复杂度 O(n) 总结PyListObject 也利用了缓冲池机制，只缓冲对象，不缓冲数据。 下面是粗略的时间复杂度( list_resize 不涉及到 移动时)： SetItem - O(1) GetItem - O(1) Append - O(1) Insert - O(n)，对象移动 GetSlice - O(high - low)，创建新对象，拷贝指针 SetSlice - O(n)，对象移动，拷贝指针 Remove - O(n)，遍历，对象移动]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyListObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyBytesObject/PyUnicodeObject]]></title>
    <url>%2F2018%2F07%2F15%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.2.Python%E5%AD%97%E7%AC%A6%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[前言众所周知，Python2 中存在 str、bytes、unicode，Python3中只存在 str、bytes，然而却并不表示相同的含义，Python3中的 str 即Python2中的 unicode。 按照 CPython3的文档显示：Sequence Objects下辖 Bytes Objects、Unicode Objects。自PEP393之后，Unicode Type 变成了层次化的结构，用以减少内存占用。 Bytes ObjectsPyBytesObject12345// bytesobject.h.12Type PyBytesObject represents a character string. An extra zero byte isreserved at the end to ensure it is zero-terminated, but a size ispresent so strings with null bytes in them can be represented. Thisis an immutable object type. 同样开局一段注释： 字符串末尾有一个 \0 字符串计数 size 不含 \0 自身是不可变类型 12345678910111213141516// pyport.h.93/* Py_hash_t is the same size as a pointer. */typedef Py_ssize_t Py_hash_t;// bytesobject.h.31typedef struct &#123; PyObject_VAR_HEAD Py_hash_t ob_shash; char ob_sval[1]; /* Invariants: * ob_sval contains space for 'ob_size+1' elements. * ob_sval[ob_size] == 0. * ob_shash is the hash of the string or -1 if not computed yet. */&#125; PyBytesObject; 从源码可以看出： PyBytesObject 是变长对象 用 char 数组存储字符串对象，数组长度默认为 1 数组 ob_sval 含有 ob_size+1 个元素 PyBytesObject 内部有 ob_shash 变量缓存hash值，且 初始值为 -1 PyBytes_Type1234567891011121314151617// bytesobject.c.25#define PyBytesObject_SIZE (offsetof(PyBytesObject, ob_sval) + 1)// bytesobject.c.2837PyTypeObject PyBytes_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "bytes", PyBytesObject_SIZE, // tp_basicsize sizeof(char), // tp_itemsize ... (reprfunc)bytes_repr, /* tp_repr */ &amp;bytes_as_number, /* tp_as_number */ &amp;bytes_as_sequence, /* tp_as_sequence */ &amp;bytes_as_mapping, /* tp_as_mapping */ (hashfunc)bytes_hash, /* tp_hash */ ...&#125;; 恩，不出意外，也是 PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)。 Bytes 共享机制创建对象时，存在跟 small_ints 类似，使用了对象池技术的 characters：123// bytesobject.c.22static PyBytesObject *characters[UCHAR_MAX + 1];static PyBytesObject *nullstring; 当 size==1 时，将尝试从 characters 中获取对象指针。UCHAR_MAX 即 无符号整型最大值 255。 当 size==0 时，将共享使用 同一个 空字符串指针 nullstring。 123456789101112131415161718&gt;&gt;&gt; a = b'a'&gt;&gt;&gt; b = b'a'&gt;&gt;&gt; id(a),id(b)(1618457902176, 1618457902176)&gt;&gt;&gt;&gt;&gt;&gt; a = b'aa'&gt;&gt;&gt; b = b'aa'&gt;&gt;&gt; id(a),id(b)(1618457901016, 1618457902256)&gt;&gt;&gt;&gt;&gt;&gt; c = b'a'&gt;&gt;&gt; id(c)1618457902176&gt;&gt;&gt;&gt;&gt;&gt; d = b''&gt;&gt;&gt; e = b''&gt;&gt;&gt; id(d),id(e)(1618427315824, 1618427315824) PyBytes_FromString12345PyObject* PyBytes_FromString(const char *v)PyObject* PyBytes_FromStringAndSize(const char *v, Py_ssize_t len)PyObject* PyBytes_FromFormat(const char *format, ...)PyObject* PyBytes_FromFormatV(const char *format, va_list vargs)PyObject* PyBytes_FromObject(PyObject *o) 同样，CPython定义了很多创建 BytesObejct 的方法，下面也只看其中一种。 123456789101112131415161718192021222324252627282930313233343536// bytesobject.c.132/* For PyBytes_FromString(), the parameter `str' points to a null-terminated string containing exactly `size' bytes.*/PyObject * PyBytes_FromString(const char *str)&#123; size_t size; PyBytesObject *op; assert(str != NULL); size = strlen(str); if (size == 0 &amp;&amp; (op = nullstring) != NULL) &#123; Py_INCREF(op); return (PyObject *)op; &#125; if (size == 1 &amp;&amp; (op = characters[*str &amp; UCHAR_MAX]) != NULL) &#123; Py_INCREF(op); return (PyObject *)op; &#125; /* Inline PyObject_NewVar */ op = (PyBytesObject *)PyObject_MALLOC(PyBytesObject_SIZE + size); (void)PyObject_INIT_VAR(op, &amp;PyBytes_Type, size); // PY_TYPE(op) = PyBytes_Type op-&gt;ob_shash = -1; memcpy(op-&gt;ob_sval, str, size+1); /* share short strings */ if (size == 0) &#123; nullstring = op; Py_INCREF(op); &#125; else if (size == 1) &#123; characters[*str &amp; UCHAR_MAX] = op; Py_INCREF(op); &#125; return (PyObject *) op;&#125; 从上面的源码可以看出，PyBytes_FromString 大概分为4部分： 计算 字符串长度 strlen(str) 处理 空字符串 size == 0，尝试获取全局变量 nullstring 处理 单字符串 size == 1，尝试获取共享对象 characters 申请空间、创建对象、拷贝内存、返回结果 需要注意的是： PyObject_MALLOC 申请空间大小为 PyBytesObject_SIZE + size，是一个确定的不能再次改变的值 memcpy(op-&gt;ob_sval, str, size+1)， size+1 表明把 字符数组的 ‘\0’也存入了 op_ob_sval，与前文 相对应 op-&gt;ob_shash = -1，hash 缓冲值，赋值-1，与前文相对应 共享数组 characters ，是在对象的不断创建中，逐渐填满 Unicode ObjectsPyUnicodeObject1234567891011121314151617181920212223242526272829/* There are 4 forms of Unicode strings: - compact ascii: * structure = PyASCIIObject * kind = PyUnicode_1BYTE_KIND * 仅 ASCII 字符，7bit * throw PyUnicode_New - compact: * structure = PyCompactUnicodeObject * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or PyUnicode_4BYTE_KIND * 仅 latin1 且 Non-ASCII 字符，&gt;=8bit * throw PyUnicode_New - legacy string, not ready: * structure = PyUnicodeObject * kind = PyUnicode_WCHAR_KIND * PyUnicode_FromUnicode(NULL, len); - legacy string, ready: * structure = PyUnicodeObject structure * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or PyUnicode_4BYTE_KIND * PyUnicode_FromUnicode(NULL, len); // compact 与 legacy 的显著区别： Compact strings use only one memory block (structure + characters), whereas legacy strings use one block for the structure and one block for characters.*/ 同样开篇一段注释，详细内容可以看PEP393，之所以弄得这么复杂，就是为了权衡通用性与空间利用率。下面还是来看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142// unicodeobject.h.197/* ASCII-only strings created through PyUnicode_New; utf8_length == wstr_length == length; the utf8 pointer == data pointer == wstr */typedef struct &#123; PyObject_HEAD Py_ssize_t length; /* 码位(code points) */ Py_hash_t hash; /* Hash value; -1 if not set */ struct &#123; unsigned int interned:2; // 共享机制 unsigned int kind:3; unsigned int compact:1; unsigned int ascii:1; unsigned int ready:1;/ unsigned int :24; &#125; state; wchar_t *wstr; /* 真实字符串 (null-terminated) */&#125; PyASCIIObject;/* Non-ASCII strings allocated through PyUnicode_New; the data immediately follow the structure. */typedef struct &#123; PyASCIIObject _base; Py_ssize_t utf8_length; /* Number of bytes in utf8, excluding the terminating \0. */ char *utf8; /* UTF-8 representation (null-terminated) */ Py_ssize_t wstr_length; /* Number of code points in wstr, possible * surrogates count as two code points. */&#125; PyCompactUnicodeObject;/* Strings allocated through PyUnicode_FromUnicode(NULL, len); The actual string data is initially in the wstr block; and copied into the data block using _PyUnicode_Ready. */typedef struct &#123; PyCompactUnicodeObject _base; union &#123; void *any; Py_UCS1 *latin1; Py_UCS2 *ucs2; Py_UCS4 *ucs4; &#125; data; /* Canonical, smallest-form Unicode buffer */&#125; PyUnicodeObject; 如上，定义了3种Objec结构体，具体功能及创建方式，见注释内容。 PyUnicode_Type123456789101112131415161718// unicodeobject.c.15170PyTypeObject PyUnicode_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "str", /* tp_name */ sizeof(PyUnicodeObject), /* tp_size */ 0, /* tp_itemsize */ /* Slots */ (destructor)unicode_dealloc, /* tp_dealloc */ ... unicode_repr, /* tp_repr */ &amp;unicode_as_number, /* tp_as_number */ &amp;unicode_as_sequence, /* tp_as_sequence */ &amp;unicode_as_mapping, /* tp_as_mapping */ (hashfunc) unicode_hash, /* tp_hash*/ ... unicode_new, /* tp_new */ PyObject_Del, /* tp_free */&#125;; 可见，PyUnicode_Type 就是 Python3 中的 str。 创建对象与 PyBytesObject 类似，PyUnicodeObject 也存在好几种创建方式，详见python.org。由于存在多种 Unicode OBject，各自的创建方式还不一样，下面分开查看。 PyUnicode_New12345678910111213141516171819202122232425262728293031// unicodeobject.c.1220PyObject * PyUnicode_New(Py_ssize_t size, Py_UCS4 maxchar)&#123; PyObject *obj; PyCompactUnicodeObject *unicode; void *data; enum PyUnicode_Kind kind; int is_sharing, is_ascii; Py_ssize_t char_size; Py_ssize_t struct_size; ... /* 判断 获取变量的值 */ obj = (PyObject *) PyObject_MALLOC(struct_size + (size + 1) * char_size); obj = PyObject_INIT(obj, &amp;PyUnicode_Type); unicode = (PyCompactUnicodeObject *)obj; _PyUnicode_LENGTH(unicode) = size; _PyUnicode_HASH(unicode) = -1; _PyUnicode_STATE(unicode).interned = 0; _PyUnicode_STATE(unicode).kind = kind; _PyUnicode_STATE(unicode).compact = 1; _PyUnicode_STATE(unicode).ready = 1; _PyUnicode_STATE(unicode).ascii = is_ascii; ... /* 根据变量值, 赋值 unicode-&gt;utf8 = ? unicode-&gt;utf8_length = ? _PyUnicode_WSTR_LENGTH(unicode) = ? _PyUnicode_WSTR(unicode) = ? */ return obj;&#125; PyUnicode_New 是创建compact string的方式，代码很长，多数都是在容错处理。最终 MALLOC，然后赋初值，return。那么，问题来了，难道 Unicode Object 没有共享机制？ PyUnicode_FromUnicode12345678910111213141516171819202122232425// unicodeobject.c.1993PyObject * PyUnicode_FromUnicode(const Py_UNICODE *u, Py_ssize_t size)&#123; PyObject *unicode; Py_UCS4 maxchar = 0; Py_ssize_t num_surrogates; if (u == NULL) return (PyObject*)_PyUnicode_New(size); /* 宏套宏，最终实现共享 unicode_empty=PyUnicode_New(0, 0); */ if (size == 0) _Py_RETURN_UNICODE_EMPTY(); /* 共享 Single character*/ if (size == 1 &amp;&amp; (Py_UCS4)*u &lt; 256) return get_latin1_char((unsigned char)*u); /* 创建新 not single 对象 */ unicode = PyUnicode_New(size - num_surrogates, maxchar); switch (PyUnicode_KIND(unicode)) &#123; /* case 不同 kind 执行执行相应的转换*/ &#125; return unicode_result(unicode);&#125; 如上，原始代码很长，上面只截取了相对重要的部分。好高兴，终于看到 Unicode 共享机制的苗头了，不过还得一个一个来看。 _PyUnicode_New12345678910111213141516171819202122232425262728293031323334353637383940414243// unicodeobject.c.1067static PyUnicodeObject * _PyUnicode_New(Py_ssize_t length)&#123; PyUnicodeObject *unicode; size_t new_size; /* 共享 empty strings */ if (length == 0 &amp;&amp; unicode_empty != NULL) &#123; Py_INCREF(unicode_empty); return (PyUnicodeObject*)unicode_empty; &#125; /* 容错代码(略)：length 不能过大，也不能 &lt; 0 */ // 创建对象 unicode = PyObject_New(PyUnicodeObject, &amp;PyUnicode_Type); new_size = sizeof(Py_UNICODE) * ((size_t)length + 1); // 赋初值 _PyUnicode_WSTR_LENGTH(unicode) = length; _PyUnicode_HASH(unicode) = -1; _PyUnicode_STATE(unicode).interned = 0; _PyUnicode_STATE(unicode).kind = 0; _PyUnicode_STATE(unicode).compact = 0; _PyUnicode_STATE(unicode).ready = 0; _PyUnicode_STATE(unicode).ascii = 0; _PyUnicode_DATA_ANY(unicode) = NULL; _PyUnicode_LENGTH(unicode) = 0; _PyUnicode_UTF8(unicode) = NULL; _PyUnicode_UTF8_LENGTH(unicode) = 0; // 真实数据 _PyUnicode_WSTR(unicode) = (Py_UNICODE*) PyObject_MALLOC(new_size); // 讨巧，只处理数组两端 _PyUnicode_WSTR(unicode)[0] = 0; _PyUnicode_WSTR(unicode)[length] = 0; return unicode;&#125;// 调用链：if (u == NULL) return (PyObject*)_PyUnicode_New(size); 源码依然很长，从整理后的代码可以看出，_PyUnicode_New 使用场景是：知道字符串长度，但不知道字符串的具体内容。只创建了内存空间，真实数据 ‘都是0’ 。 get_latin1_char(latin-1共享机制)123456789101112131415161718static PyObject* get_latin1_char(unsigned char ch)&#123; PyObject *unicode = unicode_latin1[ch]; if (!unicode) &#123; unicode = PyUnicode_New(1, ch); if (!unicode) return NULL; PyUnicode_1BYTE_DATA(unicode)[0] = ch; assert(_PyUnicode_CheckConsistency(unicode, 1)); unicode_latin1[ch] = unicode; &#125; Py_INCREF(unicode); return unicode;&#125;// 调用链：if (size == 1 &amp;&amp; (Py_UCS4)*u &lt; 256) return get_latin1_char((unsigned char)*u); 在上面的代码中，看到了熟悉的套路，一个数组unicode_latin1。1234// unicodeobject.c.213/* Single character Unicode strings in the Latin-1 range are being shared as well. */static PyObject *unicode_latin1[256] = &#123;NULL&#125;; 可见unicode_latin1数组，是一开始就创建，但并未填充数据，这就是单 unicode 的共享机制。 unicode_result123456789101112131415161718192021222324252627282930313233343536// unicodeobject.c.548static PyObject* unicode_result(PyObject *unicode)&#123; if (PyUnicode_IS_READY(unicode)) return unicode_result_ready(unicode); else return unicode_result_wchar(unicode);&#125;static PyObject* unicode_result_ready(PyObject *unicode)&#123; Py_ssize_t length; length = PyUnicode_GET_LENGTH(unicode); if (length == 0) &#123; // 共享 unicode_empty return unicode_empty; &#125; if (length == 1) &#123; void *data = PyUnicode_DATA(unicode); int kind = PyUnicode_KIND(unicode); Py_UCS4 ch = PyUnicode_READ(kind, data, 0); if (ch &lt; 256) &#123; // 共享 latin1_char return unicode; &#125; &#125; return unicode;&#125;// 调用链：/* 创建新 not single 对象 PyUnicode_New 中赋值 unicode.ready = 1; */unicode = PyUnicode_New(size - num_surrogates, maxchar);return unicode_result(unicode); 从上面的代码来看，似乎 unicode_result 对 PyUnicode_New 来说，纯粹是多余的。 从整个PyUnicode_FromUnicode来看，只是针对单latin-1字符，进行了共享。那就不能解释下面的代码：123456789101112&gt;&gt;&gt; a = 'abcde'&gt;&gt;&gt; b = 'abcde'&gt;&gt;&gt; id(a), id(b),id(a)==id(b)(1605538588408, 1605538588408, True)&gt;&gt;&gt; del a&gt;&gt;&gt; del b&gt;&gt;&gt; a = 'abcde'&gt;&gt;&gt; id(a)1605538115744&gt;&gt;&gt; b = 'abcde'&gt;&gt;&gt; id(a) == id(b)True Unicode 共享机制1234// unicodeobject.h.412#define SSTATE_NOT_INTERNED 0 // 未共享#define SSTATE_INTERNED_MORTAL 1 // 共享，不增加引用计数#define SSTATE_INTERNED_IMMORTAL 2 // 永久，不会被销毁 在上文的PyUnicode_New、_PyUnicode_New中，都进行了 unicode.interned = 0 赋值操作。在源码中发现 0 对应着不共享。 同时在 unicodeobject.c源码中，发现 4个可疑函数：1234void PyUnicode_InternInPlace(PyObject **p)void PyUnicode_InternImmortal(PyObject **p)PyObject * PyUnicode_InternFromString(const char *cp)void _Py_ReleaseInternedUnicodeStrings(void) 在 CPython 的其他源码中，大量存在类似true_str = PyUnicode_InternFromString(&quot;True&quot;)的代码，而PyUnicode_InternFromString内部又调用PyUnicode_InternInPlace。 PyUnicode_InternInPlace123456789101112131415161718192021222324252627282930313233343536373839// unicodeobject.c.174/* 注意，interned 不会影响 deallocation*/static PyObject *interned = NULL;static PyObject *unicode_empty = NULL;// unicodeobject.c.15278void PyUnicode_InternInPlace(PyObject **p)&#123; PyObject *s = *p; PyObject *t; // 类型检查，对子类 不共享 if (s == NULL || !PyUnicode_Check(s)) return; /* If it's a subclass, we don't really know what putting it in the interned dict might do. */ if (!PyUnicode_CheckExact(s)) return; if (PyUnicode_CHECK_INTERNED(s)) return; // 初始化 interned 字典 if (interned == NULL) &#123; interned = PyDict_New(); &#125; Py_ALLOW_RECURSION // ceval.h.113，保存线程 recursion_critical t = PyDict_SetDefault(interned, s, s); Py_END_ALLOW_RECURSION // 恢复 recursion_critical // 之前不存在 if (t != s) &#123; Py_INCREF(t); Py_SETREF(*p, t); return; &#125; // 已经存在 Py_REFCNT(s) -= 2; // k,v 各一次 _PyUnicode_STATE(s).interned = SSTATE_INTERNED_MORTAL; // == 1&#125; 可以发现： 共享前会进行类型检查，共享历史检查 共享是用 interned 这个字典对象实现 PyDict_SetDefault 返回的是字典中对象的指针 若 t != s 即，字典中已经存在该值，对t 减引用，修改 *p 指向，返回 若 t ==s 即，字典中之前不存在，那么 放入字典，并设置 s.interned = 1 interned 字典中的指针，不作为对象的有效引用，因此执行 Py_REFCNT(s) -= 2 问题暂时解决了，利用 interned 字典+PyUnicode_Intern*实现了共享。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyBytesObject</tag>
        <tag>PyUnicodeObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyLongObject]]></title>
    <url>%2F2018%2F07%2F14%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.1.Python%E6%95%B4%E6%95%B0%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[参考 Integer Objects PyLongObject在 Python2 中，存在 PyIntObject 和 PyLongObject 两种类型。前者是一个定长对象，后者是一个变长对象。Python3中 只存在后者。在 Python2 的结构体中 定义的是 long ob_ival，而 Python3 中定义的是只有1个元素的数组。1234567891011121314// longobject.h.10typedef struct _longobject PyLongObject;// longintrepr.h.85struct _longobject &#123; PyObject_VAR_HEAD digit ob_digit[1]; // digit 与平台相关，长度不一致&#125;;/* ob_size == 0 -&gt; zero ob_size &lt; 0 -&gt; 负数 PyLong_SHIFT == 30 or 15 value == SUM(for i=0 through abs(ob_size)-1) ob_digit[i] * 2**(SHIFT*i)*/ 由上可以看出，在 Python 中，整形的存储方式，是存储在一个数组中。因此通过控制 PyVarObject 的 ob_size 值，可以表示出非常非常大的数。 PyTypeObject12345678910111213// longobject.c.5431PyTypeObject PyLong_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "int", /* tp_name */ offsetof(PyLongObject, ob_digit), /* tp_basicsize */ sizeof(digit), /* tp_itemsize */ ... &amp;long_as_number, /* tp_as_number */ 0, /* tp_as_sequence */ 0, /* tp_as_mapping */ long_new, /* tp_new */ PyObject_Del, /* tp_free */&#125;; 可见： int对象的类型对象是 PyLong_Type 从之前的 PyObject 分析也能得出 PyLong_Type的类型对象是 PyType_Type int对象，只支持 as_number，不支持作为序列、映射对象操作 123456789101112131415161718// longobject.c.5393static PyNumberMethods long_as_number = &#123; (binaryfunc)long_add, /*nb_add*/ (binaryfunc)long_sub, /*nb_subtract*/ (binaryfunc)long_mul, /*nb_multiply*/ ... long_float, /*nb_float*/ ...&#125;;// longobject.c.3108static PyObject *long_add(PyLongObject *a, PyLongObject *b)&#123; PyLongObject *z; .. // 检查，计算，返回 return (PyObject *)z;&#125; long_as_number 是前文所述 PyNumberMethods 函数簇的 一个结构体实例，初始化了大量方法。如上面的 long_add 操作，创建并返回一个新的 PyObject。 对象池 small_ints1234567891011121314151617181920// longobject.c.12#define NSMALLPOSINTS 257#define NSMALLNEGINTS 5static PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];// longobject.c.5514int _PyLong_Init(void)&#123; int ival, size; PyLongObject *v = small_ints; for (ival = -NSMALLNEGINTS; ival &lt; NSMALLPOSINTS; ival++, v++) &#123; size = (ival &lt; 0) ? -1 : ((ival == 0) ? 0 : 1); (void)PyObject_INIT(v, &amp;PyLong_Type); // Py_TYPE(op) = tp; Py_SIZE(v) = size; v-&gt;ob_digit[0] = (digit)abs(ival); &#125; return 1;&#125; 如上，当 Python 初始化时，_PyLong_Init 被调用，然后会 初始化 small_ints数组，作为小整数对象池来共享使用。 前面也提到了 _longobject 结构体中 定义的是 digit ob_digit[1]，从源码中可以发现： small_ints数组长度，默认[-5, 256] size 与 值的关系：小于0 or 等于0 or 大于0 小整数共享123456789101112131415// longobject.c.51#define CHECK_SMALL_INT(ival) \ do if (-NSMALLNEGINTS &lt;= ival &amp;&amp; ival &lt; NSMALLPOSINTS) &#123; \ return get_small_int((sdigit)ival); \ &#125; while(0)// longobject.c.37static PyObject * get_small_int(sdigit ival)&#123; PyObject *v; assert(-NSMALLNEGINTS &lt;= ival &amp;&amp; ival &lt; NSMALLPOSINTS); v = (PyObject *)&amp;small_ints[ival + NSMALLNEGINTS]; Py_INCREF(v); return v;&#125; 如上，通过宏 CHECK_SMALL_INT，可以共享小整数。返回增加引用计数，并且返回指针。 创建对象1234567891011PyObject* PyLong_FromLong(long v)PyObject* PyLong_FromUnsignedLong(unsigned long v)PyObject* PyLong_FromSsize_t(Py_ssize_t v)PyObject* PyLong_FromSize_t(size_t v)PyObject* PyLong_FromLongLong(long long v)PyObject* PyLong_FromUnsignedLongLong(unsigned long long v)PyObject* PyLong_FromDouble(double v)PyObject* PyLong_FromString(const char *str, char **pend, int base)PyObject* PyLong_FromUnicode(Py_UNICODE *u, Py_ssize_t length, int base)PyObject* PyLong_FromUnicodeObject(PyObject *u, int base)PyObject* PyLong_FromVoidPtr(void *p) 在 CPython3.6.6 中，提供了大量创建 PyLongObject 的方法。下面，我们将查看其中一个。 PyLong_FromLong123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051PyObject * PyLong_FromLong(long ival)&#123; PyLongObject *v; unsigned long abs_ival; unsigned long t; /* unsigned so &gt;&gt; doesn't propagate sign bit */ int ndigits = 0; int sign; CHECK_SMALL_INT(ival); // 宏，尝试小整数共享 // 处理得到 abs_ival(unsigned long) if (ival &lt; 0) &#123; /* negate: can't write this as abs_ival = -ival since that invokes undefined behaviour when ival is LONG_MIN */ abs_ival = 0U-(unsigned long)ival; sign = -1; &#125; else &#123; abs_ival = (unsigned long)ival; sign = ival == 0 ? 0 : 1; &#125; /* 处理 single-digit ints */ if (!(abs_ival &gt;&gt; PyLong_SHIFT)) &#123; v = _PyLong_New(1); if (v) &#123; Py_SIZE(v) = sign; v-&gt;ob_digit[0] = Py_SAFE_DOWNCAST(abs_ival, unsigned long, digit); // pyport.h.304: #define Py_SAFE_DOWNCAST(VALUE, WIDE, NARROW) (NARROW)(VALUE) &#125; return (PyObject*)v; &#125; /* Larger numbers: loop to determine number of digits */ t = abs_ival; while (t) &#123; ++ndigits; t &gt;&gt;= PyLong_SHIFT; &#125; v = _PyLong_New(ndigits); if (v != NULL) &#123; digit *p = v-&gt;ob_digit; Py_SIZE(v) = ndigits*sign; t = abs_ival; while (t) &#123; *p++ = Py_SAFE_DOWNCAST(t &amp; PyLong_MASK, unsigned long, digit); t &gt;&gt;= PyLong_SHIFT; &#125; &#125; return (PyObject *)v;&#125; 如上，创建一个 int 对象，主要有以下几个步骤： 尝试从对象池中获取 处理获取 abs_value 处理 single-digit 循环处理 Larger numbers 代码很简单，下面只看一下 _PyLong_New 具体逻辑。 _PyLong_New12345678910111213141516// longobject.c.179#define MAX_LONG_DIGITS \ ((PY_SSIZE_T_MAX - offsetof(PyLongObject, ob_digit))/sizeof(digit))PyLongObject * _PyLong_New(Py_ssize_t size)&#123; PyLongObject *result; if (size &gt; (Py_ssize_t)MAX_LONG_DIGITS) &#123; PyErr_SetString(PyExc_OverflowError, "too many digits in integer"); return NULL; &#125; result = PyObject_MALLOC(offsetof(PyLongObject, ob_digit) + size*sizeof(digit)); return (PyLongObject*)PyObject_INIT_VAR(result, &amp;PyLong_Type, size);&#125; 从代码可以看出，能够表示的最大整数是跟堆内存相关的，几乎可以表示无穷大的数了。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
        <tag>PyLongObject</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CPython3.6源码分析】PyObject/PyObjectType]]></title>
    <url>%2F2018%2F07%2F14%2F1.CPython3.6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F1.0.PyObject%2F</url>
    <content type="text"><![CDATA[参考资料 Python/C API Reference Manual 前言123456789101112131415161718192021222324252627# object.h.8/* Object and type object interface */Objects are structures allocated on the heap.Objects are never allocated statically or on the stack;An object has a &apos;reference count&apos; that is increased or decreased when apointer to the object is copied or deleted;when the reference count reaches zero there are no references to the object leftand it can be removed from the heap.An object has a &apos;type&apos; that determines what it represents and what kindof data it contains. An object&apos;s type is fixed when it is created.Types themselves are represented as objects; an object contains apointer to the corresponding type object. The type itself has a typepointer pointing to the object representing the type &apos;type&apos;, whichcontains a pointer to itself!).once allocated an object keeps the same size and address.Objects that must hold variable-size data can contain pointers tovariable-size parts of the object.Objects are always accessed through pointers of the type &apos;PyObject *&apos;.The type &apos;PyObject&apos; is a structure that only contains the reference countand the type pointer.A standard interface exists for objects that contain an array of itemswhose size is determined when the object is allocated. 开篇一段注释，从注释中能提取到很多要点： 对象堆分配、从不栈分配 垃圾回收之引用计数 对象、类型对象、type 容器对象可变依据：持有指针 基石对象 PyObject 与类型转换 PyObject123456789101112// object.h.98typedef struct _object &#123; // ifdef Py_TRACE_REFS，定义双向链表存储所有堆上存活对象指针 _PyObject_HEAD_EXTRA Py_ssize_t ob_refcnt; # 引用计数 struct _typeobject *ob_type; # 类型对象指针&#125; PyObject;typedef struct &#123; PyObject ob_base; Py_ssize_t ob_size; /* Number of items in variable part，作 int 理解*/&#125; PyVarObject; 在 Python 中，实际上没有任何东西被声明为 PyObject，但所有对象都可以通过 PyObject 进行引用。类似的还有，指向容器的 PyVarObject 。 PyObject 结构体中包含： 指向类型对象 _typeobject 的指针 ob_type 用于垃圾回收的引用计数 ob_refcnt 对于容器对象，PyObject_VAR_HEAD 用 ob_size 代表元素个数。 PyTypeObject1234567891011121314151617181920212223242526272829// include.h.346typedef struct _typeobject &#123; PyObject_VAR_HEAD // #define PyObject_VAR_HEAD PyVarObject ob_base; const char *tp_name; /* For printing, in format "&lt;module&gt;.&lt;name&gt;" */ Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ /* Methods to implement standard operations */ destructor tp_dealloc; printfunc tp_print; /* Method suites for standard classes */ PyNumberMethods *tp_as_number; PySequenceMethods *tp_as_sequence; PyMappingMethods *tp_as_mapping; /* More standard operations (here for binary compatibility) */ /* Functions to access object as input/output buffer */ /* Flags to define presence of optional/expanded features */ /* Documentation string */ /* call function for all accessible objects */ /* delete references to contained objects */ /* weak reference enabler */ /* Iterators */ getiterfunc tp_iter; iternextfunc tp_iternext; /* Attribute descriptor and subclassing stuff */ struct PyMethodDef *tp_methods; struct PyMemberDef *tp_members;&#125; PyTypeObject; 创建对象之前，必须知道申请的内存空间大小，而这些元信息就存储在对象的类型对象中。含有头域PyObject_VAR_HEAD，表明类型对象本身是 可变长对象。结构体内存储大量信息，主要包括： 常规信息：类型名、Doc、tp_itemsize、tp_basicsize等 常规方法指针：tp_new、tp_init、tp_free等 函数簇：PyNumberMethods、PySequenceMethods等 123456// object.h.301typedef struct &#123; lenfunc mp_length; binaryfunc mp_subscript; objobjargproc mp_ass_subscript;&#125; PyMappingMethods; 在函数簇 PyMappingMethods 中，定义了支持映射的对象应该支持的操作。反过来说，一旦定义了 其中的方法，那么该对象就支持该方法。正因为 PyTypeObject 中同时定义了三种函数簇，所以才可以实现鸭子类型。 PyType_Type前面说过，PyVarObject -&gt; PyObject -&gt; PyTypeObject，但 PyTypeObject 内部又存在 PyVarObject。那么，这个内部的 VarObject 的 type 又是什么？此处先来看下 a = int(10) == 整型对象 a.ob_type == PyLong_Type PyLong_Type.ob_type == PyType_Type PyType_Type.ob_type == PyType_Type 123456789101112131415161718192021// object.h.85#define PyObject_HEAD_INIT(type) &#123; 1, type &#125;,#define PyVarObject_HEAD_INIT(type, size) &#123; PyObject_HEAD_INIT(type) size &#125;,// typeobject.c.3383PyTypeObject PyType_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) /* ob_base = &#123;ob_refcnt=1, *ob_type=PyType_Type&#125; ob_size = 0 */ "type", /* tp_name */ sizeof(PyHeapTypeObject), /* tp_basicsize */ sizeof(PyMemberDef), /* tp_itemsize */ ... type_doc, /* tp_doc */ ... type_init, /* tp_init */ type_new, /* tp_new */ ...&#125;; 如上，可以看见 tp_name == ‘type’，即 Python 中 type 的类型对象就是 PyType_Type。第一句，&amp;PyType_Type 印证了 type(type)==type，形成自旋。 对于内建对象，Python 中有定义好的结构体，如 PyLongObject-&gt;PyLong_Type。而对于用户创建的类，就必须动态创建 type 对象。我们知道，创建类可以通过 type() 的方式生成，最终将调用 PyType_Type.type_new()。 PyBaseObject_Type1234567891011// typeobject.c.4535PyTypeObject PyBaseObject_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) "object", /* tp_name */ sizeof(PyObject), /* tp_basicsize */ object_methods, /* tp_methods */ object_init, /* tp_init */ PyType_GenericAlloc, /* tp_alloc */ object_new, /* tp_new */&#125;; 从上可以看出，object的类型对象就是PyBaseObject_Type。第一句，&amp;PyType_Type 印证了 type(object)==type，即 object 的类型对象，的类型对象是 PyType_Type。 object VS type这里要搞清楚的是： 对象，是通过 PyObject 结构体定义的，必须包含 ob_refcnt、ob_type 类型，PyBaseObject_Type、PyType_Type，本身也是可变对象 PyVarObject 普通对象的类型指针，ob_type，指向的是 类型对象：PyBaseObject_Type、PyType_Type 而 PyBaseObject_Type 本身也是对象，也具有 ob_type，指向的是 PyType_Type 最终 PyType_Type 也是对象，其 ob_type，指向的是 自身 123456789101112PyTypeObject PyList_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) &quot;list&quot;,&#125;PyTypeObject PyLong_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) &quot;int&quot;,&#125;PyTypeObject PyBaseObject_Type = &#123; PyVarObject_HEAD_INIT(&amp;PyType_Type, 0) &quot;object&quot;,&#125; 层次结构： 基石，PyObject，一切皆对象 最顶端的是 type，这也正是 type 被称为 metaclass 的原因。 内置对象 list/int/object等，其类型对象都是指向 type。 实例对象 int(1)，其类型对象是 PyLong_Type。 假设： 没有 1，好像可以照常用，只是不能创建 类了 没有 2, 也可以照常用，只是每次需要自己创建 int等基础类型 没有 3，不能实例化了，啥也干不了 容易混淆的是： object，既可以说是实例对象 3，又可以说是 类型对象 2，还可以说成 python对象 0 type，既可以说成实例对象3的类型对象 2，又可以说成元类 1 如果有人问，type 和 object 的关系，就得先问清楚他说的 type和object 指哪一个层面！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CPython3.6源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客开通啦]]></title>
    <url>%2F2018%2F07%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[在时间、成本、道德约束等各种抉择下，最终还是选择了github.io。嗯，安心写博客。]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>起风了</tag>
      </tags>
  </entry>
</search>
